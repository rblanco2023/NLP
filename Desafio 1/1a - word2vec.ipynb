{"cells":[{"cell_type":"markdown","metadata":{"id":"Ue5hxxkdAQJg"},"source":["<img src=\"https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## Word2vect\n"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":362,"status":"ok","timestamp":1656557193698,"user":{"displayName":"Raul Blanco Eliçabe","userId":"07141923789195414484"},"user_tz":180},"id":"kCED1hh-Ioyf"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from numpy import array\n","from numpy import argmax\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":370,"status":"ok","timestamp":1656557196610,"user":{"displayName":"Raul Blanco Eliçabe","userId":"07141923789195414484"},"user_tz":180},"id":"PUbfVnzIIoMj"},"outputs":[],"source":["def cosine_similarity(a, b):\n","    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"]},{"cell_type":"markdown","metadata":{"id":"DMOa4JPSCJ29"},"source":["### Datos"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1656557197712,"user":{"displayName":"Raul Blanco Eliçabe","userId":"07141923789195414484"},"user_tz":180},"id":"RIO7b8GjAC17"},"outputs":[],"source":["corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"]},{"cell_type":"markdown","metadata":{"id":"8WqdaTmO8P1r"},"source":["Documento 1 --> que dia es hoy \\\n","Documento 2 --> martes el dia de hoy es martes \\\n","Documento 3 --> martes muchas gracias"]},{"cell_type":"markdown","metadata":{"id":"FVHxBRNzCMOS"},"source":["### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n","- Cada documento transformarlo en una lista de términos\n","- Armar un vector de términos no repetidos de todos los documentos"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":381,"status":"ok","timestamp":1656557202639,"user":{"displayName":"Raul Blanco Eliçabe","userId":"07141923789195414484"},"user_tz":180},"id":"3ZqTOZzDI7uv"},"outputs":[],"source":["doc1 = corpus[0]\n","voc1 = doc1.split(\" \")\n","doc2 = corpus[1]\n","voc2 = doc2.split(\" \")\n","doc3 = corpus[2]\n","voc3 = doc3.split(\" \")"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":411,"status":"ok","timestamp":1656557989624,"user":{"displayName":"Raul Blanco Eliçabe","userId":"07141923789195414484"},"user_tz":180},"id":"A4xhZZ8OBTnF"},"outputs":[],"source":["bow = voc1 + voc2 + voc3\n","bow = set(bow)"]},{"cell_type":"markdown","metadata":{"id":"RUhH983FI7It"},"source":["### 2- OneHot encoding\n","Data una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"executionInfo":{"elapsed":335,"status":"error","timestamp":1656557960550,"user":{"displayName":"Raul Blanco Eliçabe","userId":"07141923789195414484"},"user_tz":180},"id":"fULczmM2WspV","outputId":"388c3586-120c-4f79-d298-c1a12c661682"},"outputs":[],"source":["#Uno los documentos en una matriz/Dataframe\n","doc1=pd.DataFrame({\"doc1\": voc1}).T\n","doc2=pd.DataFrame({\"doc2\": voc2}).T\n","doc3=pd.DataFrame({\"doc3\": voc3}).T\n","corp = pd.concat([doc1,doc2,doc3])\n","corpus = corp.to_numpy()  #obtengo matriz con documentos\n","rows, columns = corpus.shape\n","OHE_array = np.zeros((rows,len(bow)))\n","bow=pd.DataFrame(bow)\n","bow = bow.to_numpy()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def One_Hot_Encoder (corpus):\n","  for word in range(len(bow)):\n","    for i in range(rows):\n","      for j in range(len(corpus[i])):\n","        if corpus[i,j] == bow[word]:\n","          OHE_array[i,word] = 1\n"," # OHE_array.squeeze()\n","  #OHE_Data = pd.DataFrame(OHE_array)\n"," # OHE_Data.columns = bow\n","  #return OHE_Data"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":313,"status":"ok","timestamp":1656558656443,"user":{"displayName":"Raul Blanco Eliçabe","userId":"07141923789195414484"},"user_tz":180},"id":"ev2ing29ICZJ","outputId":"7cfaf210-d71c-4843-9a3e-9e9335c15f36"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>(dia,)</th>\n","      <th>(es,)</th>\n","      <th>(hoy,)</th>\n","      <th>(martes,)</th>\n","      <th>(muchas,)</th>\n","      <th>(de,)</th>\n","      <th>(gracias,)</th>\n","      <th>(que,)</th>\n","      <th>(el,)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   (dia,)  (es,)  (hoy,)  (martes,)  (muchas,)  (de,)  (gracias,)  (que,)  \\\n","0     1.0    1.0     1.0        0.0        0.0    0.0         0.0     1.0   \n","1     1.0    1.0     1.0        1.0        0.0    1.0         0.0     0.0   \n","2     0.0    0.0     0.0        1.0        1.0    0.0         1.0     0.0   \n","\n","   (el,)  \n","0    0.0  \n","1    1.0  \n","2    0.0  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["One_Hot_Encoder(corpus)\n","OHE_array.squeeze()\n","OHE_Data = pd.DataFrame(OHE_array)\n","OHE_Data.columns=bow\n","OHE_Data.head()"]},{"cell_type":"markdown","metadata":{"id":"IIyWGmCpJVQL"},"source":["### 3- Vectores de frecuencia\n","Data una lista de textos, devolver una matriz con la representación de frecuencia de estos"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["def TF(corpus,bow,rows):\n","    for word in range(len(bow)):\n","        for i in range(rows):\n","            for j in range(len(corpus[i])):\n","                if corpus[i,j] == bow[word]:\n","                    TF_array[i,word] = TF_array[i,word] + 1\n","    #TF_Data = pd.DataFrame(TF_array)\n","    #TF_Data.columns = bow\n","    return TF_array#, TF_Data"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/plain":["array([[1., 1., 1., 0., 0., 0., 0., 1., 0.],\n","       [1., 1., 1., 2., 0., 1., 0., 0., 1.],\n","       [0., 0., 0., 1., 1., 0., 1., 0., 0.]])"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["rows, columns = corpus.shape\n","TF_array = np.zeros((rows, len(bow)))\n","TF(corpus, bow, rows)"]},{"cell_type":"markdown","metadata":{"id":"z_Ot8HvWJcBu"},"source":["### 4- TF-IDF\n","Data una lista de textos, devolver una matriz con la representacion TFIDF"]},{"cell_type":"code","execution_count":81,"metadata":{"id":"waG_oWtpJjRw"},"outputs":[],"source":["# Log N/DF\n","# N = cantidad de documentos en el corpus\n","# DF = cantida de documentos con la palabra n en el corpus\n","def TFIDF(corpus, TF_array, rows):\n","    TF_Data = pd.DataFrame(TF_array)\n","    DF = OHE_Data.sum(axis=0)\n","    IDF = np.log10(rows/DF)\n","    IDF = np.array(IDF)\n","    TF_array = TF_Data.to_numpy()\n","   # TF_IDF = TF_array * IDF\n","   # TF_IDF = pd.DataFrame(TF_IDF)\n","   # TF_IDF.columns= bow\n","    return TF_array * IDF,  np.log10(rows/DF)"]},{"cell_type":"code","execution_count":82,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>(dia,)</th>\n","      <th>(es,)</th>\n","      <th>(hoy,)</th>\n","      <th>(martes,)</th>\n","      <th>(muchas,)</th>\n","      <th>(de,)</th>\n","      <th>(gracias,)</th>\n","      <th>(que,)</th>\n","      <th>(el,)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.176091</td>\n","      <td>0.176091</td>\n","      <td>0.176091</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.477121</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.176091</td>\n","      <td>0.176091</td>\n","      <td>0.176091</td>\n","      <td>0.352183</td>\n","      <td>0.000000</td>\n","      <td>0.477121</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.477121</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.176091</td>\n","      <td>0.477121</td>\n","      <td>0.000000</td>\n","      <td>0.477121</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     (dia,)     (es,)    (hoy,)  (martes,)  (muchas,)     (de,)  (gracias,)  \\\n","0  0.176091  0.176091  0.176091   0.000000   0.000000  0.000000    0.000000   \n","1  0.176091  0.176091  0.176091   0.352183   0.000000  0.477121    0.000000   \n","2  0.000000  0.000000  0.000000   0.176091   0.477121  0.000000    0.477121   \n","\n","     (que,)     (el,)  \n","0  0.477121  0.000000  \n","1  0.000000  0.477121  \n","2  0.000000  0.000000  "]},"execution_count":82,"metadata":{},"output_type":"execute_result"}],"source":["TF_IDF, IDF = TFIDF(corpus,TF_array,rows)\n","TF_IDF = pd.DataFrame(TF_IDF)\n","TF_IDF.columns = bow\n","IDF = np.array(IDF)\n","#TF_array = TF_Data.to_numpy()\n","TF_IDF"]},{"cell_type":"markdown","metadata":{"id":"xMcsfndWJjm_"},"source":["### 5 - Comparación de documentos\n","Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"]},{"cell_type":"code","execution_count":97,"metadata":{"id":"CZdiop6IJpZN"},"outputs":[],"source":["def comparacion(corpus, indice, rows):\n","    TF_IDF, IDF= TFIDF(corpus, TF_array, rows)\n","    ref = np.zeros(len(corpus))\n","    for i in range(len(corpus)):\n","        resultado = cosine_similarity(TF_IDF[indice, :], TF_IDF[i, :])\n","        print(\"Similtud coseno doc{} contra doc{} es: {}\".format(indice, i, resultado))\n","    #A = ref.argsort()[::-1][:len(corpus)]\n","    return ref.argsort()[::-1][:len(corpus)]"]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Similtud coseno doc1 contra doc0 es: 0.2003419026809871\n","Similtud coseno doc1 contra doc1 es: 1.0\n","Similtud coseno doc1 contra doc2 es: 0.10845711727883083\n"]}],"source":["result = comparacion(corpus, indice = 1, rows = 3)"]},{"cell_type":"code","execution_count":101,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["La similitud cos() para los documentos pertenecientes al corpus es:  [2 1 0]\n"]}],"source":["print(\"La similitud cos() para los documentos pertenecientes al corpus es: \", result)"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"1a - word2vec.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.9.7","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"vscode":{"interpreter":{"hash":"a2ced859803238e76c8f9e1c09ef13675f14314bd3f3e87839a4f0bb215fc403"}}},"nbformat":4,"nbformat_minor":0}
