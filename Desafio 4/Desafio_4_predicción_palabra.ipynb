{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3yeJGnCYxuF"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## Predicción de próxima palabra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv5PEwGzZA9-"
      },
      "source": [
        "### Objetivo\n",
        "El objetivo es utilizar documentos / corpus para crear embeddings de palabras basado en ese contexto utilizando la layer Embedding de Keras. Se utilizará esos embeddings junto con layers LSTM para predeccir la próxima posible palabra."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-QdFbHZYj7C"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import io\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "import re\n",
        "\n",
        "# Para leer y parsear el texto en HTML de wikipedia\n",
        "import bs4 as bs\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
        "from keras.layers import Bidirectional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTvXlEKQZdqx"
      },
      "source": [
        "### Datos\n",
        "Utilizaremos como dataset los sonetos de Shakespeare"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_html = urllib.request.urlopen('https://www.gutenberg.org/files/1041/1041-h/1041-h.htm')\n",
        "raw_html = raw_html.read()\n",
        "\n",
        "article_html = bs.BeautifulSoup(raw_html, 'lxml')\n",
        "\n",
        "article_paragraphs = article_html.find_all('p')\n",
        "\n",
        "article_text = ''\n",
        "\n",
        "for para in article_paragraphs:\n",
        "    article_text += para.text\n",
        "\n",
        "article_text = article_text.lower()"
      ],
      "metadata": {
        "id": "xnpt-P5a5Twp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article_text = article_text.replace('\\n', '.') #Elimino los saltos de fila\n",
        "article_text = article_text.replace(',.', '.') # Reemplazo ,. por .\n",
        "article_text = article_text.replace(':.', '.')\n",
        "article_text = article_text.replace(';.', '.')\n",
        "article_text = article_text.replace('\\xa0\\xa0\\xa0\\xa0', '')\n",
        "article_text = re.split(r\"\\r.\", article_text) #Separo las oraciones"
      ],
      "metadata": {
        "id": "BQyX0MSJ5gs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(article_text)\n",
        "df.drop(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "kk394ozH5iS0",
        "outputId": "3b25f4d4-9019-4dbc-ae3a-b5043a7fe55c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                      0\n",
              "1            from fairest creatures we desire increase,\n",
              "2           that thereby beauty’s rose might never die,\n",
              "3              but as the riper should by time decease,\n",
              "4                his tender heir might bear his memory:\n",
              "5        but thou, contracted to thine own bright eyes,\n",
              "...                                                 ...\n",
              "2151        which from love’s fire took heat perpetual,\n",
              "2152               growing a bath and healthful remedy,\n",
              "2153      for men diseas’d; but i, my mistress’ thrall,\n",
              "2154      came there for cure and this by that i prove,\n",
              "2155    love’s fire heats water, water cools not love..\n",
              "\n",
              "[2155 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd9d4196-7fb5-4b79-b700-2224908422d4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>from fairest creatures we desire increase,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>that thereby beauty’s rose might never die,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>but as the riper should by time decease,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>his tender heir might bear his memory:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>but thou, contracted to thine own bright eyes,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2151</th>\n",
              "      <td>which from love’s fire took heat perpetual,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2152</th>\n",
              "      <td>growing a bath and healthful remedy,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2153</th>\n",
              "      <td>for men diseas’d; but i, my mistress’ thrall,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2154</th>\n",
              "      <td>came there for cure and this by that i prove,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2155</th>\n",
              "      <td>love’s fire heats water, water cools not love..</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2155 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd9d4196-7fb5-4b79-b700-2224908422d4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dd9d4196-7fb5-4b79-b700-2224908422d4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dd9d4196-7fb5-4b79-b700-2224908422d4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riT898QlZnmF",
        "outputId": "6b77a7b4-2b56-4660-b87b-421a70ff3036"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de documentos: 2156\n"
          ]
        }
      ],
      "source": [
        "print(\"Cantidad de documentos:\", df.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDoouHp7Zp6D"
      },
      "source": [
        "### 1 - Ejemplo de Preprocesamiento\n",
        "- Hay que transformar las oraciones en tokens.\n",
        "- Dichas oraciones hay que ajustarlas al tamaño fijo de nuestra sentencia de entrada al modelo.\n",
        "- Hay que separar las palabras objetivos (target) que el modelo debe predecir en cada sentencia armada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5FeTaGvbDbw"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer # equivalente a ltokenizer de nltk\n",
        "from keras.preprocessing.text import text_to_word_sequence # equivalente a word_teokenize de nltk\n",
        "from keras.preprocessing.sequence import pad_sequences # se utilizará para padding\n",
        "\n",
        "# largo de la secuencia, incluye seq input + word output\n",
        "train_len = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Zf3O7eK6ZpP8",
        "outputId": "5ed833f1-a6db-4c38-d33d-27b5f2bd76b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  from fairest creatures we desire increase,'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Ejemplo de como transformar una oración a tokens usando keras\n",
        "text = df.loc[1,0]\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOv67Sj7aeFH",
        "outputId": "a0fcb9e5-9d10-4638-b983-80c4a8343e9e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['from', 'fairest', 'creatures', 'we', 'desire', 'increase']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "tokens = text_to_word_sequence(text) # entran oraciones -> salen vectores de N posiciones (tokens)\n",
        "tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrlyqkoiaymK"
      },
      "source": [
        "1.1 - Transformar las oraciones en secuencias (tokens) de palabras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XH_L14Wjaowe"
      },
      "outputs": [],
      "source": [
        "# Recorrer todas las filas y transformar las oraciones\n",
        "# en secuencias de palabras\n",
        "sentence_tokens = []\n",
        "for _, row in df[:None].iterrows():\n",
        "    sentence_tokens.append(text_to_word_sequence(row[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KASzU4CdaxbZ",
        "outputId": "b8194221-f570-483a-ba6f-ae62d7ccd886"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['from', 'fairest', 'creatures', 'we', 'desire', 'increase'],\n",
              " ['that', 'thereby', 'beauty’s', 'rose', 'might', 'never', 'die']]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Demos un vistazo\n",
        "sentence_tokens[1:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A659lswTbIIB"
      },
      "outputs": [],
      "source": [
        "# Código para hacer el desfazaje de las palabras\n",
        "# según el train_len\n",
        "text_sequences = []\n",
        "\n",
        "for i in range(train_len, len(tokens)):\n",
        "  seq = tokens[i-train_len:i]\n",
        "  text_sequences.append(seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01JEoPPnbgRF",
        "outputId": "c4bfbc13-1632-457d-9b7c-353d43d3906c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['from', 'fairest', 'creatures', 'we'],\n",
              " ['fairest', 'creatures', 'we', 'desire']]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Demos un vistazo a nuestros vectores para entrenar el modelo\n",
        "text_sequences "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4B0gHnKVa4W_"
      },
      "source": [
        "1.2 - Crear los vectores de palabras (word2vec)\n",
        "\n",
        "Ahora necesitamos pasarlos a números para que lo entienda la red y separar input de output.\n",
        "- El Input seran integers (word2vec)\n",
        "- Mientras que el output será one hot encodeado (labels) del tamaño del vocabulario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkPNvXeQcS0U"
      },
      "outputs": [],
      "source": [
        "tok = Tokenizer() \n",
        "\n",
        "# El tokeinzer \"aprende\" las palabras que se usaran\n",
        "# Se construye (fit) una vez por proyecto, se aplica N veces (tal cual un encoder)\n",
        "tok.fit_on_texts(text_sequences) \n",
        "\n",
        "# Convertimos las palabras a números\n",
        "# entran palabras -> salen números\n",
        "sequences = tok.texts_to_sequences(text_sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SIc44IocyQb",
        "outputId": "0e298c80-67fd-43e4-bd57-d2e6dba06360"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[4, 1, 2, 3], [1, 2, 3, 5]]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Ahora sequences tiene los números \"ID\", largo 4\n",
        "sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ro81yCQc1oX",
        "outputId": "266f3a74-77c4-4fad-981f-0797e0dae47d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ],
      "source": [
        "# Cantidad de casos (doc) de entrada\n",
        "print(tok.document_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzAWNfroc4u1",
        "outputId": "413335ff-ebf5-4ff6-ffb7-ca7afcab01df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ],
      "source": [
        "# Cantidad de veces que aparece cada palabra\n",
        "print(len(tok.word_counts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spTBxmFQc6h8",
        "outputId": "46267922-375c-4339-d31e-19241c04c144"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fairest': 1, 'creatures': 2, 'we': 3, 'from': 4, 'desire': 5}\n"
          ]
        }
      ],
      "source": [
        "# El índice para cada palabra\n",
        "# El sistema las ordena de las más populares a las menos populares\n",
        "print(tok.word_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUDkjy80c77h",
        "outputId": "b4006497-1e3b-4971-c701-5f2ccdeb4320"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(<class 'int'>, {'creatures': 2, 'from': 1, 'fairest': 2, 'we': 2, 'desire': 1})\n"
          ]
        }
      ],
      "source": [
        "# Cantidad de veces quea aparece cada palabra en cada \"documento\"\n",
        "# (1 documento = 1 caso de entrada)\n",
        "print(tok.word_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohS5Tao1d2KB"
      },
      "source": [
        "### 2 - Preprocesamiento completo\n",
        "Debemos realizar los mismos pasos que en el ejemplo anterior, pero antes de eso debemos transformar ese dataset de filas de oraciones en un texto completo continuo para poder extraer el vocabulario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63Z2-Se2t27r",
        "outputId": "faf6dbb7-2db5-4f80-bbdc-2633cf2e017a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                                      \n",
              "1            from fairest creatures we desire increase,\n",
              "2           that thereby beauty’s rose might never die,\n",
              "3              but as the riper should by time decease,\n",
              "4                his tender heir might bear his memory:\n",
              "5        but thou, contracted to thine own bright eyes,\n",
              "6       feed’st thy light’s flame with self-substant...\n",
              "7                 making a famine where abundance lies,\n",
              "8         thyself thy foe, to thy sweet self too cruel:\n",
              "9         thou that art now the world’s fresh ornament,\n",
              "10                 and only herald to the gaudy spring,\n",
              "11            within thine own bud buriest thy content,\n",
              "12         and tender churl mak’st waste in niggarding:\n",
              "13             pity the world, or else this glutton be,\n",
              "14      to eat the world’s due, by the grave and thee..\n",
              "15           when forty winters shall besiege thy brow,\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Vistazo a las primeras filas\n",
        "df.loc[:15,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "kILsSoxTuHEr",
        "outputId": "a9905390-8159-41a8-de23-35f219f31287"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'   from fairest creatures we desire increase,   that thereby beauty’s rose might never die,   but as the riper should by time decease,   his tender heir might bear his memory:   but thou, contracted to thine own bright eyes,   feed’st thy light’s flame with self-substantial fuel,   making a famine where abundance lies,   thyself thy foe, to thy sweet self too cruel:   thou that art now the world’s fresh ornament,   and only herald to the gaudy spring,   within thine own bud buriest thy content,   and tender churl mak’st waste in niggarding:   pity the world, or else this glutton be,   to eat the world’s due, by the grave and thee..   when forty winters shall besiege thy brow,   and dig deep trenches in thy beauty’s field,   thy youth’s proud livery so gazed on now,   will be a tatter’d weed of small worth held:   then being asked, where all thy beauty lies,   where all the treasure of thy lusty days;   to say, within thine own deep sunken eyes,   were an all-eating shame, and thriftless praise.   how much more praise deserv’d thy beauty’s use,   if thou couldst answer ‘this fair child of mine   shall sum my count, and make my old excuse,’   proving his beauty by succession thine!   this were to be new made when thou art old,   and see thy blood warm when thou feel’st it cold..   look in thy glass and tell the face thou viewest   now is the time that face should form another;   whose fresh repair if now thou not renewest,   thou dost beguile the world, unbless some mother.   for where is she so fair whose unear’d womb   disdains the tillage of thy husbandry?   or who is he so fond will be the tomb,   of his self-love to stop posterity?   thou art thy mother’s glass and she in thee   calls back the lovely april of her prime;   so thou through windows of thine age shalt see,   despite of wrinkles this thy golden time.   but if thou live, remember’d not to be,   die single and thine image dies with thee..   unthrifty loveliness, why dost thou spend   upon thyself thy beauty’s legacy?   nature’s bequest gives nothing, but doth lend,   and being frank she lends to those are free:   then, beauteous niggard, why dost thou abuse   the bounteous largess given thee to give?   profitless usurer, why dost thou use   so great a sum of sums, yet canst not live?   for having traffic with thyself alone,   thou of thyself thy sweet self dost deceive:   then how when nature calls thee to be gone,   what acceptable audit canst thou leave?   thy unused beauty must be tombed with thee,   which, used, lives th’ executor to be..   those hours, that with gentle work did frame   the lovely gaze where every eye doth dwell,   will play the tyrants to the very same   and that unfair which fairly doth excel;   for never-resting time leads summer on   to hideous winter, and confounds him there;   sap checked with frost, and lusty leaves quite gone,   beauty o’er-snowed and bareness every where:   then were not summer’s distillation left,   a liquid prisoner pent in walls of glass,   beauty’s effect with beauty were bereft,   nor it, nor no remembrance what it was:   but flowers distill’d, though they with winter meet,   leese but their show; their substance still lives sweet..   then let not winter’s ragged hand deface,   in thee thy summer, ere thou be distill’d:   make sweet some vial; treasure thou some place   with beauty’s treasure ere it be self-kill’d.   that use is not forbidden usury,   which happies those that pay the willing loan;   that’s for thyself to breed another thee,   or ten times happier, be it ten for one;   ten times thyself were happier than thou art,   if ten of thine ten times refigur’d thee:   then what could death do if thou shouldst depart,   leaving thee living in posterity?   be not self-will’d, for thou art much too fair   to be death’s conquest and make worms thine heir..   lo! in the orient when the gracious light   lifts up his burning head, each under eye   doth homage to his new-appearing sight,   serving with looks his sacred majesty;   and having climb’d the steep-up heavenly hill,   resembling strong youth in his middle age,   yet mortal looks adore his beauty still,   attending on his golden pilgrimage:   but when from highmost pitch, with weary car,   like feeble age, he reeleth from the day,   the eyes, ’fore duteous, now converted are   from his low tract, and look another way:   so thou, thyself outgoing in thy noon:   unlook’d, on diest unless thou get a son..   music to hear, why hear’st thou music sadly?   sweets with sweets war not, joy delights in joy:   why lov’st thou that which thou receiv’st not gladly,   or else receiv’st with pleasure thine annoy?   if the true concord of well-tuned sounds,   by unions married, do offend thine ear,   they do but sweetly chide thee, who confounds   in singleness the parts that thou shouldst bear.   mark how one string, sweet husband to another,   strikes each in each by mutual ordering;   resembling sire and child and happy mother,   who, all in one, one pleasing note do sing:   whose speechless song being many, seeming one,   sings this to thee: ‘thou single wilt prove none.’.   is it for fear to wet a widow’s eye,   that thou consum’st thyself in single life?   ah! if thou issueless shalt hap to die,   the world will wail thee like a makeless wife;   the world will be thy widow and still weep   that thou no form of thee hast left behind,   when every private widow well may keep   by children’s eyes, her husband’s shape in mind:   look! what an unthrift in the world doth spend   shifts but his place, for still the world enjoys it;   but beauty’s waste hath in the world an end,   and kept unused the user so destroys it.   no love toward others in that bosom sits   that on himself such murd’rous shame commits..   for shame! deny that thou bear’st love to any,   who for thyself art so unprovident.   grant, if thou wilt, thou art belov’d of many,   but that thou none lov’st is most evident:   for thou art so possess’d with murderous hate,   that ’gainst thyself thou stick’st not to conspire,   seeking that beauteous roof to ruinate   which to repair should be thy chief desire.   o! change thy thought, that i may change my mind:   shall hate be fairer lodg’d than gentle love?   be, as thy presence is, gracious and kind,   or to thyself at least kind-hearted prove:   make thee another self for love of me,   that beauty still may live in thine or thee..   as fast as thou shalt wane, so fast thou grow’st,   in one of thine, from that which thou departest;   and that fresh blood which youngly thou bestow’st,   thou mayst call thine when thou from youth convertest,   herein lives wisdom, beauty, and increase;   without this folly, age, and cold decay:   if all were minded so, the times should cease   and threescore year would make the world away.   let those whom nature hath not made for store,   harsh, featureless, and rude, barrenly perish:   look, whom she best endow’d, she gave thee more;   which bounteous gift thou shouldst in bounty cherish:   she carv’d thee for her seal, and meant thereby,   thou shouldst print more, not let that copy die..   when i do count the clock that tells the time,   and see the brave day sunk in hideous night;   when i behold the violet past prime,   and sable curls, all silvered o’er with white;   when lofty trees i see barren of leaves,   which erst from heat did canopy the herd,   and summer’s green all girded up in sheaves,   borne on the bier with white and bristly beard,   then of thy beauty do i question make,   that thou among the wastes of time must go,   since sweets and beauties do themselves forsake   and die as fast as they see others grow;   and nothing ’gainst time’s scythe can make defence   save breed, to brave him when he takes thee hence..   o! that you were your self; but, love you are   no longer yours, than you yourself here live:   against this coming end you should prepare,   and your sweet semblance to some other give:   so should that beauty which you hold in lease   find no determination; then you were   yourself again, after yourself’s decease,   when your sweet issue your sweet form should bear.   who lets so fair a house fall to decay,   which husbandry in honour might uphold,   against the stormy gusts of winter’s day   and barren rage of death’s eternal cold?   o! none but unthrifts. dear my love, you know,   you had a father: let your son say so..   not from the stars do i my judgement pluck;   and yet methinks i have astronomy,   but not to tell of good or evil luck,   of plagues, of dearths, or seasons’ quality;   nor can i fortune to brief minutes tell,   pointing to each his thunder, rain and wind,   or say with princes if it shall go well   by oft predict that i in heaven find:   but from thine eyes my knowledge i derive,   and constant stars in them i read such art   as ‘truth and beauty shall together thrive,   if from thyself, to store thou wouldst convert’;   or else of thee this i prognosticate:   ‘thy end is truth’s and beauty’s doom and date.’.   when i consider every thing that grows   holds in perfection but a little moment,   that this huge stage presenteth nought but shows   whereon the stars in secret influence comment;   when i perceive that men as plants increase,   cheered and checked even by the self-same sky,   vaunt in their youthful sap, at height decrease,   and wear their brave state out of memory;   then the conceit of this inconstant stay   sets you most rich in youth before my sight,   where wasteful time debateth with decay   to change your day of youth to sullied night,   and all in war with time for love of you,   as he takes from you, i engraft you new..   but wherefore do not you a mightier way   make war upon this bloody tyrant, time?   and fortify yourself in your decay   with means more blessed than my barren rhyme?   now stand you on the top of happy hours,   and many maiden gardens, yet unset,   with virtuous wish would bear you living flowers,   much liker than your painted counterfeit:   so should the lines of life that life repair,   which this, time’s pencil, or my pupil pen,   neither in inward worth nor outward fair,   can make you live yourself in eyes of men.   to give away yourself, keeps yourself still,   and you must live, drawn by your own sweet skill..   who will believe my verse in time to come,   if it were fill’d with your most high deserts?   though yet heaven knows it is but as a tomb   which hides your life, and shows not half your parts.   if i could write the beauty of your eyes,   and in fresh numbers number all your graces,   the age to come would say ‘this poet lies;   such heavenly touches ne’er touch’d earthly faces.’   so should my papers, yellow’d with their age,   be scorn’d, like old men of less truth than tongue,   and your true rights be term’d a poet’s rage   and stretched metre of an antique song:   but were some child of yours alive that time,   you should live twice,--in it, and in my rhyme..   shall i compare thee to a summer’s day?   thou art more lovely and more temperate:   rough winds do shake the darling buds of may,   and summer’s lease hath all too short a date:   sometime too hot the eye of heaven shines,   and often is his gold complexion dimm’d,   and every fair from fair sometime declines,   by chance, or nature’s changing course untrimm’d:   but thy eternal summer shall not fade,   nor lose possession of that fair thou ow’st,   nor shall death brag thou wander’st in his shade,   when in eternal lines to time thou grow’st,   so long as men can breathe, or eyes can see,   so long lives this, and this gives life to thee..   devouring time, blunt thou the lion’s paws,   and make the earth devour her own sweet brood;   pluck the keen teeth from the fierce tiger’s jaws,   and burn the long-liv’d phoenix, in her blood;   make glad and sorry seasons as thou fleets,   and do whate’er thou wilt, swift-footed time,   to the wide world and all her fading sweets;   but i forbid thee one most heinous crime:   o! carve not with thy hours my love’s fair brow,   nor draw no lines there with thine antique pen;   him in thy course untainted do allow   for beauty’s pattern to succeeding men.   yet, do thy worst old time: despite thy wrong,   my love shall in my verse ever live young..   a woman’s face with nature’s own hand painted,   hast thou, the master mistress of my passion;   a woman’s gentle heart, but not acquainted   with shifting change, as is false women’s fashion:   an eye more bright than theirs, less false in rolling,   gilding the object whereupon it gazeth;   a man in hue all ‘hues’ in his controlling,   which steals men’s eyes and women’s souls amazeth.   and for a woman wert thou first created;   till nature, as she wrought thee, fell a-doting,   and by addition me of thee defeated,   by adding one thing to my purpose nothing.   but since she prick’d thee out for women’s pleasure,   mine be thy love and thy love’s use their treasure..   so is it not with me as with that muse,   stirr’d by a painted beauty to his verse,   who heaven itself for ornament doth use   and every fair with his fair doth rehearse,   making a couplement of proud compare.   with sun and moon, with earth and sea’s rich gems,   with april’s first-born flowers, and all things rare,   that heaven’s air in this huge rondure hems.   o! let me, true in love, but truly write,   and then believe me, my love is as fair   as any mother’s child, though not so bright   as those gold candles fix’d in heaven’s air:   let them say more that like of hearsay well;   i will not praise that purpose not to sell..   my glass shall not persuade me i am old,   so long as youth and thou are of one date;   but when in thee time’s furrows i behold,   then look i death my days should expiate.   for all that beauty that doth cover thee,   is but the seemly raiment of my heart,   which in thy breast doth live, as thine in me:   how can i then be elder than thou art?   o! therefore love, be of thyself so wary   as i, not for myself, but for thee will;   bearing thy heart, which i will keep so chary   as tender nurse her babe from faring ill.   presume not on thy heart when mine is slain,   thou gav’st me thine not to give back again..   as an unperfect actor on the stage,   who with his fear is put beside his part,   or some fierce thing replete with too much rage,   whose strength’s abundance weakens his own heart;   so i, for fear of trust, forget to say   the perfect ceremony of love’s rite,   and in mine own love’s strength seem to decay,   o’ercharg’d with burthen of mine own love’s might.   o! let my looks be then the eloquence   and dumb presagers of my speaking breast,   who plead for love, and look for recompense,   more than that tongue that more hath more express’d.   o! learn to read what silent love hath writ:   to hear with eyes belongs to love’s fine wit..   mine eye hath play’d the painter and hath stell’d,   thy beauty’s form in table of my heart;   my body is the frame wherein ’tis held,   and perspective it is best painter’s art.   for through the painter must you see his skill,   to find where your true image pictur’d lies,   which in my bosom’s shop is hanging still,   that hath his windows glazed with thine eyes.   now see what good turns eyes for eyes have done:   mine eyes have drawn thy shape, and thine for me   are windows to my breast, where-through the sun   delights to peep, to gaze therein on thee;   yet eyes this cunning want to grace their art,   they draw but what they see, know not the heart..   let those who are in favour with their stars   of public honour and proud titles boast,   whilst i, whom fortune of such triumph bars   unlook’d for joy in that i honour most.   great princes’ favourites their fair leaves spread   but as the marigold at the sun’s eye,   and in themselves their pride lies buried,   for at a frown they in their glory die.   the painful warrior famoused for fight,   after a thousand victories once foil’d,   is from the book of honour razed quite,   and all the rest forgot for which he toil’d:   then happy i, that love and am belov’d,   where i may not remove nor be remov’d..   lord of my love, to whom in vassalage   thy merit hath my duty strongly knit,   to thee i send this written embassage,   to witness duty, not to show my wit:   duty so great, which wit so poor as mine   may make seem bare, in wanting words to show it,   but that i hope some good conceit of thine   in thy soul’s thought, all naked, will bestow it:   till whatsoever star that guides my moving,   points on me graciously with fair aspect,   and puts apparel on my tatter’d loving,   to show me worthy of thy sweet respect:   then may i dare to boast how i do love thee;   till then, not show my head where thou mayst prove me..   weary with toil, i haste me to my bed,   the dear respose for limbs with travel tir’d;   but then begins a journey in my head   to work my mind, when body’s work’s expired:   for then my thoughts--from far where i abide--   intend a zealous pilgrimage to thee,   and keep my drooping eyelids open wide,   looking on darkness which the blind do see:   save that my soul’s imaginary sight   presents thy shadow to my sightless view,   which, like a jewel hung in ghastly night,   makes black night beauteous, and her old face new.   lo! thus, by day my limbs, by night my mind,   for thee, and for myself, no quiet find..   how can i then return in happy plight,   that am debarre’d the benefit of rest?   when day’s oppression is not eas’d by night,   but day by night and night by day oppress’d,   and each, though enemies to either’s reign,   do in consent shake hands to torture me,   the one by toil, the other to complain   how far i toil, still farther off from thee.   i tell the day, to please him thou art bright,   and dost him grace when clouds do blot the heaven:   so flatter i the swart-complexion’d night,   when sparkling stars twire not thou gild’st the even.   but day doth daily draw my sorrows longer,   and night doth nightly make grief’s length seem stronger..   when in disgrace with fortune and men’s eyes   i all alone beweep my outcast state,   and trouble deaf heaven with my bootless cries,   and look upon myself, and curse my fate,   wishing me like to one more rich in hope,   featur’d like him, like him with friends possess’d,   desiring this man’s art, and that man’s scope,   with what i most enjoy contented least;   yet in these thoughts my self almost despising,   haply i think on thee,-- and then my state,   like to the lark at break of day arising   from sullen earth, sings hymns at heaven’s gate;   for thy sweet love remember’d such wealth brings   that then i scorn to change my state with kings..   when to the sessions of sweet silent thought   i summon up remembrance of things past,   i sigh the lack of many a thing i sought,   and with old woes new wail my dear time’s waste:   then can i drown an eye, unused to flow,   for precious friends hid in death’s dateless night,   and weep afresh love’s long since cancell’d woe,   and moan the expense of many a vanish’d sight:   then can i grieve at grievances foregone,   and heavily from woe to woe tell o’er   the sad account of fore-bemoaned moan,   which i new pay as if not paid before.   but if the while i think on thee, dear friend,   all losses are restor’d and sorrows end..   thy bosom is endeared with all hearts,   which i by lacking have supposed dead;   and there reigns love, and all love’s loving parts,   and all those friends which i thought buried.   how many a holy and obsequious tear   hath dear religious love stol’n from mine eye,   as interest of the dead, which now appear   but things remov’d that hidden in thee lie!   thou art the grave where buried love doth live,   hung with the trophies of my lovers gone,   who all their parts of me to thee did give,   that due of many now is thine alone:   their images i lov’d, i view in thee,   and thou--all they--hast all the all of me..   if thou survive my well-contented day,   when that churl death my bones with dust shall cover   and shalt by fortune once more re-survey   these poor rude lines of thy deceased lover,   compare them with the bett’ring of the time,   and though they be outstripp’d by every pen,   reserve them for my love, not for their rhyme,   exceeded by the height of happier men.   o! then vouchsafe me but this loving thought:   ‘had my friend’s muse grown with this growing age,   a dearer birth than this his love had brought,   to march in ranks of better equipage:   but since he died and poets better prove,   theirs for their style i’ll read, his for his love’..   full many a glorious morning have i seen   flatter the mountain tops with sovereign eye,   kissing with golden face the meadows green,   gilding pale streams with heavenly alchemy;   anon permit the basest clouds to ride   with ugly rack on his celestial face,   and from the forlorn world his visage hide,   stealing unseen to west with this disgrace:   even so my sun one early morn did shine,   with all triumphant splendour on my brow;   but out! alack! he was but one hour mine,   the region cloud hath mask’d him from me now.   yet him for this my love no whit disdaineth;   suns of the world may stain when heaven’s sun staineth..   why didst thou promise such a beauteous day,   and make me travel forth without my cloak,   to let base clouds o’ertake me in my way,   hiding thy bravery in their rotten smoke?   ’tis not enough that through the cloud thou break,   to dry the rain on my storm-beaten face,   for no man well of such a salve can speak,   that heals the wound, and cures not the disgrace:   nor can thy shame give physic to my grief;   though thou repent, yet i have still the loss:   the offender’s sorrow lends but weak relief   to him that bears the strong offence’s cross.   ah! but those tears are pearl which thy love sheds,   and they are rich and ransom all ill deeds..   no more be griev’d at that which thou hast done:   roses have thorns, and silver fountains mud:   clouds and eclipses stain both moon and sun,   and loathsome canker lives in sweetest bud.   all men make faults, and even i in this,   authorizing thy trespass with compare,   myself corrupting, salving thy amiss,   excusing thy sins more than thy sins are;   for to thy sensual fault i bring in sense,--   thy adverse party is thy advocate,--   and ’gainst myself a lawful plea commence:   such civil war is in my love and hate,   that i an accessary needs must be,   to that sweet thief which sourly robs from me..   let me confess that we two must be twain,   although our undivided loves are one:   so shall those blots that do with me remain,   without thy help, by me be borne alone.   in our two loves there is but one respect,   though in our lives a separable spite,   which though it alter not love’s sole effect,   yet doth it steal sweet hours from love’s delight.   i may not evermore acknowledge thee,   lest my bewailed guilt should do thee shame,   nor thou with public kindness honour me,   unless thou take that honour from thy name:   but do not so, i love thee in such sort,   as thou being mine, mine is thy good report..   as a decrepit father takes delight   to see his active child do deeds of youth,   so i, made lame by fortune’s dearest spite,   take all my comfort of thy worth and truth;   for whether beauty, birth, or wealth, or wit,   or any of these all, or all, or more,   entitled in thy parts, do crowned sit,   i make my love engrafted, to this store:   so then i am not lame, poor, nor despis’d,   whilst that this shadow doth such substance give   that i in thy abundance am suffic’d,   and by a part of all thy glory live.   look what is best, that best i wish in thee:   this wish i have; then ten times happy me!.   how can my muse want subject to invent,   while thou dost breathe, that pour’st into my verse   thine own sweet argument, too excellent   for every vulgar paper to rehearse?   o! give thyself the thanks, if aught in me   worthy perusal stand against thy sight;   for who’s so dumb that cannot write to thee,   when thou thyself dost give invention light?   be thou the tenth muse, ten times more in worth   than those old nine which rhymers invocate;   and he that calls on thee, let him bring forth   eternal numbers to outlive long date.   if my slight muse do please these curious days,   the pain be mine, but thine shall be the praise..   o! how thy worth with manners may i sing,   when thou art all the better part of me?   what can mine own praise to mine own self bring?   and what is’t but mine own when i praise thee?   even for this, let us divided live,   and our dear love lose name of single one,   that by this separation i may give   that due to thee which thou deserv’st alone.   o absence! what a torment wouldst thou prove,   were it not thy sour leisure gave sweet leave,   to entertain the time with thoughts of love,   which time and thoughts so sweetly doth deceive,   and that thou teachest how to make one twain,   by praising him here who doth hence remain..   take all my loves, my love, yea take them all;   what hast thou then more than thou hadst before?   no love, my love, that thou mayst true love call;   all mine was thine, before thou hadst this more.   then, if for my love, thou my love receivest,   i cannot blame thee, for my love thou usest;   but yet be blam’d, if thou thyself deceivest   by wilful taste of what thyself refusest.   i do forgive thy robbery, gentle thief,   although thou steal thee all my poverty:   and yet, love knows it is a greater grief   to bear love’s wrong, than hate’s known injury.   lascivious grace, in whom all ill well shows,   kill me with spites yet we must not be foes..   those pretty wrongs that liberty commits,   when i am sometime absent from thy heart,   thy beauty, and thy years full well befits,   for still temptation follows where thou art.   gentle thou art, and therefore to be won,   beauteous thou art, therefore to be assail’d;   and when a woman woos, what woman’s son   will sourly leave her till he have prevail’d?   ay me! but yet thou mightst my seat forbear,   and chide thy beauty and thy straying youth,   who lead thee in their riot even there   where thou art forced to break a twofold truth:--   hers by thy beauty tempting her to thee,   thine by thy beauty being false to me..   that thou hast her it is not all my grief,   and yet it may be said i loved her dearly;   that she hath thee is of my wailing chief,   a loss in love that touches me more nearly.   loving offenders thus i will excuse ye:   thou dost love her, because thou know’st i love her;   and for my sake even so doth she abuse me,   suffering my friend for my sake to approve her.   if i lose thee, my loss is my love’s gain,   and losing her, my friend hath found that loss;   both find each other, and i lose both twain,   and both for my sake lay on me this cross:   but here’s the joy; my friend and i are one;   sweet flattery! then she loves but me alone..   when most i wink, then do mine eyes best see,   for all the day they view things unrespected;   but when i sleep, in dreams they look on thee,   and darkly bright, are bright in dark directed.   then thou, whose shadow shadows doth make bright,   how would thy shadow’s form form happy show   to the clear day with thy much clearer light,   when to unseeing eyes thy shade shines so!   how would, i say, mine eyes be blessed made   by looking on thee in the living day,   when in dead night thy fair imperfect shade   through heavy sleep on sightless eyes doth stay!   all days are nights to see till i see thee,   and nights bright days when dreams do show thee me..   if the dull substance of my flesh were thought,   injurious distance should not stop my way;   for then despite of space i would be brought,   from limits far remote, where thou dost stay.   no matter then although my foot did stand   upon the farthest earth remov’d from thee;   for nimble thought can jump both sea and land,   as soon as think the place where he would be.   but, ah! thought kills me that i am not thought,   to leap large lengths of miles when thou art gone,   but that so much of earth and water wrought,   i must attend time’s leisure with my moan;   receiving nought by elements so slow   but heavy tears, badges of either’s woe..   the other two, slight air, and purging fire   are both with thee, wherever i abide;   the first my thought, the other my desire,   these present-absent with swift motion slide.   for when these quicker elements are gone   in tender embassy of love to thee,   my life, being made of four, with two alone   sinks down to death, oppress’d with melancholy;   until life’s composition be recur’d   by those swift messengers return’d from thee,   who even but now come back again, assur’d,   of thy fair health, recounting it to me:   this told, i joy; but then no longer glad,   i send them back again, and straight grow sad..   mine eye and heart are at a mortal war,   how to divide the conquest of thy sight;   mine eye my heart thy picture’s sight would bar,   my heart mine eye the freedom of that right.   my heart doth plead that thou in him dost lie,--   a closet never pierc’d with crystal eyes--   but the defendant doth that plea deny,   and says in him thy fair appearance lies.   to side this title is impannelled   a quest of thoughts, all tenants to the heart;   and by their verdict is determined   the clear eye’s moiety, and the dear heart’s part:   as thus; mine eye’s due is thy outward part,   and my heart’s right, thy inward love of heart..   betwixt mine eye and heart a league is took,   and each doth good turns now unto the other:   when that mine eye is famish’d for a look,   or heart in love with sighs himself doth smother,   with my love’s picture then my eye doth feast,   and to the painted banquet bids my heart;   another time mine eye is my heart’s guest,   and in his thoughts of love doth share a part:   so, either by thy picture or my love,   thyself away, art present still with me;   for thou not farther than my thoughts canst move,   and i am still with them, and they with thee;   or, if they sleep, thy picture in my sight   awakes my heart, to heart’s and eye’s delight..   how careful was i when i took my way,   each trifle under truest bars to thrust,   that to my use it might unused stay   from hands of falsehood, in sure wards of trust!   but thou, to whom my jewels trifles are,   most worthy comfort, now my greatest grief,   thou best of dearest, and mine only care,   art left the prey of every vulgar thief.   thee have i not lock’d up in any chest,   save where thou art not, though i feel thou art,   within the gentle closure of my breast,   from whence at pleasure thou mayst come and part;   and even thence thou wilt be stol’n i fear,   for truth proves thievish for a prize so dear..   against that time, if ever that time come,   when i shall see thee frown on my defects,   when as thy love hath cast his utmost sum,   call’d to that audit by advis’d respects;   against that time when thou shalt strangely pass,   and scarcely greet me with that sun, thine eye,   when love, converted from the thing it was,   shall reasons find of settled gravity;   against that time do i ensconce me here,   within the knowledge of mine own desert,   and this my hand, against my self uprear,   to guard the lawful reasons on thy part:   to leave poor me thou hast the strength of laws,   since why to love i can allege no cause..   how heavy do i journey on the way,   when what i seek, my weary travel’s end,   doth teach that ease and that repose to say,   ‘thus far the miles are measured from thy friend!’   the beast that bears me, tired with my woe,   plods dully on, to bear that weight in me,   as if by some instinct the wretch did know   his rider lov’d not speed, being made from thee:   the bloody spur cannot provoke him on,   that sometimes anger thrusts into his hide,   which heavily he answers with a groan,   more sharp to me than spurring to his side;   for that same groan doth put this in my mind,   my grief lies onward, and my joy behind..   thus can my love excuse the slow offence   of my dull bearer when from thee i speed:   from where thou art why should i haste me thence?   till i return, of posting is no need.   o! what excuse will my poor beast then find,   when swift extremity can seem but slow?   then should i spur, though mounted on the wind,   in winged speed no motion shall i know,   then can no horse with my desire keep pace;   therefore desire, of perfect’st love being made,   shall neigh--no dull flesh--in his fiery race;   but love, for love, thus shall excuse my jade,--   ‘since from thee going, he went wilful-slow,   towards thee i’ll run, and give him leave to go.’.   so am i as the rich, whose blessed key,   can bring him to his sweet up-locked treasure,   the which he will not every hour survey,   for blunting the fine point of seldom pleasure.   therefore are feasts so solemn and so rare,   since, seldom coming in that long year set,   like stones of worth they thinly placed are,   or captain jewels in the carcanet.   so is the time that keeps you as my chest,   or as the wardrobe which the robe doth hide,   to make some special instant special-blest,   by new unfolding his imprison’d pride.   blessed are you whose worthiness gives scope,   being had, to triumph; being lacked, to hope..   what is your substance, whereof are you made,   that millions of strange shadows on you tend?   since every one, hath every one, one shade,   and you but one, can every shadow lend.   describe adonis, and the counterfeit   is poorly imitated after you;   on helen’s cheek all art of beauty set,   and you in grecian tires are painted new:   speak of the spring, and foison of the year,   the one doth shadow of your beauty show,   the other as your bounty doth appear;   and you in every blessed shape we know.   in all external grace you have some part,   but you like none, none you, for constant heart..   o! how much more doth beauty beauteous seem   by that sweet ornament which truth doth give.   the rose looks fair, but fairer we it deem   for that sweet odour, which doth in it live.   the canker blooms have full as deep a dye   as the perfumed tincture of the roses.   hang on such thorns, and play as wantonly   when summer’s breath their masked buds discloses:   but, for their virtue only is their show,   they live unwoo’d, and unrespected fade;   die to themselves. sweet roses do not so;   of their sweet deaths, are sweetest odours made:   and so of you, beauteous and lovely youth,   when that shall vade, by verse distills your truth..   not marble, nor the gilded monuments   of princes, shall outlive this powerful rhyme;   but you shall shine more bright in these contents   than unswept stone, besmear’d with sluttish time.   when wasteful war shall statues overturn,   and broils root out the work of masonry,   nor mars his sword, nor war’s quick fire shall burn   the living record of your memory.   ’gainst death, and all-oblivious enmity   shall you pace forth; your praise shall still find room   even in the eyes of all posterity   that wear this world out to the ending doom.   so, till the judgment that yourself arise,   you live in this, and dwell in lovers’ eyes..   sweet love, renew thy force; be it not said   thy edge should blunter be than appetite,   which but to-day by feeding is allay’d,   to-morrow sharpened in his former might:   so, love, be thou, although to-day thou fill   thy hungry eyes, even till they wink with fulness,   to-morrow see again, and do not kill   the spirit of love, with a perpetual dulness.   let this sad interim like the ocean be   which parts the shore, where two contracted new   come daily to the banks, that when they see   return of love, more blest may be the view;   or call it winter, which being full of care,   makes summer’s welcome, thrice more wished, more rare..   being your slave what should i do but tend,   upon the hours, and times of your desire?   i have no precious time at all to spend;   nor services to do, till you require.   nor dare i chide the world-without-end hour,   whilst i, my sovereign, watch the clock for you,   nor think the bitterness of absence sour,   when you have bid your servant once adieu;   nor dare i question with my jealous thought   where you may be, or your affairs suppose,   but, like a sad slave, stay and think of nought   save, where you are, how happy you make those.   so true a fool is love, that in your will,   though you do anything, he thinks no ill..   that god forbid, that made me first your slave,   i should in thought control your times of pleasure,   or at your hand the account of hours to crave,   being your vassal, bound to stay your leisure!   o! let me suffer, being at your beck,   the imprison’d absence of your liberty;   and patience, tame to sufferance, bide each check,   without accusing you of injury.   be where you list, your charter is so strong   that you yourself may privilage your time   to what you will; to you it doth belong   yourself to pardon of self-doing crime.   i am to wait, though waiting so be hell,   not blame your pleasure be it ill or well..   if there be nothing new, but that which is   hath been before, how are our brains beguil’d,   which labouring for invention bear amiss   the second burthen of a former child!   o! that record could with a backward look,   even of five hundred courses of the sun,   show me your image in some antique book,   since mind at first in character was done!   that i might see what the old world could say   to this composed wonder of your frame;   wh’r we are mended, or wh’r better they,   or whether revolution be the same.   o! sure i am the wits of former days,   to subjects worse have given admiring praise..   like as the waves make towards the pebbled shore,   so do our minutes hasten to their end;   each changing place with that which goes before,   in sequent toil all forwards do contend.   nativity, once in the main of light,   crawls to maturity, wherewith being crown’d,   crooked eclipses ’gainst his glory fight,   and time that gave doth now his gift confound.   time doth transfix the flourish set on youth   and delves the parallels in beauty’s brow,   feeds on the rarities of nature’s truth,   and nothing stands but for his scythe to mow:   and yet to times in hope, my verse shall stand.   praising thy worth, despite his cruel hand..   is it thy will, thy image should keep open   my heavy eyelids to the weary night?   dost thou desire my slumbers should be broken,   while shadows like to thee do mock my sight?   is it thy spirit that thou send’st from thee   so far from home into my deeds to pry,   to find out shames and idle hours in me,   the scope and tenure of thy jealousy?   o, no! thy love, though much, is not so great:   it is my love that keeps mine eye awake:   mine own true love that doth my rest defeat,   to play the watchman ever for thy sake:   for thee watch i, whilst thou dost wake elsewhere,   from me far off, with others all too near..   sin of self-love possesseth all mine eye   and all my soul, and all my every part;   and for this sin there is no remedy,   it is so grounded inward in my heart.   methinks no face so gracious is as mine,   no shape so true, no truth of such account;   and for myself mine own worth do define,   as i all other in all worths surmount.   but when my glass shows me myself indeed   beated and chopp’d with tanned antiquity,   mine own self-love quite contrary i read;   self so self-loving were iniquity.   ’tis thee,--myself,--that for myself i praise,   painting my age with beauty of thy days..   against my love shall be as i am now,   with time’s injurious hand crush’d and o’erworn;   when hours have drain’d his blood and fill’d his brow   with lines and wrinkles; when his youthful morn   hath travell’d on to age’s steepy night;   and all those beauties whereof now he’s king   are vanishing, or vanished out of sight,   stealing away the treasure of his spring;   for such a time do i now fortify   against confounding age’s cruel knife,   that he shall never cut from memory   my sweet love’s beauty, though my lover’s life:   his beauty shall in these black lines be seen,   and they shall live, and he in them still green..   when i have seen by time’s fell hand defac’d   the rich-proud cost of outworn buried age;   when sometime lofty towers i see down-raz’d,   and brass eternal slave to mortal rage;   when i have seen the hungry ocean gain   advantage on the kingdom of the shore,   and the firm soil win of the watery main,   increasing store with loss, and loss with store;   when i have seen such interchange of state,   or state itself confounded, to decay;   ruin hath taught me thus to ruminate--   that time will come and take my love away.   this thought is as a death which cannot choose   but weep to have, that which it fears to lose..   since brass, nor stone, nor earth, nor boundless sea,   but sad mortality o’ersways their power,   how with this rage shall beauty hold a plea,   whose action is no stronger than a flower?   o! how shall summer’s honey breath hold out,   against the wrackful siege of battering days,   when rocks impregnable are not so stout,   nor gates of steel so strong but time decays?   o fearful meditation! where, alack,   shall time’s best jewel from time’s chest lie hid?   or what strong hand can hold his swift foot back?   or who his spoil of beauty can forbid?   o! none, unless this miracle have might,   that in black ink my love may still shine bright..   tired with all these, for restful death i cry,   as to behold desert a beggar born,   and needy nothing trimm’d in jollity,   and purest faith unhappily forsworn,   and gilded honour shamefully misplac’d,   and maiden virtue rudely strumpeted,   and right perfection wrongfully disgrac’d,   and strength by limping sway disabled   and art made tongue-tied by authority,   and folly--doctor-like--controlling skill,   and simple truth miscall’d simplicity,   and captive good attending captain ill:   tir’d with all these, from these would i be gone,   save that, to die, i leave my love alone..   ah! wherefore with infection should he live,   and with his presence grace impiety,   that sin by him advantage should achieve,   and lace itself with his society?   why should false painting imitate his cheek,   and steel dead seeming of his living hue?   why should poor beauty indirectly seek   roses of shadow, since his rose is true?   why should he live, now nature bankrupt is,   beggar’d of blood to blush through lively veins?   for she hath no exchequer now but his,   and proud of many, lives upon his gains.   o! him she stores, to show what wealth she had   in days long since, before these last so bad..   thus is his cheek the map of days outworn,   when beauty lived and died as flowers do now,   before these bastard signs of fair were born,   or durst inhabit on a living brow;   before the golden tresses of the dead,   the right of sepulchres, were shorn away,   to live a second life on second head;   ere beauty’s dead fleece made another gay:   in him those holy antique hours are seen,   without all ornament, itself and true,   making no summer of another’s green,   robbing no old to dress his beauty new;   and him as for a map doth nature store,   to show false art what beauty was of yore..   those parts of thee that the world’s eye doth view   want nothing that the thought of hearts can mend;   all tongues--the voice of souls--give thee that due,   uttering bare truth, even so as foes commend.   thy outward thus with outward praise is crown’d;   but those same tongues, that give thee so thine own,   in other accents do this praise confound   by seeing farther than the eye hath shown.   they look into the beauty of thy mind,   and that in guess they measure by thy deeds;   then--churls--their thoughts, although their eyes were kind,   to thy fair flower add the rank smell of weeds:   but why thy odour matcheth not thy show,   the soil is this, that thou dost common grow..   that thou art blam’d shall not be thy defect,   for slander’s mark was ever yet the fair;   the ornament of beauty is suspect,   a crow that flies in heaven’s sweetest air.   so thou be good, slander doth but approve   thy worth the greater being woo’d of time;   for canker vice the sweetest buds doth love,   and thou present’st a pure unstained prime.   thou hast passed by the ambush of young days   either not assail’d, or victor being charg’d;   yet this thy praise cannot be so thy praise,   to tie up envy, evermore enlarg’d,   if some suspect of ill mask’d not thy show,   then thou alone kingdoms of hearts shouldst owe..   no longer mourn for me when i am dead   than you shall hear the surly sullen bell   give warning to the world that i am fled   from this vile world with vilest worms to dwell:   nay, if you read this line, remember not   the hand that writ it, for i love you so,   that i in your sweet thoughts would be forgot,   if thinking on me then should make you woe.   o! if,--i say you look upon this verse,   when i perhaps compounded am with clay,   do not so much as my poor name rehearse;   but let your love even with my life decay;   lest the wise world should look into your moan,   and mock you with me after i am gone..   o! lest the world should task you to recite   what merit lived in me, that you should love   after my death,--dear love, forget me quite,   for you in me can nothing worthy prove;   unless you would devise some virtuous lie,   to do more for me than mine own desert,   and hang more praise upon deceased i   than niggard truth would willingly impart:   o! lest your true love may seem false in this   that you for love speak well of me untrue,   my name be buried where my body is,   and live no more to shame nor me nor you.   for i am shamed by that which i bring forth,   and so should you, to love things nothing worth..   that time of year thou mayst in me behold   when yellow leaves, or none, or few, do hang   upon those boughs which shake against the cold,   bare ruin’d choirs, where late the sweet birds sang.   in me thou see’st the twilight of such day   as after sunset fadeth in the west;   which by and by black night doth take away,   death’s second self, that seals up all in rest.   in me thou see’st the glowing of such fire,   that on the ashes of his youth doth lie,   as the death-bed, whereon it must expire,   consum’d with that which it was nourish’d by.   this thou perceiv’st, which makes thy love more strong,   to love that well, which thou must leave ere long..   but be contented: when that fell arrest   without all bail shall carry me away,   my life hath in this line some interest,   which for memorial still with thee shall stay.   when thou reviewest this, thou dost review   the very part was consecrate to thee:   the earth can have but earth, which is his due;   my spirit is thine, the better part of me:   so then thou hast but lost the dregs of life,   the prey of worms, my body being dead;   the coward conquest of a wretch’s knife,   too base of thee to be remembered.   the worth of that is that which it contains,   and that is this, and this with thee remains..   so are you to my thoughts as food to life,   or as sweet-season’d showers are to the ground;   and for the peace of you i hold such strife   as ’twixt a miser and his wealth is found.   now proud as an enjoyer, and anon   doubting the filching age will steal his treasure;   now counting best to be with you alone,   then better’d that the world may see my pleasure:   sometime all full with feasting on your sight,   and by and by clean starved for a look;   possessing or pursuing no delight,   save what is had, or must from you be took.   thus do i pine and surfeit day by day,   or gluttoning on all, or all away..   why is my verse so barren of new pride,   so far from variation or quick change?   why with the time do i not glance aside   to new-found methods, and to compounds strange?   why write i still all one, ever the same,   and keep invention in a noted weed,   that every word doth almost tell my name,   showing their birth, and where they did proceed?   o! know sweet love i always write of you,   and you and love are still my argument;   so all my best is dressing old words new,   spending again what is already spent:   for as the sun is daily new and old,   so is my love still telling what is told..   thy glass will show thee how thy beauties wear,   thy dial how thy precious minutes waste;   these vacant leaves thy mind’s imprint will bear,   and of this book, this learning mayst thou taste.   the wrinkles which thy glass will truly show   of mouthed graves will give thee memory;   thou by thy dial’s shady stealth mayst know   time’s thievish progress to eternity.   look! what thy memory cannot contain,   commit to these waste blanks, and thou shalt find   those children nursed, deliver’d from thy brain,   to take a new acquaintance of thy mind.   these offices, so oft as thou wilt look,   shall profit thee and much enrich thy book..   so oft have i invoked thee for my muse,   and found such fair assistance in my verse   as every alien pen hath got my use   and under thee their poesy disperse.   thine eyes, that taught the dumb on high to sing   and heavy ignorance aloft to fly,   have added feathers to the learned’s wing   and given grace a double majesty.   yet be most proud of that which i compile,   whose influence is thine, and born of thee:   in others’ works thou dost but mend the style,   and arts with thy sweet graces graced be;   but thou art all my art, and dost advance   as high as learning, my rude ignorance..   whilst i alone did call upon thy aid,   my verse alone had all thy gentle grace;   but now my gracious numbers are decay’d,   and my sick muse doth give an other place.   i grant, sweet love, thy lovely argument   deserves the travail of a worthier pen;   yet what of thee thy poet doth invent   he robs thee of, and pays it thee again.   he lends thee virtue, and he stole that word   from thy behaviour; beauty doth he give,   and found it in thy cheek: he can afford   no praise to thee, but what in thee doth live.   then thank him not for that which he doth say,   since what he owes thee, thou thyself dost pay..   o! how i faint when i of you do write,   knowing a better spirit doth use your name,   and in the praise thereof spends all his might,   to make me tongue-tied speaking of your fame!   but since your worth--wide as the ocean is,--   the humble as the proudest sail doth bear,   my saucy bark, inferior far to his,   on your broad main doth wilfully appear.   your shallowest help will hold me up afloat,   whilst he upon your soundless deep doth ride;   or, being wrack’d, i am a worthless boat,   he of tall building, and of goodly pride:   then if he thrive and i be cast away,   the worst was this,--my love was my decay..   or i shall live your epitaph to make,   or you survive when i in earth am rotten;   from hence your memory death cannot take,   although in me each part will be forgotten.   your name from hence immortal life shall have,   though i, once gone, to all the world must die:   the earth can yield me but a common grave,   when you entombed in men’s eyes shall lie.   your monument shall be my gentle verse,   which eyes not yet created shall o’er-read;   and tongues to be, your being shall rehearse,   when all the breathers of this world are dead;   you still shall live,--such virtue hath my pen,--   where breath most breathes, even in the mouths of men..   i grant thou wert not married to my muse,   and therefore mayst without attaint o’erlook   the dedicated words which writers use   of their fair subject, blessing every book.   thou art as fair in knowledge as in hue,   finding thy worth a limit past my praise;   and therefore art enforced to seek anew   some fresher stamp of the time-bettering days.   and do so, love; yet when they have devis’d,   what strained touches rhetoric can lend,   thou truly fair, wert truly sympathiz’d   in true plain words, by thy true-telling friend;   and their gross painting might be better us’d   where cheeks need blood; in thee it is abus’d..   i never saw that you did painting need,   and therefore to your fair no painting set;   i found, or thought i found, you did exceed   that barren tender of a poet’s debt:   and therefore have i slept in your report,   that you yourself, being extant, well might show   how far a modern quill doth come too short,   speaking of worth, what worth in you doth grow.   this silence for my sin you did impute,   which shall be most my glory being dumb;   for i impair not beauty being mute,   when others would give life, and bring a tomb.   there lives more life in one of your fair eyes   than both your poets can in praise devise..   who is it that says most, which can say more,   than this rich praise,--that you alone, are you?   in whose confine immured is the store   which should example where your equal grew.   lean penury within that pen doth dwell   that to his subject lends not some small glory;   but he that writes of you, if he can tell   that you are you, so dignifies his story,   let him but copy what in you is writ,   not making worse what nature made so clear,   and such a counterpart shall fame his wit,   making his style admired every where.   you to your beauteous blessings add a curse,   being fond on praise, which makes your praises worse..   my tongue-tied muse in manners holds her still,   while comments of your praise richly compil’d,   reserve their character with golden quill,   and precious phrase by all the muses fil’d.   i think good thoughts, whilst others write good words,   and like unlettered clerk still cry ‘amen’   to every hymn that able spirit affords,   in polish’d form of well-refined pen.   hearing you praised, i say ‘’tis so, ’tis true,’   and to the most of praise add something more;   but that is in my thought, whose love to you,   though words come hindmost, holds his rank before.   then others, for the breath of words respect,   me for my dumb thoughts, speaking in effect..   was it the proud full sail of his great verse,   bound for the prize of all too precious you,   that did my ripe thoughts in my brain inhearse,   making their tomb the womb wherein they grew?   was it his spirit, by spirits taught to write,   above a mortal pitch, that struck me dead?   no, neither he, nor his compeers by night   giving him aid, my verse astonished.   he, nor that affable familiar ghost   which nightly gulls him with intelligence,   as victors of my silence cannot boast;   i was not sick of any fear from thence:   but when your countenance fill’d up his line,   then lacked i matter; that enfeebled mine..   farewell! thou art too dear for my possessing,   and like enough thou know’st thy estimate,   the charter of thy worth gives thee releasing;   my bonds in thee are all determinate.   for how do i hold thee but by thy granting?   and for that riches where is my deserving?   the cause of this fair gift in me is wanting,   and so my patent back again is swerving.   thyself thou gav’st, thy own worth then not knowing,   or me to whom thou gav’st it, else mistaking;   so thy great gift, upon misprision growing,   comes home again, on better judgement making.   thus have i had thee, as a dream doth flatter,   in sleep a king, but waking no such matter..   when thou shalt be dispos’d to set me light,   and place my merit in the eye of scorn,   upon thy side, against myself i’ll fight,   and prove thee virtuous, though thou art forsworn.   with mine own weakness, being best acquainted,   upon thy part i can set down a story   of faults conceal’d, wherein i am attainted;   that thou in losing me shalt win much glory:   and i by this will be a gainer too;   for bending all my loving thoughts on thee,   the injuries that to myself i do,   doing thee vantage, double-vantage me.   such is my love, to thee i so belong,   that for thy right, myself will bear all wrong..   say that thou didst forsake me for some fault,   and i will comment upon that offence:   speak of my lameness, and i straight will halt,   against thy reasons making no defence.   thou canst not love disgrace me half so ill,   to set a form upon desired change,   as i’ll myself disgrace; knowing thy will,   i will acquaintance strangle, and look strange;   be absent from thy walks; and in my tongue   thy sweet beloved name no more shall dwell,   lest i, too much profane, should do it wrong,   and haply of our old acquaintance tell.   for thee, against my self i’ll vow debate,   for i must ne’er love him whom thou dost hate..   then hate me when thou wilt; if ever, now;   now, while the world is bent my deeds to cross,   join with the spite of fortune, make me bow,   and do not drop in for an after-loss:   ah! do not, when my heart hath ’scap’d this sorrow,   come in the rearward of a conquer’d woe;   give not a windy night a rainy morrow,   to linger out a purpos’d overthrow.   if thou wilt leave me, do not leave me last,   when other petty griefs have done their spite,   but in the onset come: so shall i taste   at first the very worst of fortune’s might;   and other strains of woe, which now seem woe,   compar’d with loss of thee, will not seem so..   some glory in their birth, some in their skill,   some in their wealth, some in their body’s force,   some in their garments though new-fangled ill;   some in their hawks and hounds, some in their horse;   and every humour hath his adjunct pleasure,   wherein it finds a joy above the rest:   but these particulars are not my measure,   all these i better in one general best.   thy love is better than high birth to me,   richer than wealth, prouder than garments’ costs,   of more delight than hawks and horses be;   and having thee, of all men’s pride i boast:   wretched in this alone, that thou mayst take   all this away, and me most wretchcd make..   but do thy worst to steal thyself away,   for term of life thou art assured mine;   and life no longer than thy love will stay,   for it depends upon that love of thine.   then need i not to fear the worst of wrongs,   when in the least of them my life hath end.   i see a better state to me belongs   than that which on thy humour doth depend:   thou canst not vex me with inconstant mind,   since that my life on thy revolt doth lie.   o! what a happy title do i find,   happy to have thy love, happy to die!   but what’s so blessed-fair that fears no blot?   thou mayst be false, and yet i know it not..   so shall i live, supposing thou art true,   like a deceived husband; so love’s face   may still seem love to me, though alter’d new;   thy looks with me, thy heart in other place:   for there can live no hatred in thine eye,   therefore in that i cannot know thy change.   in many’s looks, the false heart’s history   is writ in moods, and frowns, and wrinkles strange.   but heaven in thy creation did decree   that in thy face sweet love should ever dwell;   whate’er thy thoughts, or thy heart’s workings be,   thy looks should nothing thence, but sweetness tell.   how like eve’s apple doth thy beauty grow,   if thy sweet virtue answer not thy show!.   they that have power to hurt, and will do none,   that do not do the thing they most do show,   who, moving others, are themselves as stone,   unmoved, cold, and to temptation slow;   they rightly do inherit heaven’s graces,   and husband nature’s riches from expense;   they are the lords and owners of their faces,   others, but stewards of their excellence.   the summer’s flower is to the summer sweet,   though to itself, it only live and die,   but if that flower with base infection meet,   the basest weed outbraves his dignity:   for sweetest things turn sourest by their deeds;   lilies that fester, smell far worse than weeds..   how sweet and lovely dost thou make the shame   which, like a canker in the fragrant rose,   doth spot the beauty of thy budding name!   o! in what sweets dost thou thy sins enclose.   that tongue that tells the story of thy days,   making lascivious comments on thy sport,   cannot dispraise, but in a kind of praise;   naming thy name, blesses an ill report.   o! what a mansion have those vices got   which for their habitation chose out thee,   where beauty’s veil doth cover every blot   and all things turns to fair that eyes can see!   take heed, dear heart, of this large privilege;   the hardest knife ill-us’d doth lose his edge..   some say thy fault is youth, some wantonness;   some say thy grace is youth and gentle sport;   both grace and faults are lov’d of more and less:   thou mak’st faults graces that to thee resort.   as on the finger of a throned queen   the basest jewel will be well esteem’d,   so are those errors that in thee are seen   to truths translated, and for true things deem’d.   how many lambs might the stern wolf betray,   if like a lamb he could his looks translate!   how many gazers mightst thou lead away,   if thou wouldst use the strength of all thy state!   but do not so; i love thee in such sort,   as, thou being mine, mine is thy good report..   how like a winter hath my absence been   from thee, the pleasure of the fleeting year!   what freezings have i felt, what dark days seen!   what old december’s bareness everywhere!   and yet this time removed was summer’s time;   the teeming autumn, big with rich increase,   bearing the wanton burden of the prime,   like widow’d wombs after their lords’ decease:   yet this abundant issue seem’d to me   but hope of orphans, and unfather’d fruit;   for summer and his pleasures wait on thee,   and, thou away, the very birds are mute:   or, if they sing, ’tis with so dull a cheer,   that leaves look pale, dreading the winter’s near..   from you have i been absent in the spring,   when proud-pied april, dress’d in all his trim,   hath put a spirit of youth in every thing,   that heavy saturn laugh’d and leap’d with him.   yet nor the lays of birds, nor the sweet smell   of different flowers in odour and in hue,   could make me any summer’s story tell,   or from their proud lap pluck them where they grew:   nor did i wonder at the lily’s white,   nor praise the deep vermilion in the rose;   they were but sweet, but figures of delight,   drawn after you, you pattern of all those.   yet seem’d it winter still, and you away,   as with your shadow i with these did play..   the forward violet thus did i chide:   sweet thief, whence didst thou steal thy sweet that smells,   if not from my love’s breath? the purple pride   which on thy soft cheek for complexion dwells   in my love’s veins thou hast too grossly dy’d.   the lily i condemned for thy hand,   and buds of marjoram had stol’n thy hair;   the roses fearfully on thorns did stand,   one blushing shame, another white despair;   a third, nor red nor white, had stol’n of both,   and to his robbery had annex’d thy breath;   but, for his theft, in pride of all his growth   a vengeful canker eat him up to death.   more flowers i noted, yet i none could see,   but sweet, or colour it had stol’n from thee..   where art thou muse that thou forget’st so long,   to speak of that which gives thee all thy might?   spend’st thou thy fury on some worthless song,   darkening thy power to lend base subjects light?   return forgetful muse, and straight redeem,   in gentle numbers time so idly spent;   sing to the ear that doth thy lays esteem   and gives thy pen both skill and argument.   rise, resty muse, my love’s sweet face survey,   if time have any wrinkle graven there;   if any, be a satire to decay,   and make time’s spoils despised every where.   give my love fame faster than time wastes life,   so thou prevent’st his scythe and crooked knife..   o truant muse what shall be thy amends   for thy neglect of truth in beauty dy’d?   both truth and beauty on my love depends;   so dost thou too, and therein dignified.   make answer muse: wilt thou not haply say,   ‘truth needs no colour, with his colour fix’d;   beauty no pencil, beauty’s truth to lay;   but best is best, if never intermix’d’?   because he needs no praise, wilt thou be dumb?   excuse not silence so, for’t lies in thee   to make him much outlive a gilded tomb   and to be prais’d of ages yet to be.   then do thy office, muse; i teach thee how   to make him seem long hence as he shows now..   my love is strengthen’d, though more weak in seeming;   i love not less, though less the show appear;   that love is merchandiz’d, whose rich esteeming,   the owner’s tongue doth publish every where.   our love was new, and then but in the spring,   when i was wont to greet it with my lays;   as philomel in summer’s front doth sing,   and stops her pipe in growth of riper days:   not that the summer is less pleasant now   than when her mournful hymns did hush the night,   but that wild music burthens every bough,   and sweets grown common lose their dear delight.   therefore like her, i sometime hold my tongue:   because i would not dull you with my song..   alack! what poverty my muse brings forth,   that having such a scope to show her pride,   the argument, all bare, is of more worth   than when it hath my added praise beside!   o! blame me not, if i no more can write!   look in your glass, and there appears a face   that over-goes my blunt invention quite,   dulling my lines, and doing me disgrace.   were it not sinful then, striving to mend,   to mar the subject that before was well?   for to no other pass my verses tend   than of your graces and your gifts to tell;   and more, much more, than in my verse can sit,   your own glass shows you when you look in it..   to me, fair friend, you never can be old,   for as you were when first your eye i ey’d,   such seems your beauty still. three winters cold,   have from the forests shook three summers’ pride,   three beauteous springs to yellow autumn turn’d,   in process of the seasons have i seen,   three april perfumes in three hot junes burn’d,   since first i saw you fresh, which yet are green.   ah! yet doth beauty like a dial-hand,   steal from his figure, and no pace perceiv’d;   so your sweet hue, which methinks still doth stand,   hath motion, and mine eye may be deceiv’d:   for fear of which, hear this thou age unbred:   ere you were born was beauty’s summer dead..   let not my love be call’d idolatry,   nor my beloved as an idol show,   since all alike my songs and praises be   to one, of one, still such, and ever so.   kind is my love to-day, to-morrow kind,   still constant in a wondrous excellence;   therefore my verse to constancy confin’d,   one thing expressing, leaves out difference.   ‘fair, kind, and true,’ is all my argument,   ‘fair, kind, and true,’ varying to other words;   and in this change is my invention spent,   three themes in one, which wondrous scope affords.   fair, kind, and true, have often liv’d alone,   which three till now, never kept seat in one..   when in the chronicle of wasted time   i see descriptions of the fairest wights,   and beauty making beautiful old rime,   in praise of ladies dead and lovely knights,   then, in the blazon of sweet beauty’s best,   of hand, of foot, of lip, of eye, of brow,   i see their antique pen would have express’d   even such a beauty as you master now.   so all their praises are but prophecies   of this our time, all you prefiguring;   and for they looked but with divining eyes,   they had not skill enough your worth to sing:   for we, which now behold these present days,   have eyes to wonder, but lack tongues to praise..   not mine own fears, nor the prophetic soul   of the wide world dreaming on things to come,   can yet the lease of my true love control,   supposed as forfeit to a confin’d doom.   the mortal moon hath her eclipse endur’d,   and the sad augurs mock their own presage;   incertainties now crown themselves assur’d,   and peace proclaims olives of endless age.   now with the drops of this most balmy time,   my love looks fresh, and death to me subscribes,   since, spite of him, i’ll live in this poor rime,   while he insults o’er dull and speechless tribes:   and thou in this shalt find thy monument,   when tyrants’ crests and tombs of brass are spent..   what’s in the brain, that ink may character,   which hath not figur’d to thee my true spirit?   what’s new to speak, what now to register,   that may express my love, or thy dear merit?   nothing, sweet boy; but yet, like prayers divine,   i must each day say o’er the very same;   counting no old thing old, thou mine, i thine,   even as when first i hallow’d thy fair name.   so that eternal love in love’s fresh case,   weighs not the dust and injury of age,   nor gives to necessary wrinkles place,   but makes antiquity for aye his page;   finding the first conceit of love there bred,   where time and outward form would show it dead..   o! never say that i was false of heart,   though absence seem’d my flame to qualify,   as easy might i from my self depart   as from my soul which in thy breast doth lie:   that is my home of love: if i have rang’d,   like him that travels, i return again;   just to the time, not with the time exchang’d,   so that myself bring water for my stain.   never believe though in my nature reign’d,   all frailties that besiege all kinds of blood,   that it could so preposterously be stain’d,   to leave for nothing all thy sum of good;   for nothing this wide universe i call,   save thou, my rose, in it thou art my all..   alas! ’tis true, i have gone here and there,   and made my self a motley to the view,   gor’d mine own thoughts, sold cheap what is most dear,   made old offences of affections new;   most true it is, that i have look’d on truth   askance and strangely; but, by all above,   these blenches gave my heart another youth,   and worse essays prov’d thee my best of love.   now all is done, save what shall have no end:   mine appetite i never more will grind   on newer proof, to try an older friend,   a god in love, to whom i am confin’d.   then give me welcome, next my heaven the best,   even to thy pure and most most loving breast..   o! for my sake do you with fortune chide,   the guilty goddess of my harmful deeds,   that did not better for my life provide   than public means which public manners breeds.   thence comes it that my name receives a brand,   and almost thence my nature is subdu’d   to what it works in, like the dyer’s hand:   pity me, then, and wish i were renew’d;   whilst, like a willing patient, i will drink,   potions of eisel ’gainst my strong infection;   no bitterness that i will bitter think,   nor double penance, to correct correction.   pity me then, dear friend, and i assure ye,   even that your pity is enough to cure me..   your love and pity doth the impression fill,   which vulgar scandal stamp’d upon my brow;   for what care i who calls me well or ill,   so you o’er-green my bad, my good allow?   you are my all-the-world, and i must strive   to know my shames and praises from your tongue;   none else to me, nor i to none alive,   that my steel’d sense or changes right or wrong.   in so profound abysm i throw all care   of others’ voices, that my adder’s sense   to critic and to flatterer stopped are.   mark how with my neglect i do dispense:   you are so strongly in my purpose bred,   that all the world besides methinks are dead..   since i left you, mine eye is in my mind;   and that which governs me to go about   doth part his function and is partly blind,   seems seeing, but effectually is out;   for it no form delivers to the heart   of bird, of flower, or shape which it doth latch:   of his quick objects hath the mind no part,   nor his own vision holds what it doth catch;   for if it see the rud’st or gentlest sight,   the most sweet favour or deformed’st creature,   the mountain or the sea, the day or night:   the crow, or dove, it shapes them to your feature.   incapable of more, replete with you,   my most true mind thus maketh mine untrue..   or whether doth my mind, being crown’d with you,   drink up the monarch’s plague, this flattery?   or whether shall i say, mine eye saith true,   and that your love taught it this alchemy,   to make of monsters and things indigest   such cherubins as your sweet self resemble,   creating every bad a perfect best,   as fast as objects to his beams assemble?   o! ’tis the first, ’tis flattery in my seeing,   and my great mind most kingly drinks it up:   mine eye well knows what with his gust is ’greeing,   and to his palate doth prepare the cup:   if it be poison’d, ’tis the lesser sin   that mine eye loves it and doth first begin..   those lines that i before have writ do lie,   even those that said i could not love you dearer:   yet then my judgment knew no reason why   my most full flame should afterwards burn clearer.   but reckoning time, whose million’d accidents   creep in ’twixt vows, and change decrees of kings,   tan sacred beauty, blunt the sharp’st intents,   divert strong minds to the course of altering things;   alas! why fearing of time’s tyranny,   might i not then say, ‘now i love you best,’   when i was certain o’er incertainty,   crowning the present, doubting of the rest?   love is a babe, then might i not say so,   to give full growth to that which still doth grow?.   let me not to the marriage of true minds   admit impediments. love is not love   which alters when it alteration finds,   or bends with the remover to remove:   o, no! it is an ever-fixed mark,   that looks on tempests and is never shaken;   it is the star to every wandering bark,   whose worth’s unknown, although his height be taken.   love’s not time’s fool, though rosy lips and cheeks   within his bending sickle’s compass come;   love alters not with his brief hours and weeks,   but bears it out even to the edge of doom.   if this be error and upon me prov’d,   i never writ, nor no man ever lov’d..   accuse me thus: that i have scanted all,   wherein i should your great deserts repay,   forgot upon your dearest love to call,   whereto all bonds do tie me day by day;   that i have frequent been with unknown minds,   and given to time your own dear-purchas’d right;   that i have hoisted sail to all the winds   which should transport me farthest from your sight.   book both my wilfulness and errors down,   and on just proof surmise, accumulate;   bring me within the level of your frown,   but shoot not at me in your waken’d hate;   since my appeal says i did strive to prove   the constancy and virtue of your love..   like as, to make our appetite more keen,   with eager compounds we our palate urge;   as, to prevent our maladies unseen,   we sicken to shun sickness when we purge;   even so, being full of your ne’er-cloying sweetness,   to bitter sauces did i frame my feeding;   and, sick of welfare, found a kind of meetness   to be diseas’d, ere that there was true needing.   thus policy in love, to anticipate   the ills that were not, grew to faults assur’d,   and brought to medicine a healthful state   which, rank of goodness, would by ill be cur’d;   but thence i learn and find the lesson true,   drugs poison him that so fell sick of you..   what potions have i drunk of siren tears,   distill’d from limbecks foul as hell within,   applying fears to hopes, and hopes to fears,   still losing when i saw myself to win!   what wretched errors hath my heart committed,   whilst it hath thought itself so blessed never!   how have mine eyes out of their spheres been fitted,   in the distraction of this madding fever!   o benefit of ill! now i find true   that better is, by evil still made better;   and ruin’d love, when it is built anew,   grows fairer than at first, more strong, far greater.   so i return rebuk’d to my content,   and gain by ill thrice more than i have spent..   that you were once unkind befriends me now,   and for that sorrow, which i then did feel,   needs must i under my transgression bow,   unless my nerves were brass or hammer’d steel.   for if you were by my unkindness shaken,   as i by yours, you’ve pass’d a hell of time;   and i, a tyrant, have no leisure taken   to weigh how once i suffer’d in your crime.   o! that our night of woe might have remember’d   my deepest sense, how hard true sorrow hits,   and soon to you, as you to me, then tender’d   the humble salve, which wounded bosoms fits!   but that your trespass now becomes a fee;   mine ransoms yours, and yours must ransom me..   ’tis better to be vile than vile esteem’d,   when not to be receives reproach of being;   and the just pleasure lost, which is so deem’d   not by our feeling, but by others’ seeing:   for why should others’ false adulterate eyes   give salutation to my sportive blood?   or on my frailties why are frailer spies,   which in their wills count bad what i think good?   no, i am that i am, and they that level   at my abuses reckon up their own:   i may be straight though they themselves be bevel;   by their rank thoughts, my deeds must not be shown;   unless this general evil they maintain,   all men are bad and in their badness reign..   thy gift, thy tables, are within my brain   full character’d with lasting memory,   which shall above that idle rank remain,   beyond all date; even to eternity:   or, at the least, so long as brain and heart   have faculty by nature to subsist;   till each to raz’d oblivion yield his part   of thee, thy record never can be miss’d.   that poor retention could not so much hold,   nor need i tallies thy dear love to score;   therefore to give them from me was i bold,   to trust those tables that receive thee more:   to keep an adjunct to remember thee   were to import forgetfulness in me..   no, time, thou shalt not boast that i do change:   thy pyramids built up with newer might   to me are nothing novel, nothing strange;   they are but dressings of a former sight.   our dates are brief, and therefore we admire   what thou dost foist upon us that is old;   and rather make them born to our desire   than think that we before have heard them told.   thy registers and thee i both defy,   not wondering at the present nor the past,   for thy records and what we see doth lie,   made more or less by thy continual haste.   this i do vow and this shall ever be;   i will be true despite thy scythe and thee..   if my dear love were but the child of state,   it might for fortune’s bastard be unfather’d,   as subject to time’s love or to time’s hate,   weeds among weeds, or flowers with flowers gather’d.   no, it was builded far from accident;   it suffers not in smiling pomp, nor falls   under the blow of thralled discontent,   whereto th’ inviting time our fashion calls:   it fears not policy, that heretic,   which works on leases of short-number’d hours,   but all alone stands hugely politic,   that it nor grows with heat, nor drowns with showers.   to this i witness call the fools of time,   which die for goodness, who have lived for crime..   were’t aught to me i bore the canopy,   with my extern the outward honouring,   or laid great bases for eternity,   which proves more short than waste or ruining?   have i not seen dwellers on form and favour   lose all and more by paying too much rent   for compound sweet; forgoing simple savour,   pitiful thrivers, in their gazing spent?   no; let me be obsequious in thy heart,   and take thou my oblation, poor but free,   which is not mix’d with seconds, knows no art,   but mutual render, only me for thee.   hence, thou suborned informer! a true soul   when most impeach’d, stands least in thy control..   o thou, my lovely boy, who in thy power   dost hold time’s fickle glass, his fickle hour;   who hast by waning grown, and therein show’st   thy lovers withering, as thy sweet self grow’st.   if nature, sovereign mistress over wrack,   as thou goest onwards, still will pluck thee back,   she keeps thee to this purpose, that her skill   may time disgrace and wretched minutes kill.   yet fear her, o thou minion of her pleasure!   she may detain, but not still keep, her treasure:   her audit (though delayed) answered must be,   and her quietus is to render thee..   in the old age black was not counted fair,   or if it were, it bore not beauty’s name;   but now is black beauty’s successive heir,   and beauty slander’d with a bastard shame:   for since each hand hath put on nature’s power,   fairing the foul with art’s false borrowed face,   sweet beauty hath no name, no holy bower,   but is profan’d, if not lives in disgrace.   therefore my mistress’ eyes are raven black,   her eyes so suited, and they mourners seem   at such who, not born fair, no beauty lack,   sland’ring creation with a false esteem:   yet so they mourn becoming of their woe,   that every tongue says beauty should look so..   how oft when thou, my music, music play’st,   upon that blessed wood whose motion sounds   with thy sweet fingers when thou gently sway’st   the wiry concord that mine ear confounds,   do i envy those jacks that nimble leap,   to kiss the tender inward of thy hand,   whilst my poor lips which should that harvest reap,   at the wood’s boldness by thee blushing stand!   to be so tickled, they would change their state   and situation with those dancing chips,   o’er whom thy fingers walk with gentle gait,   making dead wood more bless’d than living lips.   since saucy jacks so happy are in this,   give them thy fingers, me thy lips to kiss..   the expense of spirit in a waste of shame   is lust in action: and till action, lust   is perjur’d, murderous, bloody, full of blame,   savage, extreme, rude, cruel, not to trust;   enjoy’d no sooner but despised straight;   past reason hunted; and no sooner had,   past reason hated, as a swallow’d bait,   on purpose laid to make the taker mad:   mad in pursuit and in possession so;   had, having, and in quest, to have extreme;   a bliss in proof,-- and prov’d, a very woe;   before, a joy propos’d; behind a dream.   all this the world well knows; yet none knows well   to shun the heaven that leads men to this hell..   my mistress’ eyes are nothing like the sun;   coral is far more red, than her lips red:   if snow be white, why then her breasts are dun;   if hairs be wires, black wires grow on her head.   i have seen roses damask’d, red and white,   but no such roses see i in her cheeks;   and in some perfumes is there more delight   than in the breath that from my mistress reeks.   i love to hear her speak, yet well i know   that music hath a far more pleasing sound:   i grant i never saw a goddess go,--   my mistress, when she walks, treads on the ground:   and yet by heaven, i think my love as rare,   as any she belied with false compare..   thou art as tyrannous, so as thou art,   as those whose beauties proudly make them cruel;   for well thou know’st to my dear doting heart   thou art the fairest and most precious jewel.   yet, in good faith, some say that thee behold,   thy face hath not the power to make love groan;   to say they err i dare not be so bold,   although i swear it to myself alone.   and to be sure that is not false i swear,   a thousand groans, but thinking on thy face,   one on another’s neck, do witness bear   thy black is fairest in my judgment’s place.   in nothing art thou black save in thy deeds,   and thence this slander, as i think, proceeds..   thine eyes i love, and they, as pitying me,   knowing thy heart torment me with disdain,   have put on black and loving mourners be,   looking with pretty ruth upon my pain.   and truly not the morning sun of heaven   better becomes the grey cheeks of the east,   nor that full star that ushers in the even,   doth half that glory to the sober west,   as those two mourning eyes become thy face:   o! let it then as well beseem thy heart   to mourn for me since mourning doth thee grace,   and suit thy pity like in every part.   then will i swear beauty herself is black,   and all they foul that thy complexion lack..   beshrew that heart that makes my heart to groan   for that deep wound it gives my friend and me!   is’t not enough to torture me alone,   but slave to slavery my sweet’st friend must be?   me from myself thy cruel eye hath taken,   and my next self thou harder hast engross’d:   of him, myself, and thee i am forsaken;   a torment thrice three-fold thus to be cross’d:   prison my heart in thy steel bosom’s ward,   but then my friend’s heart let my poor heart bail;   whoe’er keeps me, let my heart be his guard;   thou canst not then use rigour in my jail:   and yet thou wilt; for i, being pent in thee,   perforce am thine, and all that is in me..   so, now i have confess’d that he is thine,   and i my self am mortgag’d to thy will,   myself i’ll forfeit, so that other mine   thou wilt restore to be my comfort still:   but thou wilt not, nor he will not be free,   for thou art covetous, and he is kind;   he learn’d but surety-like to write for me,   under that bond that him as fast doth bind.   the statute of thy beauty thou wilt take,   thou usurer, that putt’st forth all to use,   and sue a friend came debtor for my sake;   so him i lose through my unkind abuse.   him have i lost; thou hast both him and me:   he pays the whole, and yet am i not free..   whoever hath her wish, thou hast thy ‘will,’   and ‘will’ to boot, and ‘will’ in over-plus;   more than enough am i that vex’d thee still,   to thy sweet will making addition thus.   wilt thou, whose will is large and spacious,   not once vouchsafe to hide my will in thine?   shall will in others seem right gracious,   and in my will no fair acceptance shine?   the sea, all water, yet receives rain still,   and in abundance addeth to his store;   so thou, being rich in ‘will,’ add to thy ‘will’   one will of mine, to make thy large will more.   let no unkind ‘no’ fair beseechers kill;   think all but one, and me in that one ‘will.’.   if thy soul check thee that i come so near,   swear to thy blind soul that i was thy ‘will’,   and will, thy soul knows, is admitted there;   thus far for love, my love-suit, sweet, fulfil.   ‘will’, will fulfil the treasure of thy love,   ay, fill it full with wills, and my will one.   in things of great receipt with ease we prove   among a number one is reckon’d none:   then in the number let me pass untold,   though in thy store’s account i one must be;   for nothing hold me, so it please thee hold   that nothing me, a something sweet to thee:   make but my name thy love, and love that still,   and then thou lov’st me for my name is ‘will.’.   thou blind fool, love, what dost thou to mine eyes,   that they behold, and see not what they see?   they know what beauty is, see where it lies,   yet what the best is take the worst to be.   if eyes, corrupt by over-partial looks,   be anchor’d in the bay where all men ride,   why of eyes’ falsehood hast thou forged hooks,   whereto the judgment of my heart is tied?   why should my heart think that a several plot,   which my heart knows the wide world’s common place?   or mine eyes, seeing this, say this is not,   to put fair truth upon so foul a face?   in things right true my heart and eyes have err’d,   and to this false plague are they now transferr’d..   when my love swears that she is made of truth,   i do believe her though i know she lies,   that she might think me some untutor’d youth,   unlearned in the world’s false subtleties.   thus vainly thinking that she thinks me young,   although she knows my days are past the best,   simply i credit her false-speaking tongue:   on both sides thus is simple truth suppressed:   but wherefore says she not she is unjust?   and wherefore say not i that i am old?   o! love’s best habit is in seeming trust,   and age in love, loves not to have years told:   therefore i lie with her, and she with me,   and in our faults by lies we flatter’d be..   o! call not me to justify the wrong   that thy unkindness lays upon my heart;   wound me not with thine eye, but with thy tongue:   use power with power, and slay me not by art,   tell me thou lov’st elsewhere; but in my sight,   dear heart, forbear to glance thine eye aside:   what need’st thou wound with cunning, when thy might   is more than my o’erpress’d defence can bide?   let me excuse thee: ah! my love well knows   her pretty looks have been mine enemies;   and therefore from my face she turns my foes,   that they elsewhere might dart their injuries:   yet do not so; but since i am near slain,   kill me outright with looks, and rid my pain..   be wise as thou art cruel; do not press   my tongue-tied patience with too much disdain;   lest sorrow lend me words, and words express   the manner of my pity-wanting pain.   if i might teach thee wit, better it were,   though not to love, yet, love to tell me so;--   as testy sick men, when their deaths be near,   no news but health from their physicians know;--   for, if i should despair, i should grow mad,   and in my madness might speak ill of thee;   now this ill-wresting world is grown so bad,   mad slanderers by mad ears believed be.   that i may not be so, nor thou belied,   bear thine eyes straight, though thy proud heart go wide..   in faith i do not love thee with mine eyes,   for they in thee a thousand errors note;   but ’tis my heart that loves what they despise,   who, in despite of view, is pleased to dote.   nor are mine ears with thy tongue’s tune delighted;   nor tender feeling, to base touches prone,   nor taste, nor smell, desire to be invited   to any sensual feast with thee alone:   but my five wits nor my five senses can   dissuade one foolish heart from serving thee,   who leaves unsway’d the likeness of a man,   thy proud heart’s slave and vassal wretch to be:   only my plague thus far i count my gain,   that she that makes me sin awards me pain..   love is my sin, and thy dear virtue hate,   hate of my sin, grounded on sinful loving:   o! but with mine compare thou thine own state,   and thou shalt find it merits not reproving;   or, if it do, not from those lips of thine,   that have profan’d their scarlet ornaments   and seal’d false bonds of love as oft as mine,   robb’d others’ beds’ revenues of their rents.   be it lawful i love thee, as thou lov’st those   whom thine eyes woo as mine importune thee:   root pity in thy heart, that, when it grows,   thy pity may deserve to pitied be.   if thou dost seek to have what thou dost hide,   by self-example mayst thou be denied!.   lo, as a careful housewife runs to catch   one of her feather’d creatures broke away,   sets down her babe, and makes all swift dispatch   in pursuit of the thing she would have stay;   whilst her neglected child holds her in chase,   cries to catch her whose busy care is bent   to follow that which flies before her face,   not prizing her poor infant’s discontent;   so runn’st thou after that which flies from thee,   whilst i thy babe chase thee afar behind;   but if thou catch thy hope, turn back to me,   and play the mother’s part, kiss me, be kind;   so will i pray that thou mayst have thy ‘will,’   if thou turn back and my loud crying still..   two loves i have of comfort and despair,   which like two spirits do suggest me still:   the better angel is a man right fair,   the worser spirit a woman colour’d ill.   to win me soon to hell, my female evil,   tempteth my better angel from my side,   and would corrupt my saint to be a devil,   wooing his purity with her foul pride.   and whether that my angel be turn’d fiend,   suspect i may, yet not directly tell;   but being both from me, both to each friend,   i guess one angel in another’s hell:   yet this shall i ne’er know, but live in doubt,   till my bad angel fire my good one out..   those lips that love’s own hand did make,   breathed forth the sound that said ‘i hate’,   to me that languish’d for her sake:   but when she saw my woeful state,   straight in her heart did mercy come,   chiding that tongue that ever sweet   was us’d in giving gentle doom;   and taught it thus anew to greet;   ‘i hate’ she alter’d with an end,   that followed it as gentle day,   doth follow night, who like a fiend   from heaven to hell is flown away.   ‘i hate’, from hate away she threw,   and sav’d my life, saying ‘not you’..   poor soul, the centre of my sinful earth,   my sinful earth these rebel powers array,   why dost thou pine within and suffer dearth,   painting thy outward walls so costly gay?   why so large cost, having so short a lease,   dost thou upon thy fading mansion spend?   shall worms, inheritors of this excess,   eat up thy charge? is this thy body’s end?   then soul, live thou upon thy servant’s loss,   and let that pine to aggravate thy store;   buy terms divine in selling hours of dross;   within be fed, without be rich no more:   so shall thou feed on death, that feeds on men,   and death once dead, there’s no more dying then..   my love is as a fever longing still,   for that which longer nurseth the disease;   feeding on that which doth preserve the ill,   the uncertain sickly appetite to please.   my reason, the physician to my love,   angry that his prescriptions are not kept,   hath left me, and i desperate now approve   desire is death, which physic did except.   past cure i am, now reason is past care,   and frantic-mad with evermore unrest;   my thoughts and my discourse as madmen’s are,   at random from the truth vainly express’d;   for i have sworn thee fair, and thought thee bright,   who art as black as hell, as dark as night..   o me! what eyes hath love put in my head,   which have no correspondence with true sight;   or, if they have, where is my judgment fled,   that censures falsely what they see aright?   if that be fair whereon my false eyes dote,   what means the world to say it is not so?   if it be not, then love doth well denote   love’s eye is not so true as all men’s: no,   how can it? o! how can love’s eye be true,   that is so vexed with watching and with tears?   no marvel then, though i mistake my view;   the sun itself sees not, till heaven clears.   o cunning love! with tears thou keep’st me blind,   lest eyes well-seeing thy foul faults should find..   canst thou, o cruel! say i love thee not,   when i against myself with thee partake?   do i not think on thee, when i forgot   am of my self, all tyrant, for thy sake?   who hateth thee that i do call my friend,   on whom frown’st thou that i do fawn upon,   nay, if thou lour’st on me, do i not spend   revenge upon myself with present moan?   what merit do i in my self respect,   that is so proud thy service to despise,   when all my best doth worship thy defect,   commanded by the motion of thine eyes?   but, love, hate on, for now i know thy mind;   those that can see thou lov’st, and i am blind..   o! from what power hast thou this powerful might,   with insufficiency my heart to sway?   to make me give the lie to my true sight,   and swear that brightness doth not grace the day?   whence hast thou this becoming of things ill,   that in the very refuse of thy deeds   there is such strength and warrantise of skill,   that, in my mind, thy worst all best exceeds?   who taught thee how to make me love thee more,   the more i hear and see just cause of hate?   o! though i love what others do abhor,   with others thou shouldst not abhor my state:   if thy unworthiness rais’d love in me,   more worthy i to be belov’d of thee..   love is too young to know what conscience is,   yet who knows not conscience is born of love?   then, gentle cheater, urge not my amiss,   lest guilty of my faults thy sweet self prove:   for, thou betraying me, i do betray   my nobler part to my gross body’s treason;   my soul doth tell my body that he may   triumph in love; flesh stays no farther reason,   but rising at thy name doth point out thee,   as his triumphant prize. proud of this pride,   he is contented thy poor drudge to be,   to stand in thy affairs, fall by thy side.   no want of conscience hold it that i call   her ‘love,’ for whose dear love i rise and fall..   in loving thee thou know’st i am forsworn,   but thou art twice forsworn, to me love swearing;   in act thy bed-vow broke, and new faith torn,   in vowing new hate after new love bearing:   but why of two oaths’ breach do i accuse thee,   when i break twenty? i am perjur’d most;   for all my vows are oaths but to misuse thee,   and all my honest faith in thee is lost:   for i have sworn deep oaths of thy deep kindness,   oaths of thy love, thy truth, thy constancy;   and, to enlighten thee, gave eyes to blindness,   or made them swear against the thing they see;   for i have sworn thee fair; more perjur’d i,   to swear against the truth so foul a lie!.   cupid laid by his brand and fell asleep:   a maid of dian’s this advantage found,   and his love-kindling fire did quickly steep   in a cold valley-fountain of that ground;   which borrow’d from this holy fire of love,   a dateless lively heat, still to endure,   and grew a seeting bath, which yet men prove   against strange maladies a sovereign cure.   but at my mistress’ eye love’s brand new-fired,   the boy for trial needs would touch my breast;   i, sick withal, the help of bath desired,   and thither hied, a sad distemper’d guest,   but found no cure, the bath for my help lies   where cupid got new fire; my mistress’ eyes..   the little love-god lying once asleep,   laid by his side his heart-inflaming brand,   whilst many nymphs that vow’d chaste life to keep   came tripping by; but in her maiden hand   the fairest votary took up that fire   which many legions of true hearts had warm’d;   and so the general of hot desire   was, sleeping, by a virgin hand disarm’d.   this brand she quenched in a cool well by,   which from love’s fire took heat perpetual,   growing a bath and healthful remedy,   for men diseas’d; but i, my mistress’ thrall,   came there for cure and this by that i prove,   love’s fire heats water, water cools not love..'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Concatenamos todos los rows en un solo valor\n",
        "corpus = df.apply(lambda row: ' '.join(row.values.astype(str)), axis=0)[0]\n",
        "corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KlsYd7_uOez",
        "outputId": "39508f88-13c6-4857-d809-d11c17f38512"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['from',\n",
              " 'fairest',\n",
              " 'creatures',\n",
              " 'we',\n",
              " 'desire',\n",
              " 'increase',\n",
              " 'that',\n",
              " 'thereby',\n",
              " 'beauty’s',\n",
              " 'rose',\n",
              " 'might',\n",
              " 'never',\n",
              " 'die',\n",
              " 'but',\n",
              " 'as',\n",
              " 'the',\n",
              " 'riper',\n",
              " 'should',\n",
              " 'by',\n",
              " 'time']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# Transformar el corpus a tokens\n",
        "tokens=text_to_word_sequence(corpus)\n",
        "# Vistazo general de los primeros tokens\n",
        "tokens[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlqpZSJOJ1xQ",
        "outputId": "84497725-917f-47e6-9788-737e77f7d9d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de tokens en el corpus: 17620\n"
          ]
        }
      ],
      "source": [
        "print(\"Cantidad de tokens en el corpus:\", len(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhQevOynuYk2"
      },
      "outputs": [],
      "source": [
        "# Código para hacer el desfazaje de las palabras\n",
        "# según el train_len\n",
        "text_sequences = []\n",
        "for i in range(train_len, len(tokens)):\n",
        "  seq = tokens[i-train_len:i]\n",
        "  text_sequences.append(seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FU3FuqHSuhzq",
        "outputId": "6151ecf2-cf5e-4c88-a0ac-8febec3b490e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['from', 'fairest', 'creatures', 'we'],\n",
              " ['fairest', 'creatures', 'we', 'desire'],\n",
              " ['creatures', 'we', 'desire', 'increase'],\n",
              " ['we', 'desire', 'increase', 'that'],\n",
              " ['desire', 'increase', 'that', 'thereby'],\n",
              " ['increase', 'that', 'thereby', 'beauty’s'],\n",
              " ['that', 'thereby', 'beauty’s', 'rose'],\n",
              " ['thereby', 'beauty’s', 'rose', 'might'],\n",
              " ['beauty’s', 'rose', 'might', 'never'],\n",
              " ['rose', 'might', 'never', 'die'],\n",
              " ['might', 'never', 'die', 'but'],\n",
              " ['never', 'die', 'but', 'as'],\n",
              " ['die', 'but', 'as', 'the'],\n",
              " ['but', 'as', 'the', 'riper'],\n",
              " ['as', 'the', 'riper', 'should'],\n",
              " ['the', 'riper', 'should', 'by'],\n",
              " ['riper', 'should', 'by', 'time'],\n",
              " ['should', 'by', 'time', 'decease'],\n",
              " ['by', 'time', 'decease', 'his'],\n",
              " ['time', 'decease', 'his', 'tender']]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# Demos un vistazo a nuestros vectores para entrenar el modelo\n",
        "text_sequences[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "064N2jtLvHRg",
        "outputId": "624e4b0f-b9f1-4d41-dc88-9ebd6897260b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[34, 511, 1374, 165],\n",
              " [511, 1374, 165, 214],\n",
              " [1374, 165, 214, 512],\n",
              " [165, 214, 512, 8],\n",
              " [214, 512, 8, 871],\n",
              " [512, 8, 871, 134],\n",
              " [8, 871, 134, 350],\n",
              " [871, 134, 350, 101],\n",
              " [134, 350, 101, 154],\n",
              " [350, 101, 154, 199],\n",
              " [101, 154, 199, 18],\n",
              " [154, 199, 18, 22],\n",
              " [199, 18, 22, 2],\n",
              " [18, 22, 2, 872],\n",
              " [22, 2, 872, 61],\n",
              " [2, 872, 61, 30],\n",
              " [872, 61, 30, 48],\n",
              " [61, 30, 48, 635],\n",
              " [30, 48, 635, 26],\n",
              " [48, 635, 26, 312]]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Proceso de tokenizacion\n",
        "tok = Tokenizer() \n",
        "tok.fit_on_texts(text_sequences) \n",
        "\n",
        "# Convertimos las palabras a números\n",
        "# entran palabras -> salen números\n",
        "sequences = tok.texts_to_sequences(text_sequences)\n",
        "\n",
        "# Damos un vistazo\n",
        "sequences[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwsvmvDKKXSP",
        "outputId": "869bd961-fd13-44a7-8c71-e68f314bd6ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de rows del dataset: 17616\n"
          ]
        }
      ],
      "source": [
        "print(\"Cantidad de rows del dataset:\", len(sequences))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMVP4bj0vL2e"
      },
      "source": [
        "### 3 - Input y target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1vJTG65v4Qn",
        "outputId": "306a7221-8b10-4473-ea9b-6358ee4f2389"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(17616, 3)\n",
            "(17616,)\n"
          ]
        }
      ],
      "source": [
        "arr_sequences = np.array(sequences)\n",
        "x_data = arr_sequences[:,:-1]\n",
        "y_data_int = arr_sequences[:,-1] # aún falta el oneHotEncoder\n",
        "\n",
        "print(x_data.shape)\n",
        "print(y_data_int.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ln6kVWVlwBBs",
        "outputId": "7a817b29-dd34-4645-f299-e378477b6add"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'and',\n",
              " 2: 'the',\n",
              " 3: 'to',\n",
              " 4: 'my',\n",
              " 5: 'of',\n",
              " 6: 'i',\n",
              " 7: 'in',\n",
              " 8: 'that',\n",
              " 9: 'thy',\n",
              " 10: 'thou',\n",
              " 11: 'with',\n",
              " 12: 'for',\n",
              " 13: 'is',\n",
              " 14: 'not',\n",
              " 15: 'love',\n",
              " 16: 'a',\n",
              " 17: 'me',\n",
              " 18: 'but',\n",
              " 19: 'thee',\n",
              " 20: 'so',\n",
              " 21: 'be',\n",
              " 22: 'as',\n",
              " 23: 'all',\n",
              " 24: 'you',\n",
              " 25: 'which',\n",
              " 26: 'his',\n",
              " 27: 'when',\n",
              " 28: 'it',\n",
              " 29: 'this',\n",
              " 30: 'by',\n",
              " 31: 'your',\n",
              " 32: 'doth',\n",
              " 33: 'do',\n",
              " 34: 'from',\n",
              " 35: 'on',\n",
              " 36: 'or',\n",
              " 37: 'no',\n",
              " 38: 'have',\n",
              " 39: 'then',\n",
              " 40: 'what',\n",
              " 41: 'are',\n",
              " 42: 'if',\n",
              " 43: 'more',\n",
              " 44: 'mine',\n",
              " 45: 'their',\n",
              " 46: 'shall',\n",
              " 47: 'sweet',\n",
              " 48: 'time',\n",
              " 49: 'will',\n",
              " 50: 'they',\n",
              " 51: 'eyes',\n",
              " 52: 'beauty',\n",
              " 53: 'nor',\n",
              " 54: 'art',\n",
              " 55: 'her',\n",
              " 56: 'yet',\n",
              " 57: 'heart',\n",
              " 58: 'o',\n",
              " 59: 'than',\n",
              " 60: 'now',\n",
              " 61: 'should',\n",
              " 62: 'thine',\n",
              " 63: 'can',\n",
              " 64: 'make',\n",
              " 65: 'he',\n",
              " 66: 'one',\n",
              " 67: 'hath',\n",
              " 68: 'where',\n",
              " 69: 'fair',\n",
              " 70: 'still',\n",
              " 71: 'how',\n",
              " 72: 'him',\n",
              " 73: 'true',\n",
              " 74: 'eye',\n",
              " 75: 'like',\n",
              " 76: 'see',\n",
              " 77: 'am',\n",
              " 78: 'she',\n",
              " 79: 'those',\n",
              " 80: 'though',\n",
              " 81: 'being',\n",
              " 82: 'some',\n",
              " 83: 'such',\n",
              " 84: 'own',\n",
              " 85: 'every',\n",
              " 86: 'self',\n",
              " 87: 'were',\n",
              " 88: 'dost',\n",
              " 89: 'who',\n",
              " 90: 'live',\n",
              " 91: 'upon',\n",
              " 92: 'was',\n",
              " 93: 'may',\n",
              " 94: 'world',\n",
              " 95: 'say',\n",
              " 96: 'praise',\n",
              " 97: 'day',\n",
              " 98: 'give',\n",
              " 99: 'most',\n",
              " 100: 'love’s',\n",
              " 101: 'might',\n",
              " 102: 'new',\n",
              " 103: 'did',\n",
              " 104: 'let',\n",
              " 105: 'well',\n",
              " 106: 'at',\n",
              " 107: 'why',\n",
              " 108: 'even',\n",
              " 109: 'show',\n",
              " 110: 'life',\n",
              " 111: 'best',\n",
              " 112: 'since',\n",
              " 113: 'old',\n",
              " 114: 'look',\n",
              " 115: 'night',\n",
              " 116: 'dear',\n",
              " 117: 'these',\n",
              " 118: 'thyself',\n",
              " 119: 'must',\n",
              " 120: 'would',\n",
              " 121: 'truth',\n",
              " 122: 'myself',\n",
              " 123: 'thus',\n",
              " 124: 'ill',\n",
              " 125: 'part',\n",
              " 126: 'worth',\n",
              " 127: 'made',\n",
              " 128: 'face',\n",
              " 129: 'whose',\n",
              " 130: 'nothing',\n",
              " 131: 'alone',\n",
              " 132: 'false',\n",
              " 133: 'better',\n",
              " 134: 'beauty’s',\n",
              " 135: 'too',\n",
              " 136: 'there',\n",
              " 137: 'hand',\n",
              " 138: 'thought',\n",
              " 139: 'away',\n",
              " 140: 'against',\n",
              " 141: 'thoughts',\n",
              " 142: 'our',\n",
              " 143: 'days',\n",
              " 144: 'an',\n",
              " 145: 'much',\n",
              " 146: 'up',\n",
              " 147: 'sight',\n",
              " 148: 'hast',\n",
              " 149: 'know',\n",
              " 150: 'them',\n",
              " 151: 'therefore',\n",
              " 152: 'both',\n",
              " 153: 'name',\n",
              " 154: 'never',\n",
              " 155: '’',\n",
              " 156: 'death',\n",
              " 157: 'mind',\n",
              " 158: 'time’s',\n",
              " 159: 'other',\n",
              " 160: 'find',\n",
              " 161: 'out',\n",
              " 162: 'muse',\n",
              " 163: 'far',\n",
              " 164: 'dead',\n",
              " 165: 'we',\n",
              " 166: 'tell',\n",
              " 167: 'age',\n",
              " 168: 'each',\n",
              " 169: 'youth',\n",
              " 170: 'had',\n",
              " 171: 'good',\n",
              " 172: 'men',\n",
              " 173: 'before',\n",
              " 174: 'verse',\n",
              " 175: 'come',\n",
              " 176: 'tongue',\n",
              " 177: 'poor',\n",
              " 178: 'think',\n",
              " 179: 'proud',\n",
              " 180: 'gentle',\n",
              " 181: 'wilt',\n",
              " 182: 'state',\n",
              " 183: 'till',\n",
              " 184: 'things',\n",
              " 185: 'friend',\n",
              " 186: 'use',\n",
              " 187: 'looks',\n",
              " 188: 'many',\n",
              " 189: 'none',\n",
              " 190: 'hate',\n",
              " 191: 'hold',\n",
              " 192: 'heaven',\n",
              " 193: 'first',\n",
              " 194: 'whilst',\n",
              " 195: 'black',\n",
              " 196: 'lie',\n",
              " 197: 'full',\n",
              " 198: 'take',\n",
              " 199: 'die',\n",
              " 200: 'bear',\n",
              " 201: 'making',\n",
              " 202: 'lies',\n",
              " 203: 'hours',\n",
              " 204: 'prove',\n",
              " 205: 'change',\n",
              " 206: 'kind',\n",
              " 207: 'mayst',\n",
              " 208: 'whom',\n",
              " 209: 'long',\n",
              " 210: 'earth',\n",
              " 211: 'ever',\n",
              " 212: 'seem',\n",
              " 213: 'woe',\n",
              " 214: 'desire',\n",
              " 215: 'bright',\n",
              " 216: 'within',\n",
              " 217: 'form',\n",
              " 218: 'shalt',\n",
              " 219: 'summer’s',\n",
              " 220: 'pleasure',\n",
              " 221: 'happy',\n",
              " 222: 'end',\n",
              " 223: 'others',\n",
              " 224: 'after',\n",
              " 225: 'thing',\n",
              " 226: 'rich',\n",
              " 227: 'knows',\n",
              " 228: 'sun',\n",
              " 229: '’tis',\n",
              " 230: 'grace',\n",
              " 231: 'pride',\n",
              " 232: 'seen',\n",
              " 233: 'shame',\n",
              " 234: 'glass',\n",
              " 235: 'great',\n",
              " 236: 'nature',\n",
              " 237: 'leave',\n",
              " 238: 'place',\n",
              " 239: 'could',\n",
              " 240: 'any',\n",
              " 241: 'call',\n",
              " 242: 'yourself',\n",
              " 243: 'again',\n",
              " 244: 'pen',\n",
              " 245: 'write',\n",
              " 246: 'once',\n",
              " 247: 'words',\n",
              " 248: 'loving',\n",
              " 249: 'deeds',\n",
              " 250: 'cannot',\n",
              " 251: 'found',\n",
              " 252: 'fire',\n",
              " 253: 'right',\n",
              " 254: 'spirit',\n",
              " 255: 'soul',\n",
              " 256: 'pity',\n",
              " 257: 'treasure',\n",
              " 258: 'another',\n",
              " 259: 'back',\n",
              " 260: 'beauteous',\n",
              " 261: 'gone',\n",
              " 262: 'lives',\n",
              " 263: 'o’er',\n",
              " 264: 'times',\n",
              " 265: 'strong',\n",
              " 266: 'keep',\n",
              " 267: 'without',\n",
              " 268: 'decay',\n",
              " 269: 'store',\n",
              " 270: 'past',\n",
              " 271: 'save',\n",
              " 272: 'stay',\n",
              " 273: 'lose',\n",
              " 274: 'loss',\n",
              " 275: 'two',\n",
              " 276: 'although',\n",
              " 277: 'power',\n",
              " 278: 'memory',\n",
              " 279: 'cruel',\n",
              " 280: 'brow',\n",
              " 281: 'deep',\n",
              " 282: 'child',\n",
              " 283: 'blood',\n",
              " 284: 'lovely',\n",
              " 285: 'gives',\n",
              " 286: 'summer',\n",
              " 287: 'leaves',\n",
              " 288: 'flowers',\n",
              " 289: 'joy',\n",
              " 290: 'fear',\n",
              " 291: 'grow',\n",
              " 292: 'blessed',\n",
              " 293: 'stand',\n",
              " 294: 'lines',\n",
              " 295: 'skill',\n",
              " 296: 'born',\n",
              " 297: 'glory',\n",
              " 298: 'view',\n",
              " 299: 'makes',\n",
              " 300: 'disgrace',\n",
              " 301: 'speak',\n",
              " 302: 'faults',\n",
              " 303: 'bring',\n",
              " 304: 'loves',\n",
              " 305: 'delight',\n",
              " 306: 'lest',\n",
              " 307: 'sake',\n",
              " 308: 'thence',\n",
              " 309: 'hell',\n",
              " 310: 'sin',\n",
              " 311: 'three',\n",
              " 312: 'tender',\n",
              " 313: 'fresh',\n",
              " 314: 'waste',\n",
              " 315: 'excuse',\n",
              " 316: 'cold',\n",
              " 317: 'through',\n",
              " 318: 'canst',\n",
              " 319: 'very',\n",
              " 320: 'same',\n",
              " 321: 'ten',\n",
              " 322: 'living',\n",
              " 323: 'parts',\n",
              " 324: 'sing',\n",
              " 325: 'ah',\n",
              " 326: 'behold',\n",
              " 327: 'white',\n",
              " 328: 'honour',\n",
              " 329: 'outward',\n",
              " 330: 'less',\n",
              " 331: 'wide',\n",
              " 332: 'worst',\n",
              " 333: 'itself',\n",
              " 334: 'breast',\n",
              " 335: 'put',\n",
              " 336: 'shadow',\n",
              " 337: 'sad',\n",
              " 338: 'i’ll',\n",
              " 339: 'forth',\n",
              " 340: 'roses',\n",
              " 341: 'straight',\n",
              " 342: 'heart’s',\n",
              " 343: 'set',\n",
              " 344: 'breath',\n",
              " 345: 'virtue',\n",
              " 346: 'bad',\n",
              " 347: 'lips',\n",
              " 348: 'foul',\n",
              " 349: 'swear',\n",
              " 350: 'rose',\n",
              " 351: 'only',\n",
              " 352: 'due',\n",
              " 353: 'despite',\n",
              " 354: 'nature’s',\n",
              " 355: 'having',\n",
              " 356: 'dwell',\n",
              " 357: 'ere',\n",
              " 358: 'shouldst',\n",
              " 359: 'light',\n",
              " 360: 'head',\n",
              " 361: 'under',\n",
              " 362: 'way',\n",
              " 363: 'unless',\n",
              " 364: 'music',\n",
              " 365: 'hear',\n",
              " 366: 'sweets',\n",
              " 367: 'war',\n",
              " 368: 'lov’st',\n",
              " 369: '’gainst',\n",
              " 370: 'green',\n",
              " 371: 'go',\n",
              " 372: 'themselves',\n",
              " 373: 'hence',\n",
              " 374: 'longer',\n",
              " 375: 'eternal',\n",
              " 376: 'fortune',\n",
              " 377: 'read',\n",
              " 378: 'shows',\n",
              " 379: 'compare',\n",
              " 380: 'sometime',\n",
              " 381: 'swift',\n",
              " 382: 'wrong',\n",
              " 383: 'heaven’s',\n",
              " 384: 'dumb',\n",
              " 385: 'writ',\n",
              " 386: 'wit',\n",
              " 387: 'book',\n",
              " 388: 'rest',\n",
              " 389: 'hope',\n",
              " 390: 'blind',\n",
              " 391: 'return',\n",
              " 392: 'wealth',\n",
              " 393: 'precious',\n",
              " 394: 'while',\n",
              " 395: 'enough',\n",
              " 396: 'steal',\n",
              " 397: 'argument',\n",
              " 398: 'heavy',\n",
              " 399: 'dull',\n",
              " 400: 'present',\n",
              " 401: 'side',\n",
              " 402: 'care',\n",
              " 403: 'strange',\n",
              " 404: 'slave',\n",
              " 405: 'been',\n",
              " 406: 'painting',\n",
              " 407: 'taught',\n",
              " 408: 'fears',\n",
              " 409: 'seeing',\n",
              " 410: 'spent',\n",
              " 411: 'sick',\n",
              " 412: 'reason',\n",
              " 413: 'mad',\n",
              " 414: 'world’s',\n",
              " 415: 'ornament',\n",
              " 416: 'spring',\n",
              " 417: 'else',\n",
              " 418: 'tomb',\n",
              " 419: 'calls',\n",
              " 420: 'wrinkles',\n",
              " 421: 'golden',\n",
              " 422: 'spend',\n",
              " 423: 'lend',\n",
              " 424: 'play',\n",
              " 425: 'winter',\n",
              " 426: 'quite',\n",
              " 427: 'left',\n",
              " 428: 'gracious',\n",
              " 429: 'mortal',\n",
              " 430: 'chide',\n",
              " 431: 'shape',\n",
              " 432: 'least',\n",
              " 433: 'fast',\n",
              " 434: 'year',\n",
              " 435: 'gave',\n",
              " 436: 'gift',\n",
              " 437: 'barren',\n",
              " 438: 'yours',\n",
              " 439: 'rage',\n",
              " 440: 'stars',\n",
              " 441: 'oft',\n",
              " 442: 'doom',\n",
              " 443: 'date',\n",
              " 444: 'holds',\n",
              " 445: 'wish',\n",
              " 446: 'painted',\n",
              " 447: 'keeps',\n",
              " 448: 'graces',\n",
              " 449: 'antique',\n",
              " 450: 'short',\n",
              " 451: 'man',\n",
              " 452: 'hue',\n",
              " 453: 'men’s',\n",
              " 454: 'fell',\n",
              " 455: 'purpose',\n",
              " 456: 'truly',\n",
              " 457: 'trust',\n",
              " 458: 'strength',\n",
              " 459: 'speaking',\n",
              " 460: 'wherein',\n",
              " 461: 'done',\n",
              " 462: 'boast',\n",
              " 463: 'buried',\n",
              " 464: 'merit',\n",
              " 465: 'worthy',\n",
              " 466: 'scope',\n",
              " 467: 'moan',\n",
              " 468: 'stol’n',\n",
              " 469: 'birth',\n",
              " 470: 'hide',\n",
              " 471: 'base',\n",
              " 472: 'grief',\n",
              " 473: 'sorrow',\n",
              " 474: 'tears',\n",
              " 475: 'canker',\n",
              " 476: 'sweetest',\n",
              " 477: 'needs',\n",
              " 478: 'spite',\n",
              " 479: 'whether',\n",
              " 480: 'subject',\n",
              " 481: 'into',\n",
              " 482: 'invention',\n",
              " 483: 'pain',\n",
              " 484: 'absence',\n",
              " 485: 'kill',\n",
              " 486: 'large',\n",
              " 487: 'slow',\n",
              " 488: 'motion',\n",
              " 489: 'down',\n",
              " 490: 'says',\n",
              " 491: 'took',\n",
              " 492: 'need',\n",
              " 493: 'cheek',\n",
              " 494: 'worse',\n",
              " 495: 'near',\n",
              " 496: 'flower',\n",
              " 497: 'faith',\n",
              " 498: 'tied',\n",
              " 499: 'rank',\n",
              " 500: 'brain',\n",
              " 501: 'others’',\n",
              " 502: 'saw',\n",
              " 503: 'grew',\n",
              " 504: 'brand',\n",
              " 505: 'cure',\n",
              " 506: 'mistress’',\n",
              " 507: '‘will',\n",
              " 508: '‘will’',\n",
              " 509: 'angel',\n",
              " 510: 'water',\n",
              " 511: 'fairest',\n",
              " 512: 'increase',\n",
              " 513: 'abundance',\n",
              " 514: 'sum',\n",
              " 515: 'count',\n",
              " 516: 'prime',\n",
              " 517: 'single',\n",
              " 518: 'image',\n",
              " 519: 'lends',\n",
              " 520: 'free',\n",
              " 521: 'given',\n",
              " 522: 'unused',\n",
              " 523: 'frame',\n",
              " 524: 'substance',\n",
              " 525: 'death’s',\n",
              " 526: 'worms',\n",
              " 527: 'weary',\n",
              " 528: 'mark',\n",
              " 529: 'song',\n",
              " 530: 'seeming',\n",
              " 531: 'behind',\n",
              " 532: 'grant',\n",
              " 533: 'rude',\n",
              " 534: 'heat',\n",
              " 535: 'beauties',\n",
              " 536: 'scythe',\n",
              " 537: 'here',\n",
              " 538: 'lease',\n",
              " 539: 'pluck',\n",
              " 540: 'methinks',\n",
              " 541: 'evil',\n",
              " 542: 'minutes',\n",
              " 543: 'grows',\n",
              " 544: 'wherefore',\n",
              " 545: 'rhyme',\n",
              " 546: 'inward',\n",
              " 547: 'believe',\n",
              " 548: 'high',\n",
              " 549: 'numbers',\n",
              " 550: 'touches',\n",
              " 551: 'ne’er',\n",
              " 552: 'buds',\n",
              " 553: 'shade',\n",
              " 554: 'crime',\n",
              " 555: 'young',\n",
              " 556: 'mistress',\n",
              " 557: 'rehearse',\n",
              " 558: 'rare',\n",
              " 559: 'air',\n",
              " 560: 'babe',\n",
              " 561: 'body',\n",
              " 562: 'turns',\n",
              " 563: 'want',\n",
              " 564: 'public',\n",
              " 565: 'forgot',\n",
              " 566: 'bare',\n",
              " 567: 'respect',\n",
              " 568: 'dare',\n",
              " 569: 'toil',\n",
              " 570: 'body’s',\n",
              " 571: 'jewel',\n",
              " 572: 'farther',\n",
              " 573: 'please',\n",
              " 574: 'clouds',\n",
              " 575: 'contented',\n",
              " 576: 'break',\n",
              " 577: 'lack',\n",
              " 578: 'account',\n",
              " 579: 'hearts',\n",
              " 580: 'holy',\n",
              " 581: 'appear',\n",
              " 582: 'lov’d',\n",
              " 583: 'grown',\n",
              " 584: 'sovereign',\n",
              " 585: 'shine',\n",
              " 586: 'hour',\n",
              " 587: 'wound',\n",
              " 588: 'sense',\n",
              " 589: 'thief',\n",
              " 590: 'help',\n",
              " 591: 'report',\n",
              " 592: 'comfort',\n",
              " 593: 'leisure',\n",
              " 594: 'blame',\n",
              " 595: 'taste',\n",
              " 596: 'absent',\n",
              " 597: 'said',\n",
              " 598: 'know’st',\n",
              " 599: 'gain',\n",
              " 600: 'sleep',\n",
              " 601: 'sea',\n",
              " 602: 'told',\n",
              " 603: 'seek',\n",
              " 604: 'groan',\n",
              " 605: 'judgment',\n",
              " 606: 'appetite',\n",
              " 607: 'morrow',\n",
              " 608: 'former',\n",
              " 609: 'second',\n",
              " 610: 'knife',\n",
              " 611: 'brass',\n",
              " 612: 'win',\n",
              " 613: 'steel',\n",
              " 614: 'forsworn',\n",
              " 615: 'tongues',\n",
              " 616: 'add',\n",
              " 617: 'smell',\n",
              " 618: 'weeds',\n",
              " 619: 'common',\n",
              " 620: 'lost',\n",
              " 621: 'knowing',\n",
              " 622: 'cheeks',\n",
              " 623: 'story',\n",
              " 624: 'praises',\n",
              " 625: 'above',\n",
              " 626: 'errors',\n",
              " 627: 'lays',\n",
              " 628: 'red',\n",
              " 629: 'over',\n",
              " 630: 'sinful',\n",
              " 631: 'just',\n",
              " 632: 'catch',\n",
              " 633: 'laid',\n",
              " 634: 'bath',\n",
              " 635: 'decease',\n",
              " 636: 'heir',\n",
              " 637: 'flame',\n",
              " 638: 'eat',\n",
              " 639: 'grave',\n",
              " 640: 'weed',\n",
              " 641: 'answer',\n",
              " 642: 'repair',\n",
              " 643: 'posterity',\n",
              " 644: 'mother’s',\n",
              " 645: 'april',\n",
              " 646: 'windows',\n",
              " 647: 'remember’d',\n",
              " 648: 'abuse',\n",
              " 649: 'audit',\n",
              " 650: 'work',\n",
              " 651: 'confounds',\n",
              " 652: 'effect',\n",
              " 653: 'distill’d',\n",
              " 654: 'winter’s',\n",
              " 655: 'pay',\n",
              " 656: 'happier',\n",
              " 657: 'conquest',\n",
              " 658: 'lo',\n",
              " 659: 'heavenly',\n",
              " 660: 'son',\n",
              " 661: 'ear',\n",
              " 662: 'husband',\n",
              " 663: 'weep',\n",
              " 664: 'kept',\n",
              " 665: 'belov’d',\n",
              " 666: 'fairer',\n",
              " 667: 'grow’st',\n",
              " 668: 'brave',\n",
              " 669: 'among',\n",
              " 670: 'defence',\n",
              " 671: 'takes',\n",
              " 672: 'fall',\n",
              " 673: 'brief',\n",
              " 674: 'rain',\n",
              " 675: 'knowledge',\n",
              " 676: 'constant',\n",
              " 677: 'wouldst',\n",
              " 678: 'nought',\n",
              " 679: 'whereon',\n",
              " 680: 'height',\n",
              " 681: 'wear',\n",
              " 682: 'conceit',\n",
              " 683: 'bloody',\n",
              " 684: 'tyrant',\n",
              " 685: 'means',\n",
              " 686: 'maiden',\n",
              " 687: 'virtuous',\n",
              " 688: 'drawn',\n",
              " 689: 'fill’d',\n",
              " 690: 'half',\n",
              " 691: 'number',\n",
              " 692: 'shake',\n",
              " 693: 'hot',\n",
              " 694: 'complexion',\n",
              " 695: 'course',\n",
              " 696: 'blunt',\n",
              " 697: 'burn',\n",
              " 698: 'forbid',\n",
              " 699: 'draw',\n",
              " 700: 'woman’s',\n",
              " 701: 'women’s',\n",
              " 702: 'woman',\n",
              " 703: 'wert',\n",
              " 704: 'moon',\n",
              " 705: 'cover',\n",
              " 706: 'bearing',\n",
              " 707: 'gav’st',\n",
              " 708: 'express’d',\n",
              " 709: 'therein',\n",
              " 710: 'cunning',\n",
              " 711: 'favour',\n",
              " 712: 'triumph',\n",
              " 713: 'frown',\n",
              " 714: 'fight',\n",
              " 715: 'thousand',\n",
              " 716: 'remov’d',\n",
              " 717: 'duty',\n",
              " 718: 'witness',\n",
              " 719: 'wanting',\n",
              " 720: 'star',\n",
              " 721: 'haste',\n",
              " 722: 'bed',\n",
              " 723: 'looking',\n",
              " 724: 'blot',\n",
              " 725: 'flatter',\n",
              " 726: 'daily',\n",
              " 727: 'friends',\n",
              " 728: 'almost',\n",
              " 729: 'haply',\n",
              " 730: 'expense',\n",
              " 731: 'survey',\n",
              " 732: 'growing',\n",
              " 733: 'brought',\n",
              " 734: 'style',\n",
              " 735: 'basest',\n",
              " 736: 'ride',\n",
              " 737: 'west',\n",
              " 738: 'alack',\n",
              " 739: 'stain',\n",
              " 740: 'didst',\n",
              " 741: 'bears',\n",
              " 742: 'cross',\n",
              " 743: 'thorns',\n",
              " 744: 'amiss',\n",
              " 745: 'sins',\n",
              " 746: 'fault',\n",
              " 747: 'lawful',\n",
              " 748: 'plea',\n",
              " 749: 'twain',\n",
              " 750: 'remain',\n",
              " 751: 'evermore',\n",
              " 752: 'fortune’s',\n",
              " 753: 'dearest',\n",
              " 754: 'vulgar',\n",
              " 755: 'outlive',\n",
              " 756: 'manners',\n",
              " 757: 'torment',\n",
              " 758: 'greater',\n",
              " 759: 'injury',\n",
              " 760: 'foes',\n",
              " 761: 'pretty',\n",
              " 762: 'because',\n",
              " 763: 'approve',\n",
              " 764: 'losing',\n",
              " 765: 'flattery',\n",
              " 766: 'dark',\n",
              " 767: 'shadows',\n",
              " 768: 'clear',\n",
              " 769: 'flesh',\n",
              " 770: 'matter',\n",
              " 771: 'foot',\n",
              " 772: 'soon',\n",
              " 773: 'assur’d',\n",
              " 774: 'eye’s',\n",
              " 775: 'picture',\n",
              " 776: 'sure',\n",
              " 777: 'chest',\n",
              " 778: 'whence',\n",
              " 779: 'prize',\n",
              " 780: 'pass',\n",
              " 781: 'greet',\n",
              " 782: 'reasons',\n",
              " 783: 'desert',\n",
              " 784: 'cause',\n",
              " 785: 'teach',\n",
              " 786: 'speed',\n",
              " 787: 'pace',\n",
              " 788: 'tend',\n",
              " 789: 'odour',\n",
              " 790: 'hang',\n",
              " 791: 'gilded',\n",
              " 792: 'stone',\n",
              " 793: 'quick',\n",
              " 794: 'record',\n",
              " 795: 'edge',\n",
              " 796: 'feeding',\n",
              " 797: 'fill',\n",
              " 798: 'ocean',\n",
              " 799: 'shore',\n",
              " 800: 'thrice',\n",
              " 801: 'fool',\n",
              " 802: 'god',\n",
              " 803: 'control',\n",
              " 804: 'doing',\n",
              " 805: 'five',\n",
              " 806: 'character',\n",
              " 807: 'wonder',\n",
              " 808: 'main',\n",
              " 809: 'crown’d',\n",
              " 810: 'stands',\n",
              " 811: 'mock',\n",
              " 812: 'home',\n",
              " 813: 'elsewhere',\n",
              " 814: 'advantage',\n",
              " 815: 'action',\n",
              " 816: 'simple',\n",
              " 817: 'infection',\n",
              " 818: 'lived',\n",
              " 819: 'bastard',\n",
              " 820: 'another’s',\n",
              " 821: 'mend',\n",
              " 822: 'suspect',\n",
              " 823: 'flies',\n",
              " 824: 'mourn',\n",
              " 825: 'vile',\n",
              " 826: 'line',\n",
              " 827: 'thinking',\n",
              " 828: 'birds',\n",
              " 829: 'ground',\n",
              " 830: 'pine',\n",
              " 831: 'eternity',\n",
              " 832: 'acquaintance',\n",
              " 833: 'got',\n",
              " 834: 'double',\n",
              " 835: 'works',\n",
              " 836: 'fame',\n",
              " 837: 'sail',\n",
              " 838: 'anew',\n",
              " 839: 'us’d',\n",
              " 840: 'silence',\n",
              " 841: 'bonds',\n",
              " 842: 'vow',\n",
              " 843: 'general',\n",
              " 844: 'wretched',\n",
              " 845: 'what’s',\n",
              " 846: 'turn',\n",
              " 847: 'seem’d',\n",
              " 848: 'despair',\n",
              " 849: 'growth',\n",
              " 850: 'colour',\n",
              " 851: 'constancy',\n",
              " 852: 'confin’d',\n",
              " 853: 'boy',\n",
              " 854: 'prov’d',\n",
              " 855: 'proof',\n",
              " 856: 'receives',\n",
              " 857: 'plague',\n",
              " 858: 'minds',\n",
              " 859: 'taken',\n",
              " 860: 'whereto',\n",
              " 861: 'unkind',\n",
              " 862: 'fingers',\n",
              " 863: 'kiss',\n",
              " 864: 'perjur’d',\n",
              " 865: 'came',\n",
              " 866: '‘i',\n",
              " 867: 'hate’',\n",
              " 868: 'sworn',\n",
              " 869: 'conscience',\n",
              " 870: 'oaths',\n",
              " 871: 'thereby',\n",
              " 872: 'riper',\n",
              " 873: 'contracted',\n",
              " 874: 'bud',\n",
              " 875: 'content',\n",
              " 876: 'churl',\n",
              " 877: 'mak’st',\n",
              " 878: 'winters',\n",
              " 879: 'besiege',\n",
              " 880: 'tatter’d',\n",
              " 881: 'small',\n",
              " 882: 'held',\n",
              " 883: 'lusty',\n",
              " 884: '‘this',\n",
              " 885: 'mother',\n",
              " 886: 'womb',\n",
              " 887: 'husbandry',\n",
              " 888: 'fond',\n",
              " 889: 'stop',\n",
              " 890: 'niggard',\n",
              " 891: 'bounteous',\n",
              " 892: 'usurer',\n",
              " 893: 'deceive',\n",
              " 894: 'th’',\n",
              " 895: 'gaze',\n",
              " 896: 'leads',\n",
              " 897: 'hideous',\n",
              " 898: 'sap',\n",
              " 899: 'checked',\n",
              " 900: 'bareness',\n",
              " 901: 'pent',\n",
              " 902: 'walls',\n",
              " 903: 'remembrance',\n",
              " 904: 'meet',\n",
              " 905: 'willing',\n",
              " 906: 'breed',\n",
              " 907: 'depart',\n",
              " 908: 'serving',\n",
              " 909: 'sacred',\n",
              " 910: 'majesty',\n",
              " 911: 'steep',\n",
              " 912: 'resembling',\n",
              " 913: 'attending',\n",
              " 914: 'pilgrimage',\n",
              " 915: 'pitch',\n",
              " 916: 'converted',\n",
              " 917: 'unlook’d',\n",
              " 918: 'delights',\n",
              " 919: 'receiv’st',\n",
              " 920: 'concord',\n",
              " 921: 'sounds',\n",
              " 922: 'married',\n",
              " 923: 'sweetly',\n",
              " 924: 'mutual',\n",
              " 925: 'pleasing',\n",
              " 926: 'note',\n",
              " 927: 'speechless',\n",
              " 928: 'sings',\n",
              " 929: 'wail',\n",
              " 930: 'widow',\n",
              " 931: 'bosom',\n",
              " 932: 'himself',\n",
              " 933: 'commits',\n",
              " 934: 'deny',\n",
              " 935: 'possess’d',\n",
              " 936: 'murderous',\n",
              " 937: 'chief',\n",
              " 938: 'presence',\n",
              " 939: 'folly',\n",
              " 940: 'bounty',\n",
              " 941: 'copy',\n",
              " 942: 'clock',\n",
              " 943: 'tells',\n",
              " 944: 'violet',\n",
              " 945: 'lofty',\n",
              " 946: 'canopy',\n",
              " 947: 'borne',\n",
              " 948: 'question',\n",
              " 949: 'wastes',\n",
              " 950: 'forsake',\n",
              " 951: 'coming',\n",
              " 952: 'prepare',\n",
              " 953: 'issue',\n",
              " 954: 'father',\n",
              " 955: 'judgement',\n",
              " 956: 'wind',\n",
              " 957: 'princes',\n",
              " 958: '‘truth',\n",
              " 959: 'thrive',\n",
              " 960: 'perfection',\n",
              " 961: 'little',\n",
              " 962: 'huge',\n",
              " 963: 'stage',\n",
              " 964: 'influence',\n",
              " 965: 'comment',\n",
              " 966: 'youthful',\n",
              " 967: 'inconstant',\n",
              " 968: 'sets',\n",
              " 969: 'wasteful',\n",
              " 970: 'fortify',\n",
              " 971: 'counterfeit',\n",
              " 972: 'pencil',\n",
              " 973: 'neither',\n",
              " 974: 'deserts',\n",
              " 975: 'poet',\n",
              " 976: 'faces',\n",
              " 977: 'poet’s',\n",
              " 978: 'alive',\n",
              " 979: 'twice',\n",
              " 980: 'winds',\n",
              " 981: 'shines',\n",
              " 982: 'often',\n",
              " 983: 'gold',\n",
              " 984: 'changing',\n",
              " 985: 'fade',\n",
              " 986: 'possession',\n",
              " 987: 'breathe',\n",
              " 988: 'keen',\n",
              " 989: 'fierce',\n",
              " 990: 'liv’d',\n",
              " 991: 'glad',\n",
              " 992: 'seasons',\n",
              " 993: 'whate’er',\n",
              " 994: 'fading',\n",
              " 995: 'allow',\n",
              " 996: 'pattern',\n",
              " 997: 'master',\n",
              " 998: 'acquainted',\n",
              " 999: 'fashion',\n",
              " 1000: 'theirs',\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Palabras del vocabulario\n",
        "tok.index_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJgVhq1zwEpf",
        "outputId": "95809a09-1118-4461-f945-d7b6501f1885"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3225"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Cantidad de palabras en el vocabulario\n",
        "vocab_size = len(tok.word_counts)\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWjNrNx9wM1b",
        "outputId": "f78627b0-3b0a-4bfc-e733-4286a522d08d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# En el caso anterior explota porque y_data_int comienza en \"1\" en vez de \"0\"\n",
        "# valor minimo:\n",
        "min(y_data_int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIg2e2WCwXbG",
        "outputId": "62d7fe26-3101-40e4-c6ef-3fdc14be2424"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17616, 3225)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "y_data_int_offset = y_data_int - 1\n",
        "y_data = to_categorical(y_data_int_offset, num_classes=vocab_size) \n",
        "y_data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmJWNyxQwfCE"
      },
      "source": [
        "### 4 - Entrenar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cOmNZT_weK2",
        "outputId": "1275d489-1f6f-4a7d-d943-0120c2ba64c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "# largo de la secuencia de entrada\n",
        "input_seq_len = x_data.shape[1] \n",
        "input_seq_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtwITjgnwlgp",
        "outputId": "909d46f9-50ec-4dfc-ac43-0c71d010f641"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3225"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# Largo del vector de salida --> vocab_size\n",
        "output_size = vocab_size\n",
        "output_size"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Modelo 1"
      ],
      "metadata": {
        "id": "4kG6Ip39cRwA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzTZRXrrwrvi",
        "outputId": "f561aae9-e274-46ba-d7e0-e3032ff1561b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 3, 5)              16130     \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 3, 128)           35840     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 3, 128)            0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 3, 256)           263168    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 3, 256)            0         \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 3, 512)           1050624   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 3, 512)            0         \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 512)              1574912   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                16416     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3225)              106425    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,063,515\n",
            "Trainable params: 3,063,515\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Embedding:\n",
        "# input_seq_len = 3 --> ingreso 3 palabras\n",
        "# input_dim = vocab_size --> 1628 palabras distintas\n",
        "# output_dim = 5 --> crear embeddings de tamaño 3 (tamaño variable y ajustable)\n",
        "model.add(Embedding(input_dim=vocab_size+1, output_dim=5, input_length=input_seq_len))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Bidirectional(LSTM(128,return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Bidirectional(LSTM(256,return_sequences=True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(LSTM(256))) # La última capa LSTM no lleva return_sequences\n",
        "model.add(Dense(32, activation='relu'))\n",
        "\n",
        "# Predicción de clasificación con softmax\n",
        "# La salida vuelve al espacio de 1628 palabras posibles\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "# Clasificación multiple categórica --> loss = categorical_crossentropy\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQq1PHDkxDvN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d32bac86-309f-4a11-e613-0797d993d90b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.8148 - accuracy: 0.5435 - val_loss: 38.8157 - val_accuracy: 0.0255\n",
            "Epoch 2/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.8298 - accuracy: 0.5427 - val_loss: 38.5028 - val_accuracy: 0.0368\n",
            "Epoch 3/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.7916 - accuracy: 0.5463 - val_loss: 39.3837 - val_accuracy: 0.0368\n",
            "Epoch 4/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 1.8012 - accuracy: 0.5467 - val_loss: 39.4621 - val_accuracy: 0.0368\n",
            "Epoch 5/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.7840 - accuracy: 0.5487 - val_loss: 39.0803 - val_accuracy: 0.0312\n",
            "Epoch 6/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.7579 - accuracy: 0.5578 - val_loss: 39.9988 - val_accuracy: 0.0227\n",
            "Epoch 7/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.7745 - accuracy: 0.5503 - val_loss: 39.0892 - val_accuracy: 0.0227\n",
            "Epoch 8/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.7655 - accuracy: 0.5540 - val_loss: 39.2760 - val_accuracy: 0.0340\n",
            "Epoch 9/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.7644 - accuracy: 0.5537 - val_loss: 41.1778 - val_accuracy: 0.0312\n",
            "Epoch 10/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.7411 - accuracy: 0.5603 - val_loss: 40.0769 - val_accuracy: 0.0312\n",
            "Epoch 11/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 1.7397 - accuracy: 0.5654 - val_loss: 40.5616 - val_accuracy: 0.0340\n",
            "Epoch 12/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.7508 - accuracy: 0.5560 - val_loss: 38.8656 - val_accuracy: 0.0255\n",
            "Epoch 13/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.7641 - accuracy: 0.5595 - val_loss: 40.0641 - val_accuracy: 0.0340\n",
            "Epoch 14/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.7379 - accuracy: 0.5632 - val_loss: 40.6973 - val_accuracy: 0.0227\n",
            "Epoch 15/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.7009 - accuracy: 0.5740 - val_loss: 40.1594 - val_accuracy: 0.0340\n",
            "Epoch 16/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 1.7205 - accuracy: 0.5690 - val_loss: 39.5153 - val_accuracy: 0.0368\n",
            "Epoch 17/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.6806 - accuracy: 0.5734 - val_loss: 39.8312 - val_accuracy: 0.0425\n",
            "Epoch 18/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.6895 - accuracy: 0.5741 - val_loss: 40.7600 - val_accuracy: 0.0283\n",
            "Epoch 19/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.7065 - accuracy: 0.5707 - val_loss: 41.5473 - val_accuracy: 0.0227\n",
            "Epoch 20/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.7125 - accuracy: 0.5638 - val_loss: 39.9578 - val_accuracy: 0.0283\n",
            "Epoch 21/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.6516 - accuracy: 0.5810 - val_loss: 40.3253 - val_accuracy: 0.0255\n",
            "Epoch 22/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.6824 - accuracy: 0.5787 - val_loss: 40.0221 - val_accuracy: 0.0340\n",
            "Epoch 23/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.6825 - accuracy: 0.5747 - val_loss: 40.1860 - val_accuracy: 0.0255\n",
            "Epoch 24/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.6876 - accuracy: 0.5715 - val_loss: 40.8142 - val_accuracy: 0.0453\n",
            "Epoch 25/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.6739 - accuracy: 0.5778 - val_loss: 40.5144 - val_accuracy: 0.0227\n",
            "Epoch 26/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.6733 - accuracy: 0.5786 - val_loss: 40.5320 - val_accuracy: 0.0312\n",
            "Epoch 27/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.6591 - accuracy: 0.5804 - val_loss: 40.6556 - val_accuracy: 0.0425\n",
            "Epoch 28/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.6452 - accuracy: 0.5838 - val_loss: 40.9900 - val_accuracy: 0.0368\n",
            "Epoch 29/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.6277 - accuracy: 0.5876 - val_loss: 40.7986 - val_accuracy: 0.0283\n",
            "Epoch 30/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.6225 - accuracy: 0.5878 - val_loss: 40.1707 - val_accuracy: 0.0255\n",
            "Epoch 31/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.6292 - accuracy: 0.5916 - val_loss: 40.8361 - val_accuracy: 0.0340\n",
            "Epoch 32/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.6338 - accuracy: 0.5848 - val_loss: 41.3150 - val_accuracy: 0.0340\n",
            "Epoch 33/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.6105 - accuracy: 0.5903 - val_loss: 40.9604 - val_accuracy: 0.0227\n",
            "Epoch 34/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.6290 - accuracy: 0.5908 - val_loss: 40.9697 - val_accuracy: 0.0283\n",
            "Epoch 35/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.6085 - accuracy: 0.5936 - val_loss: 40.3197 - val_accuracy: 0.0255\n",
            "Epoch 36/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 1.5987 - accuracy: 0.5956 - val_loss: 39.9303 - val_accuracy: 0.0283\n",
            "Epoch 37/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.6058 - accuracy: 0.5911 - val_loss: 39.2359 - val_accuracy: 0.0340\n",
            "Epoch 38/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.5888 - accuracy: 0.5973 - val_loss: 40.5035 - val_accuracy: 0.0255\n",
            "Epoch 39/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.5973 - accuracy: 0.5958 - val_loss: 41.8172 - val_accuracy: 0.0312\n",
            "Epoch 40/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.5570 - accuracy: 0.6012 - val_loss: 40.8521 - val_accuracy: 0.0340\n",
            "Epoch 41/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.5821 - accuracy: 0.5961 - val_loss: 40.7862 - val_accuracy: 0.0368\n",
            "Epoch 42/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.5756 - accuracy: 0.6005 - val_loss: 40.9208 - val_accuracy: 0.0283\n",
            "Epoch 43/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.5469 - accuracy: 0.6044 - val_loss: 41.3774 - val_accuracy: 0.0312\n",
            "Epoch 44/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.5791 - accuracy: 0.6020 - val_loss: 41.4160 - val_accuracy: 0.0312\n",
            "Epoch 45/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.5814 - accuracy: 0.5975 - val_loss: 41.8493 - val_accuracy: 0.0368\n",
            "Epoch 46/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.5569 - accuracy: 0.6063 - val_loss: 41.0517 - val_accuracy: 0.0283\n",
            "Epoch 47/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.5476 - accuracy: 0.6024 - val_loss: 41.7265 - val_accuracy: 0.0312\n",
            "Epoch 48/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.5222 - accuracy: 0.6101 - val_loss: 41.5798 - val_accuracy: 0.0255\n",
            "Epoch 49/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.5431 - accuracy: 0.6130 - val_loss: 42.2991 - val_accuracy: 0.0283\n",
            "Epoch 50/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 1.5135 - accuracy: 0.6153 - val_loss: 41.0504 - val_accuracy: 0.0283\n",
            "Epoch 51/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.5221 - accuracy: 0.6119 - val_loss: 41.5728 - val_accuracy: 0.0340\n",
            "Epoch 52/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.5262 - accuracy: 0.6126 - val_loss: 41.1915 - val_accuracy: 0.0425\n",
            "Epoch 53/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.5145 - accuracy: 0.6109 - val_loss: 41.4737 - val_accuracy: 0.0255\n",
            "Epoch 54/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.5070 - accuracy: 0.6143 - val_loss: 41.4951 - val_accuracy: 0.0312\n",
            "Epoch 55/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.5200 - accuracy: 0.6117 - val_loss: 41.2187 - val_accuracy: 0.0340\n",
            "Epoch 56/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.5270 - accuracy: 0.6109 - val_loss: 40.7742 - val_accuracy: 0.0283\n",
            "Epoch 57/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.4803 - accuracy: 0.6226 - val_loss: 42.0089 - val_accuracy: 0.0283\n",
            "Epoch 58/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.4944 - accuracy: 0.6181 - val_loss: 40.9544 - val_accuracy: 0.0255\n",
            "Epoch 59/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.4805 - accuracy: 0.6178 - val_loss: 41.9111 - val_accuracy: 0.0312\n",
            "Epoch 60/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.4800 - accuracy: 0.6160 - val_loss: 42.1341 - val_accuracy: 0.0283\n",
            "Epoch 61/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.4579 - accuracy: 0.6280 - val_loss: 42.2881 - val_accuracy: 0.0255\n",
            "Epoch 62/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.4615 - accuracy: 0.6202 - val_loss: 42.1409 - val_accuracy: 0.0312\n",
            "Epoch 63/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.4694 - accuracy: 0.6253 - val_loss: 42.8310 - val_accuracy: 0.0312\n",
            "Epoch 64/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.4738 - accuracy: 0.6245 - val_loss: 41.8957 - val_accuracy: 0.0283\n",
            "Epoch 65/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.4657 - accuracy: 0.6231 - val_loss: 42.9999 - val_accuracy: 0.0283\n",
            "Epoch 66/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.4617 - accuracy: 0.6267 - val_loss: 43.5660 - val_accuracy: 0.0198\n",
            "Epoch 67/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.4591 - accuracy: 0.6297 - val_loss: 43.3926 - val_accuracy: 0.0283\n",
            "Epoch 68/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.4575 - accuracy: 0.6278 - val_loss: 42.3819 - val_accuracy: 0.0312\n",
            "Epoch 69/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.4552 - accuracy: 0.6293 - val_loss: 42.5272 - val_accuracy: 0.0283\n",
            "Epoch 70/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 1.4498 - accuracy: 0.6326 - val_loss: 41.9326 - val_accuracy: 0.0227\n",
            "Epoch 71/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.4367 - accuracy: 0.6308 - val_loss: 42.9517 - val_accuracy: 0.0255\n",
            "Epoch 72/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.4252 - accuracy: 0.6351 - val_loss: 42.9316 - val_accuracy: 0.0368\n",
            "Epoch 73/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.4235 - accuracy: 0.6353 - val_loss: 43.4998 - val_accuracy: 0.0255\n",
            "Epoch 74/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.4518 - accuracy: 0.6314 - val_loss: 42.4271 - val_accuracy: 0.0283\n",
            "Epoch 75/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.4276 - accuracy: 0.6381 - val_loss: 42.8617 - val_accuracy: 0.0312\n",
            "Epoch 76/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.4020 - accuracy: 0.6448 - val_loss: 44.1805 - val_accuracy: 0.0198\n",
            "Epoch 77/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.3980 - accuracy: 0.6382 - val_loss: 43.9840 - val_accuracy: 0.0255\n",
            "Epoch 78/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.4157 - accuracy: 0.6394 - val_loss: 43.8929 - val_accuracy: 0.0283\n",
            "Epoch 79/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.3897 - accuracy: 0.6462 - val_loss: 43.2617 - val_accuracy: 0.0255\n",
            "Epoch 80/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.4162 - accuracy: 0.6409 - val_loss: 43.8507 - val_accuracy: 0.0340\n",
            "Epoch 81/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.4013 - accuracy: 0.6409 - val_loss: 42.7834 - val_accuracy: 0.0283\n",
            "Epoch 82/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.3995 - accuracy: 0.6396 - val_loss: 43.5171 - val_accuracy: 0.0340\n",
            "Epoch 83/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.3972 - accuracy: 0.6409 - val_loss: 43.6112 - val_accuracy: 0.0227\n",
            "Epoch 84/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 1.3630 - accuracy: 0.6461 - val_loss: 44.3322 - val_accuracy: 0.0312\n",
            "Epoch 85/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.3728 - accuracy: 0.6494 - val_loss: 43.0725 - val_accuracy: 0.0255\n",
            "Epoch 86/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.3836 - accuracy: 0.6407 - val_loss: 43.6202 - val_accuracy: 0.0198\n",
            "Epoch 87/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 1.3701 - accuracy: 0.6496 - val_loss: 43.5811 - val_accuracy: 0.0312\n",
            "Epoch 88/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.3817 - accuracy: 0.6440 - val_loss: 44.3406 - val_accuracy: 0.0198\n",
            "Epoch 89/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 1.3971 - accuracy: 0.6454 - val_loss: 43.6825 - val_accuracy: 0.0283\n",
            "Epoch 90/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.3973 - accuracy: 0.6448 - val_loss: 42.3635 - val_accuracy: 0.0170\n",
            "Epoch 91/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.3984 - accuracy: 0.6436 - val_loss: 42.9259 - val_accuracy: 0.0283\n",
            "Epoch 92/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.3607 - accuracy: 0.6509 - val_loss: 42.5573 - val_accuracy: 0.0255\n",
            "Epoch 93/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.3634 - accuracy: 0.6516 - val_loss: 43.1173 - val_accuracy: 0.0283\n",
            "Epoch 94/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.3502 - accuracy: 0.6557 - val_loss: 44.4492 - val_accuracy: 0.0227\n",
            "Epoch 95/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.3412 - accuracy: 0.6531 - val_loss: 42.8768 - val_accuracy: 0.0255\n",
            "Epoch 96/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.3375 - accuracy: 0.6565 - val_loss: 42.7946 - val_accuracy: 0.0368\n",
            "Epoch 97/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.3274 - accuracy: 0.6581 - val_loss: 44.2731 - val_accuracy: 0.0368\n",
            "Epoch 98/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.3564 - accuracy: 0.6535 - val_loss: 42.9130 - val_accuracy: 0.0312\n",
            "Epoch 99/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.3457 - accuracy: 0.6480 - val_loss: 43.7272 - val_accuracy: 0.0312\n",
            "Epoch 100/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.3508 - accuracy: 0.6546 - val_loss: 43.8327 - val_accuracy: 0.0340\n",
            "Epoch 101/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.3317 - accuracy: 0.6585 - val_loss: 43.4226 - val_accuracy: 0.0255\n",
            "Epoch 102/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.3175 - accuracy: 0.6596 - val_loss: 44.7601 - val_accuracy: 0.0255\n",
            "Epoch 103/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.3130 - accuracy: 0.6611 - val_loss: 43.5847 - val_accuracy: 0.0340\n",
            "Epoch 104/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.3244 - accuracy: 0.6557 - val_loss: 44.8482 - val_accuracy: 0.0198\n",
            "Epoch 105/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.3272 - accuracy: 0.6580 - val_loss: 44.3865 - val_accuracy: 0.0340\n",
            "Epoch 106/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.3059 - accuracy: 0.6611 - val_loss: 45.0143 - val_accuracy: 0.0340\n",
            "Epoch 107/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.2847 - accuracy: 0.6690 - val_loss: 44.5229 - val_accuracy: 0.0255\n",
            "Epoch 108/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.3170 - accuracy: 0.6615 - val_loss: 45.5577 - val_accuracy: 0.0283\n",
            "Epoch 109/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.2990 - accuracy: 0.6610 - val_loss: 44.3688 - val_accuracy: 0.0227\n",
            "Epoch 110/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.2969 - accuracy: 0.6679 - val_loss: 45.1492 - val_accuracy: 0.0340\n",
            "Epoch 111/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.2700 - accuracy: 0.6697 - val_loss: 44.3140 - val_accuracy: 0.0283\n",
            "Epoch 112/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.2798 - accuracy: 0.6679 - val_loss: 44.6196 - val_accuracy: 0.0227\n",
            "Epoch 113/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.2904 - accuracy: 0.6667 - val_loss: 44.9479 - val_accuracy: 0.0255\n",
            "Epoch 114/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.2517 - accuracy: 0.6757 - val_loss: 44.8273 - val_accuracy: 0.0283\n",
            "Epoch 115/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.2885 - accuracy: 0.6692 - val_loss: 44.1057 - val_accuracy: 0.0312\n",
            "Epoch 116/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.2639 - accuracy: 0.6718 - val_loss: 45.2064 - val_accuracy: 0.0312\n",
            "Epoch 117/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.2788 - accuracy: 0.6693 - val_loss: 44.2113 - val_accuracy: 0.0368\n",
            "Epoch 118/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.2994 - accuracy: 0.6679 - val_loss: 44.9517 - val_accuracy: 0.0283\n",
            "Epoch 119/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.2978 - accuracy: 0.6625 - val_loss: 44.7322 - val_accuracy: 0.0312\n",
            "Epoch 120/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.2542 - accuracy: 0.6751 - val_loss: 45.7822 - val_accuracy: 0.0312\n",
            "Epoch 121/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.2733 - accuracy: 0.6728 - val_loss: 44.8080 - val_accuracy: 0.0198\n",
            "Epoch 122/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.2502 - accuracy: 0.6743 - val_loss: 44.6378 - val_accuracy: 0.0255\n",
            "Epoch 123/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.2410 - accuracy: 0.6765 - val_loss: 45.3854 - val_accuracy: 0.0283\n",
            "Epoch 124/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.2529 - accuracy: 0.6779 - val_loss: 44.8666 - val_accuracy: 0.0312\n",
            "Epoch 125/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.2533 - accuracy: 0.6740 - val_loss: 44.3010 - val_accuracy: 0.0255\n",
            "Epoch 126/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.2731 - accuracy: 0.6728 - val_loss: 44.5965 - val_accuracy: 0.0283\n",
            "Epoch 127/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.2211 - accuracy: 0.6795 - val_loss: 45.0015 - val_accuracy: 0.0255\n",
            "Epoch 128/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.2512 - accuracy: 0.6743 - val_loss: 45.7100 - val_accuracy: 0.0283\n",
            "Epoch 129/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.2319 - accuracy: 0.6816 - val_loss: 45.6423 - val_accuracy: 0.0368\n",
            "Epoch 130/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.2360 - accuracy: 0.6793 - val_loss: 44.7580 - val_accuracy: 0.0340\n",
            "Epoch 131/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.2390 - accuracy: 0.6804 - val_loss: 45.3685 - val_accuracy: 0.0283\n",
            "Epoch 132/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.2231 - accuracy: 0.6802 - val_loss: 46.5199 - val_accuracy: 0.0312\n",
            "Epoch 133/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.2683 - accuracy: 0.6733 - val_loss: 45.3536 - val_accuracy: 0.0283\n",
            "Epoch 134/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.2334 - accuracy: 0.6798 - val_loss: 44.6350 - val_accuracy: 0.0340\n",
            "Epoch 135/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.2111 - accuracy: 0.6827 - val_loss: 46.2127 - val_accuracy: 0.0340\n",
            "Epoch 136/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.2366 - accuracy: 0.6804 - val_loss: 44.5771 - val_accuracy: 0.0255\n",
            "Epoch 137/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.2275 - accuracy: 0.6790 - val_loss: 44.7006 - val_accuracy: 0.0283\n",
            "Epoch 138/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.2110 - accuracy: 0.6903 - val_loss: 43.7829 - val_accuracy: 0.0255\n",
            "Epoch 139/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.2387 - accuracy: 0.6790 - val_loss: 44.5109 - val_accuracy: 0.0255\n",
            "Epoch 140/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.2180 - accuracy: 0.6871 - val_loss: 45.2833 - val_accuracy: 0.0255\n",
            "Epoch 141/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.2025 - accuracy: 0.6901 - val_loss: 45.0607 - val_accuracy: 0.0340\n",
            "Epoch 142/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.1978 - accuracy: 0.6897 - val_loss: 45.3253 - val_accuracy: 0.0312\n",
            "Epoch 143/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.2207 - accuracy: 0.6812 - val_loss: 45.3868 - val_accuracy: 0.0340\n",
            "Epoch 144/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.2091 - accuracy: 0.6852 - val_loss: 45.9998 - val_accuracy: 0.0340\n",
            "Epoch 145/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.1821 - accuracy: 0.6917 - val_loss: 46.0377 - val_accuracy: 0.0312\n",
            "Epoch 146/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.2081 - accuracy: 0.6888 - val_loss: 45.9297 - val_accuracy: 0.0368\n",
            "Epoch 147/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.1918 - accuracy: 0.6880 - val_loss: 46.2114 - val_accuracy: 0.0283\n",
            "Epoch 148/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.1895 - accuracy: 0.6906 - val_loss: 46.3312 - val_accuracy: 0.0255\n",
            "Epoch 149/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.2029 - accuracy: 0.6855 - val_loss: 45.0536 - val_accuracy: 0.0283\n",
            "Epoch 150/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.2051 - accuracy: 0.6863 - val_loss: 45.8024 - val_accuracy: 0.0312\n",
            "Epoch 151/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 1.1724 - accuracy: 0.6947 - val_loss: 46.2468 - val_accuracy: 0.0283\n",
            "Epoch 152/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.1906 - accuracy: 0.6922 - val_loss: 45.5620 - val_accuracy: 0.0340\n",
            "Epoch 153/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.1806 - accuracy: 0.6927 - val_loss: 45.9389 - val_accuracy: 0.0397\n",
            "Epoch 154/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.1703 - accuracy: 0.6929 - val_loss: 45.5142 - val_accuracy: 0.0340\n",
            "Epoch 155/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.1796 - accuracy: 0.6895 - val_loss: 45.9631 - val_accuracy: 0.0283\n",
            "Epoch 156/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.1814 - accuracy: 0.6941 - val_loss: 45.0529 - val_accuracy: 0.0368\n",
            "Epoch 157/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.1864 - accuracy: 0.6932 - val_loss: 44.8433 - val_accuracy: 0.0255\n",
            "Epoch 158/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.1834 - accuracy: 0.6915 - val_loss: 46.0994 - val_accuracy: 0.0312\n",
            "Epoch 159/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.1532 - accuracy: 0.6992 - val_loss: 45.1494 - val_accuracy: 0.0283\n",
            "Epoch 160/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.1569 - accuracy: 0.6954 - val_loss: 45.8007 - val_accuracy: 0.0340\n",
            "Epoch 161/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.1792 - accuracy: 0.6954 - val_loss: 45.9244 - val_accuracy: 0.0340\n",
            "Epoch 162/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.1630 - accuracy: 0.6998 - val_loss: 46.5370 - val_accuracy: 0.0340\n",
            "Epoch 163/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.1503 - accuracy: 0.6945 - val_loss: 45.5252 - val_accuracy: 0.0312\n",
            "Epoch 164/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.1699 - accuracy: 0.6947 - val_loss: 45.5517 - val_accuracy: 0.0198\n",
            "Epoch 165/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.1793 - accuracy: 0.6964 - val_loss: 44.6986 - val_accuracy: 0.0312\n",
            "Epoch 166/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.1529 - accuracy: 0.7011 - val_loss: 45.4953 - val_accuracy: 0.0340\n",
            "Epoch 167/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.1500 - accuracy: 0.7017 - val_loss: 45.4311 - val_accuracy: 0.0283\n",
            "Epoch 168/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.1622 - accuracy: 0.6992 - val_loss: 46.1193 - val_accuracy: 0.0283\n",
            "Epoch 169/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.1308 - accuracy: 0.7053 - val_loss: 46.7868 - val_accuracy: 0.0255\n",
            "Epoch 170/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.1388 - accuracy: 0.7028 - val_loss: 46.3757 - val_accuracy: 0.0283\n",
            "Epoch 171/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.1376 - accuracy: 0.7057 - val_loss: 45.8044 - val_accuracy: 0.0312\n",
            "Epoch 172/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.1219 - accuracy: 0.7049 - val_loss: 46.4762 - val_accuracy: 0.0397\n",
            "Epoch 173/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.1128 - accuracy: 0.7089 - val_loss: 46.0901 - val_accuracy: 0.0397\n",
            "Epoch 174/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.1257 - accuracy: 0.7083 - val_loss: 46.1203 - val_accuracy: 0.0340\n",
            "Epoch 175/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.1261 - accuracy: 0.7078 - val_loss: 46.3946 - val_accuracy: 0.0255\n",
            "Epoch 176/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.1253 - accuracy: 0.7042 - val_loss: 46.8400 - val_accuracy: 0.0283\n",
            "Epoch 177/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.1445 - accuracy: 0.7024 - val_loss: 45.9218 - val_accuracy: 0.0255\n",
            "Epoch 178/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0990 - accuracy: 0.7113 - val_loss: 45.7775 - val_accuracy: 0.0312\n",
            "Epoch 179/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.1165 - accuracy: 0.7065 - val_loss: 45.4294 - val_accuracy: 0.0368\n",
            "Epoch 180/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.1040 - accuracy: 0.7137 - val_loss: 45.9687 - val_accuracy: 0.0312\n",
            "Epoch 181/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.1450 - accuracy: 0.7039 - val_loss: 46.0642 - val_accuracy: 0.0255\n",
            "Epoch 182/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.1194 - accuracy: 0.7072 - val_loss: 45.9184 - val_accuracy: 0.0312\n",
            "Epoch 183/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.1063 - accuracy: 0.7108 - val_loss: 46.7871 - val_accuracy: 0.0312\n",
            "Epoch 184/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.1036 - accuracy: 0.7131 - val_loss: 46.3862 - val_accuracy: 0.0340\n",
            "Epoch 185/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.1189 - accuracy: 0.7082 - val_loss: 45.7871 - val_accuracy: 0.0283\n",
            "Epoch 186/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.1123 - accuracy: 0.7108 - val_loss: 45.4047 - val_accuracy: 0.0227\n",
            "Epoch 187/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0865 - accuracy: 0.7122 - val_loss: 47.1728 - val_accuracy: 0.0255\n",
            "Epoch 188/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0999 - accuracy: 0.7130 - val_loss: 46.2233 - val_accuracy: 0.0255\n",
            "Epoch 189/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 1.0869 - accuracy: 0.7166 - val_loss: 45.5579 - val_accuracy: 0.0283\n",
            "Epoch 190/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.1203 - accuracy: 0.7092 - val_loss: 45.2605 - val_accuracy: 0.0255\n",
            "Epoch 191/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.1066 - accuracy: 0.7082 - val_loss: 46.2170 - val_accuracy: 0.0368\n",
            "Epoch 192/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.0601 - accuracy: 0.7194 - val_loss: 46.9650 - val_accuracy: 0.0283\n",
            "Epoch 193/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.1005 - accuracy: 0.7119 - val_loss: 48.1299 - val_accuracy: 0.0283\n",
            "Epoch 194/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0922 - accuracy: 0.7151 - val_loss: 47.2230 - val_accuracy: 0.0255\n",
            "Epoch 195/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0834 - accuracy: 0.7171 - val_loss: 46.3868 - val_accuracy: 0.0312\n",
            "Epoch 196/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0919 - accuracy: 0.7142 - val_loss: 47.2126 - val_accuracy: 0.0255\n",
            "Epoch 197/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0865 - accuracy: 0.7160 - val_loss: 47.1545 - val_accuracy: 0.0312\n",
            "Epoch 198/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0710 - accuracy: 0.7159 - val_loss: 47.2829 - val_accuracy: 0.0283\n",
            "Epoch 199/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0853 - accuracy: 0.7164 - val_loss: 45.7874 - val_accuracy: 0.0368\n",
            "Epoch 200/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0842 - accuracy: 0.7169 - val_loss: 45.9329 - val_accuracy: 0.0255\n",
            "Epoch 201/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.0740 - accuracy: 0.7203 - val_loss: 45.7424 - val_accuracy: 0.0312\n",
            "Epoch 202/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0715 - accuracy: 0.7188 - val_loss: 46.0995 - val_accuracy: 0.0283\n",
            "Epoch 203/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0761 - accuracy: 0.7185 - val_loss: 46.9854 - val_accuracy: 0.0312\n",
            "Epoch 204/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0604 - accuracy: 0.7207 - val_loss: 46.6159 - val_accuracy: 0.0283\n",
            "Epoch 205/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0686 - accuracy: 0.7202 - val_loss: 46.8899 - val_accuracy: 0.0312\n",
            "Epoch 206/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.0522 - accuracy: 0.7201 - val_loss: 46.3672 - val_accuracy: 0.0283\n",
            "Epoch 207/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.0769 - accuracy: 0.7170 - val_loss: 46.6600 - val_accuracy: 0.0227\n",
            "Epoch 208/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0655 - accuracy: 0.7193 - val_loss: 48.0492 - val_accuracy: 0.0283\n",
            "Epoch 209/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0650 - accuracy: 0.7185 - val_loss: 47.6603 - val_accuracy: 0.0312\n",
            "Epoch 210/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0576 - accuracy: 0.7254 - val_loss: 47.2492 - val_accuracy: 0.0312\n",
            "Epoch 211/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0495 - accuracy: 0.7242 - val_loss: 47.2130 - val_accuracy: 0.0312\n",
            "Epoch 212/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0690 - accuracy: 0.7216 - val_loss: 47.2425 - val_accuracy: 0.0312\n",
            "Epoch 213/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0641 - accuracy: 0.7199 - val_loss: 48.1252 - val_accuracy: 0.0283\n",
            "Epoch 214/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0277 - accuracy: 0.7303 - val_loss: 47.3558 - val_accuracy: 0.0255\n",
            "Epoch 215/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0651 - accuracy: 0.7258 - val_loss: 48.8303 - val_accuracy: 0.0227\n",
            "Epoch 216/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0269 - accuracy: 0.7273 - val_loss: 48.1087 - val_accuracy: 0.0340\n",
            "Epoch 217/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0465 - accuracy: 0.7275 - val_loss: 47.4841 - val_accuracy: 0.0283\n",
            "Epoch 218/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0606 - accuracy: 0.7262 - val_loss: 46.5059 - val_accuracy: 0.0227\n",
            "Epoch 219/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0271 - accuracy: 0.7225 - val_loss: 47.6931 - val_accuracy: 0.0312\n",
            "Epoch 220/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0447 - accuracy: 0.7257 - val_loss: 48.5716 - val_accuracy: 0.0312\n",
            "Epoch 221/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0394 - accuracy: 0.7248 - val_loss: 47.3326 - val_accuracy: 0.0283\n",
            "Epoch 222/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0227 - accuracy: 0.7287 - val_loss: 47.3194 - val_accuracy: 0.0340\n",
            "Epoch 223/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0097 - accuracy: 0.7296 - val_loss: 47.6270 - val_accuracy: 0.0397\n",
            "Epoch 224/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0466 - accuracy: 0.7303 - val_loss: 47.2670 - val_accuracy: 0.0283\n",
            "Epoch 225/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.0353 - accuracy: 0.7260 - val_loss: 48.7137 - val_accuracy: 0.0312\n",
            "Epoch 226/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0530 - accuracy: 0.7247 - val_loss: 47.9913 - val_accuracy: 0.0312\n",
            "Epoch 227/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.0316 - accuracy: 0.7280 - val_loss: 46.5555 - val_accuracy: 0.0340\n",
            "Epoch 228/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0492 - accuracy: 0.7228 - val_loss: 47.8657 - val_accuracy: 0.0227\n",
            "Epoch 229/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 1.0047 - accuracy: 0.7357 - val_loss: 46.8409 - val_accuracy: 0.0227\n",
            "Epoch 230/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 1.0272 - accuracy: 0.7310 - val_loss: 47.9279 - val_accuracy: 0.0227\n",
            "Epoch 231/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 1.0265 - accuracy: 0.7269 - val_loss: 48.0625 - val_accuracy: 0.0198\n",
            "Epoch 232/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.0157 - accuracy: 0.7317 - val_loss: 47.4511 - val_accuracy: 0.0255\n",
            "Epoch 233/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 0.9974 - accuracy: 0.7350 - val_loss: 47.2996 - val_accuracy: 0.0283\n",
            "Epoch 234/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 0.9995 - accuracy: 0.7357 - val_loss: 47.8312 - val_accuracy: 0.0283\n",
            "Epoch 235/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0268 - accuracy: 0.7319 - val_loss: 47.1804 - val_accuracy: 0.0170\n",
            "Epoch 236/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 1.0035 - accuracy: 0.7338 - val_loss: 47.9402 - val_accuracy: 0.0255\n",
            "Epoch 237/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0070 - accuracy: 0.7325 - val_loss: 48.5377 - val_accuracy: 0.0255\n",
            "Epoch 238/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0000 - accuracy: 0.7378 - val_loss: 47.9433 - val_accuracy: 0.0227\n",
            "Epoch 239/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0212 - accuracy: 0.7355 - val_loss: 47.5740 - val_accuracy: 0.0255\n",
            "Epoch 240/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 0.9990 - accuracy: 0.7337 - val_loss: 49.1108 - val_accuracy: 0.0227\n",
            "Epoch 241/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0006 - accuracy: 0.7361 - val_loss: 48.1439 - val_accuracy: 0.0255\n",
            "Epoch 242/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 0.9934 - accuracy: 0.7358 - val_loss: 47.3725 - val_accuracy: 0.0283\n",
            "Epoch 243/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0116 - accuracy: 0.7350 - val_loss: 47.2058 - val_accuracy: 0.0283\n",
            "Epoch 244/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 0.9841 - accuracy: 0.7363 - val_loss: 46.9069 - val_accuracy: 0.0255\n",
            "Epoch 245/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 0.9889 - accuracy: 0.7382 - val_loss: 47.5266 - val_accuracy: 0.0283\n",
            "Epoch 246/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0191 - accuracy: 0.7335 - val_loss: 47.5524 - val_accuracy: 0.0368\n",
            "Epoch 247/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.9809 - accuracy: 0.7410 - val_loss: 47.6433 - val_accuracy: 0.0255\n",
            "Epoch 248/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 0.9959 - accuracy: 0.7370 - val_loss: 47.5178 - val_accuracy: 0.0283\n",
            "Epoch 249/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 0.9733 - accuracy: 0.7407 - val_loss: 48.4170 - val_accuracy: 0.0312\n",
            "Epoch 250/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.9828 - accuracy: 0.7381 - val_loss: 48.5927 - val_accuracy: 0.0312\n",
            "Epoch 251/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 0.9794 - accuracy: 0.7435 - val_loss: 48.1410 - val_accuracy: 0.0283\n",
            "Epoch 252/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 0.9830 - accuracy: 0.7399 - val_loss: 48.6210 - val_accuracy: 0.0368\n",
            "Epoch 253/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 0.9929 - accuracy: 0.7385 - val_loss: 49.1292 - val_accuracy: 0.0340\n",
            "Epoch 254/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 1.0071 - accuracy: 0.7348 - val_loss: 49.3115 - val_accuracy: 0.0312\n",
            "Epoch 255/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.9711 - accuracy: 0.7384 - val_loss: 47.7395 - val_accuracy: 0.0312\n",
            "Epoch 256/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9889 - accuracy: 0.7375 - val_loss: 47.6253 - val_accuracy: 0.0312\n",
            "Epoch 257/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9989 - accuracy: 0.7343 - val_loss: 48.5168 - val_accuracy: 0.0198\n",
            "Epoch 258/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9591 - accuracy: 0.7491 - val_loss: 48.2577 - val_accuracy: 0.0312\n",
            "Epoch 259/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9385 - accuracy: 0.7515 - val_loss: 48.3066 - val_accuracy: 0.0283\n",
            "Epoch 260/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.9483 - accuracy: 0.7467 - val_loss: 49.1159 - val_accuracy: 0.0368\n",
            "Epoch 261/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9547 - accuracy: 0.7432 - val_loss: 48.7686 - val_accuracy: 0.0283\n",
            "Epoch 262/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.9921 - accuracy: 0.7385 - val_loss: 47.5615 - val_accuracy: 0.0312\n",
            "Epoch 263/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9838 - accuracy: 0.7406 - val_loss: 47.8311 - val_accuracy: 0.0312\n",
            "Epoch 264/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9799 - accuracy: 0.7417 - val_loss: 47.9250 - val_accuracy: 0.0340\n",
            "Epoch 265/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.9660 - accuracy: 0.7429 - val_loss: 49.1601 - val_accuracy: 0.0312\n",
            "Epoch 266/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.9884 - accuracy: 0.7394 - val_loss: 48.5839 - val_accuracy: 0.0397\n",
            "Epoch 267/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.9636 - accuracy: 0.7460 - val_loss: 48.5789 - val_accuracy: 0.0283\n",
            "Epoch 268/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.9621 - accuracy: 0.7467 - val_loss: 48.0583 - val_accuracy: 0.0255\n",
            "Epoch 269/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 0.9560 - accuracy: 0.7456 - val_loss: 49.2508 - val_accuracy: 0.0312\n",
            "Epoch 270/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.9397 - accuracy: 0.7504 - val_loss: 49.1543 - val_accuracy: 0.0340\n",
            "Epoch 271/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9378 - accuracy: 0.7504 - val_loss: 49.9492 - val_accuracy: 0.0340\n",
            "Epoch 272/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9458 - accuracy: 0.7530 - val_loss: 48.5164 - val_accuracy: 0.0227\n",
            "Epoch 273/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9627 - accuracy: 0.7496 - val_loss: 48.9911 - val_accuracy: 0.0312\n",
            "Epoch 274/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9656 - accuracy: 0.7456 - val_loss: 48.0774 - val_accuracy: 0.0227\n",
            "Epoch 275/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9756 - accuracy: 0.7413 - val_loss: 48.1001 - val_accuracy: 0.0227\n",
            "Epoch 276/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9741 - accuracy: 0.7469 - val_loss: 49.4782 - val_accuracy: 0.0198\n",
            "Epoch 277/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9437 - accuracy: 0.7499 - val_loss: 49.7078 - val_accuracy: 0.0227\n",
            "Epoch 278/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9386 - accuracy: 0.7488 - val_loss: 48.7197 - val_accuracy: 0.0198\n",
            "Epoch 279/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9549 - accuracy: 0.7445 - val_loss: 48.8690 - val_accuracy: 0.0255\n",
            "Epoch 280/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9648 - accuracy: 0.7443 - val_loss: 48.4345 - val_accuracy: 0.0255\n",
            "Epoch 281/400\n",
            "540/540 [==============================] - 9s 17ms/step - loss: 0.9462 - accuracy: 0.7525 - val_loss: 48.8174 - val_accuracy: 0.0283\n",
            "Epoch 282/400\n",
            "540/540 [==============================] - 9s 17ms/step - loss: 0.9582 - accuracy: 0.7502 - val_loss: 47.6416 - val_accuracy: 0.0255\n",
            "Epoch 283/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9094 - accuracy: 0.7593 - val_loss: 48.7137 - val_accuracy: 0.0283\n",
            "Epoch 284/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9392 - accuracy: 0.7507 - val_loss: 49.8678 - val_accuracy: 0.0255\n",
            "Epoch 285/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.9497 - accuracy: 0.7483 - val_loss: 49.1027 - val_accuracy: 0.0198\n",
            "Epoch 286/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9538 - accuracy: 0.7469 - val_loss: 49.7261 - val_accuracy: 0.0255\n",
            "Epoch 287/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9351 - accuracy: 0.7515 - val_loss: 48.4506 - val_accuracy: 0.0283\n",
            "Epoch 288/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.9212 - accuracy: 0.7597 - val_loss: 48.6636 - val_accuracy: 0.0368\n",
            "Epoch 289/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9292 - accuracy: 0.7557 - val_loss: 47.9889 - val_accuracy: 0.0340\n",
            "Epoch 290/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.9264 - accuracy: 0.7564 - val_loss: 48.8265 - val_accuracy: 0.0312\n",
            "Epoch 291/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9026 - accuracy: 0.7560 - val_loss: 49.6874 - val_accuracy: 0.0312\n",
            "Epoch 292/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.9308 - accuracy: 0.7534 - val_loss: 48.8319 - val_accuracy: 0.0283\n",
            "Epoch 293/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.9143 - accuracy: 0.7560 - val_loss: 47.6817 - val_accuracy: 0.0425\n",
            "Epoch 294/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.9331 - accuracy: 0.7521 - val_loss: 49.3470 - val_accuracy: 0.0283\n",
            "Epoch 295/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9229 - accuracy: 0.7540 - val_loss: 48.2129 - val_accuracy: 0.0283\n",
            "Epoch 296/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8892 - accuracy: 0.7597 - val_loss: 49.4887 - val_accuracy: 0.0227\n",
            "Epoch 297/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9439 - accuracy: 0.7510 - val_loss: 49.0215 - val_accuracy: 0.0283\n",
            "Epoch 298/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9239 - accuracy: 0.7561 - val_loss: 49.3024 - val_accuracy: 0.0283\n",
            "Epoch 299/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9119 - accuracy: 0.7573 - val_loss: 50.2708 - val_accuracy: 0.0312\n",
            "Epoch 300/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8965 - accuracy: 0.7614 - val_loss: 48.7363 - val_accuracy: 0.0227\n",
            "Epoch 301/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9145 - accuracy: 0.7588 - val_loss: 49.5397 - val_accuracy: 0.0283\n",
            "Epoch 302/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.9012 - accuracy: 0.7620 - val_loss: 49.8536 - val_accuracy: 0.0312\n",
            "Epoch 303/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9085 - accuracy: 0.7583 - val_loss: 49.9254 - val_accuracy: 0.0255\n",
            "Epoch 304/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9249 - accuracy: 0.7543 - val_loss: 49.5100 - val_accuracy: 0.0312\n",
            "Epoch 305/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.9130 - accuracy: 0.7556 - val_loss: 48.9153 - val_accuracy: 0.0312\n",
            "Epoch 306/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.8833 - accuracy: 0.7641 - val_loss: 49.5369 - val_accuracy: 0.0283\n",
            "Epoch 307/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9023 - accuracy: 0.7601 - val_loss: 50.3734 - val_accuracy: 0.0283\n",
            "Epoch 308/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.9129 - accuracy: 0.7611 - val_loss: 50.9656 - val_accuracy: 0.0227\n",
            "Epoch 309/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.8831 - accuracy: 0.7591 - val_loss: 50.6502 - val_accuracy: 0.0198\n",
            "Epoch 310/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.8755 - accuracy: 0.7621 - val_loss: 49.1368 - val_accuracy: 0.0255\n",
            "Epoch 311/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.9219 - accuracy: 0.7574 - val_loss: 49.2740 - val_accuracy: 0.0255\n",
            "Epoch 312/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9025 - accuracy: 0.7612 - val_loss: 50.1949 - val_accuracy: 0.0312\n",
            "Epoch 313/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.9031 - accuracy: 0.7619 - val_loss: 49.6441 - val_accuracy: 0.0283\n",
            "Epoch 314/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9284 - accuracy: 0.7579 - val_loss: 49.9318 - val_accuracy: 0.0255\n",
            "Epoch 315/400\n",
            "540/540 [==============================] - 8s 15ms/step - loss: 0.8941 - accuracy: 0.7656 - val_loss: 49.2914 - val_accuracy: 0.0255\n",
            "Epoch 316/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.9016 - accuracy: 0.7630 - val_loss: 48.4536 - val_accuracy: 0.0312\n",
            "Epoch 317/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.9004 - accuracy: 0.7629 - val_loss: 48.8792 - val_accuracy: 0.0227\n",
            "Epoch 318/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.8782 - accuracy: 0.7655 - val_loss: 47.9878 - val_accuracy: 0.0312\n",
            "Epoch 319/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.8743 - accuracy: 0.7635 - val_loss: 48.7896 - val_accuracy: 0.0312\n",
            "Epoch 320/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8799 - accuracy: 0.7634 - val_loss: 48.1379 - val_accuracy: 0.0227\n",
            "Epoch 321/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8968 - accuracy: 0.7649 - val_loss: 48.2486 - val_accuracy: 0.0227\n",
            "Epoch 322/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.8890 - accuracy: 0.7636 - val_loss: 49.0701 - val_accuracy: 0.0312\n",
            "Epoch 323/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.8751 - accuracy: 0.7674 - val_loss: 48.0037 - val_accuracy: 0.0312\n",
            "Epoch 324/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.8772 - accuracy: 0.7662 - val_loss: 48.3041 - val_accuracy: 0.0340\n",
            "Epoch 325/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.8934 - accuracy: 0.7610 - val_loss: 49.2027 - val_accuracy: 0.0255\n",
            "Epoch 326/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.8648 - accuracy: 0.7702 - val_loss: 49.3835 - val_accuracy: 0.0227\n",
            "Epoch 327/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8634 - accuracy: 0.7681 - val_loss: 49.3016 - val_accuracy: 0.0283\n",
            "Epoch 328/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8723 - accuracy: 0.7666 - val_loss: 48.6570 - val_accuracy: 0.0283\n",
            "Epoch 329/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.8694 - accuracy: 0.7702 - val_loss: 49.2537 - val_accuracy: 0.0255\n",
            "Epoch 330/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8741 - accuracy: 0.7633 - val_loss: 50.4222 - val_accuracy: 0.0368\n",
            "Epoch 331/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8670 - accuracy: 0.7714 - val_loss: 48.8299 - val_accuracy: 0.0312\n",
            "Epoch 332/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8572 - accuracy: 0.7691 - val_loss: 49.6051 - val_accuracy: 0.0283\n",
            "Epoch 333/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8859 - accuracy: 0.7659 - val_loss: 48.6780 - val_accuracy: 0.0283\n",
            "Epoch 334/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.8563 - accuracy: 0.7723 - val_loss: 48.3498 - val_accuracy: 0.0340\n",
            "Epoch 335/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8808 - accuracy: 0.7682 - val_loss: 48.2107 - val_accuracy: 0.0368\n",
            "Epoch 336/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8694 - accuracy: 0.7719 - val_loss: 49.5390 - val_accuracy: 0.0312\n",
            "Epoch 337/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8646 - accuracy: 0.7693 - val_loss: 49.0195 - val_accuracy: 0.0255\n",
            "Epoch 338/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8625 - accuracy: 0.7701 - val_loss: 49.2659 - val_accuracy: 0.0283\n",
            "Epoch 339/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8694 - accuracy: 0.7633 - val_loss: 50.0996 - val_accuracy: 0.0283\n",
            "Epoch 340/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.8640 - accuracy: 0.7707 - val_loss: 49.6752 - val_accuracy: 0.0425\n",
            "Epoch 341/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8536 - accuracy: 0.7708 - val_loss: 50.1076 - val_accuracy: 0.0283\n",
            "Epoch 342/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8854 - accuracy: 0.7682 - val_loss: 48.7883 - val_accuracy: 0.0340\n",
            "Epoch 343/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.8625 - accuracy: 0.7717 - val_loss: 49.5996 - val_accuracy: 0.0397\n",
            "Epoch 344/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8587 - accuracy: 0.7734 - val_loss: 48.8404 - val_accuracy: 0.0312\n",
            "Epoch 345/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8231 - accuracy: 0.7800 - val_loss: 49.0116 - val_accuracy: 0.0255\n",
            "Epoch 346/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8606 - accuracy: 0.7729 - val_loss: 49.3754 - val_accuracy: 0.0283\n",
            "Epoch 347/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8522 - accuracy: 0.7700 - val_loss: 48.9750 - val_accuracy: 0.0283\n",
            "Epoch 348/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8371 - accuracy: 0.7744 - val_loss: 49.9947 - val_accuracy: 0.0368\n",
            "Epoch 349/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8329 - accuracy: 0.7751 - val_loss: 49.0324 - val_accuracy: 0.0283\n",
            "Epoch 350/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.8473 - accuracy: 0.7732 - val_loss: 49.1945 - val_accuracy: 0.0283\n",
            "Epoch 351/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8534 - accuracy: 0.7742 - val_loss: 49.6923 - val_accuracy: 0.0283\n",
            "Epoch 352/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8420 - accuracy: 0.7739 - val_loss: 49.8345 - val_accuracy: 0.0340\n",
            "Epoch 353/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8682 - accuracy: 0.7735 - val_loss: 49.0387 - val_accuracy: 0.0340\n",
            "Epoch 354/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.8537 - accuracy: 0.7749 - val_loss: 50.4950 - val_accuracy: 0.0397\n",
            "Epoch 355/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.8466 - accuracy: 0.7759 - val_loss: 50.1515 - val_accuracy: 0.0283\n",
            "Epoch 356/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8450 - accuracy: 0.7726 - val_loss: 50.4218 - val_accuracy: 0.0255\n",
            "Epoch 357/400\n",
            "540/540 [==============================] - 8s 16ms/step - loss: 0.8084 - accuracy: 0.7813 - val_loss: 50.9258 - val_accuracy: 0.0312\n",
            "Epoch 358/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8449 - accuracy: 0.7718 - val_loss: 50.9182 - val_accuracy: 0.0397\n",
            "Epoch 359/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8459 - accuracy: 0.7736 - val_loss: 50.0645 - val_accuracy: 0.0368\n",
            "Epoch 360/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8629 - accuracy: 0.7740 - val_loss: 50.5358 - val_accuracy: 0.0312\n",
            "Epoch 361/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8669 - accuracy: 0.7736 - val_loss: 49.6663 - val_accuracy: 0.0255\n",
            "Epoch 362/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8579 - accuracy: 0.7750 - val_loss: 49.4349 - val_accuracy: 0.0312\n",
            "Epoch 363/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8428 - accuracy: 0.7744 - val_loss: 49.8518 - val_accuracy: 0.0368\n",
            "Epoch 364/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8555 - accuracy: 0.7737 - val_loss: 50.7617 - val_accuracy: 0.0312\n",
            "Epoch 365/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8466 - accuracy: 0.7741 - val_loss: 51.1578 - val_accuracy: 0.0312\n",
            "Epoch 366/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8269 - accuracy: 0.7810 - val_loss: 50.3581 - val_accuracy: 0.0283\n",
            "Epoch 367/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8200 - accuracy: 0.7785 - val_loss: 50.0768 - val_accuracy: 0.0340\n",
            "Epoch 368/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8014 - accuracy: 0.7860 - val_loss: 50.2028 - val_accuracy: 0.0340\n",
            "Epoch 369/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8425 - accuracy: 0.7762 - val_loss: 49.9670 - val_accuracy: 0.0340\n",
            "Epoch 370/400\n",
            "540/540 [==============================] - 9s 17ms/step - loss: 0.8198 - accuracy: 0.7756 - val_loss: 50.5591 - val_accuracy: 0.0312\n",
            "Epoch 371/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8445 - accuracy: 0.7798 - val_loss: 49.9288 - val_accuracy: 0.0283\n",
            "Epoch 372/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8299 - accuracy: 0.7812 - val_loss: 49.1149 - val_accuracy: 0.0397\n",
            "Epoch 373/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8375 - accuracy: 0.7791 - val_loss: 50.1734 - val_accuracy: 0.0368\n",
            "Epoch 374/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8272 - accuracy: 0.7807 - val_loss: 50.3432 - val_accuracy: 0.0255\n",
            "Epoch 375/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8537 - accuracy: 0.7751 - val_loss: 50.8890 - val_accuracy: 0.0283\n",
            "Epoch 376/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.7940 - accuracy: 0.7829 - val_loss: 50.0443 - val_accuracy: 0.0397\n",
            "Epoch 377/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8241 - accuracy: 0.7781 - val_loss: 49.6391 - val_accuracy: 0.0340\n",
            "Epoch 378/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8064 - accuracy: 0.7821 - val_loss: 50.4674 - val_accuracy: 0.0312\n",
            "Epoch 379/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8329 - accuracy: 0.7804 - val_loss: 50.2913 - val_accuracy: 0.0368\n",
            "Epoch 380/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8315 - accuracy: 0.7781 - val_loss: 50.8312 - val_accuracy: 0.0312\n",
            "Epoch 381/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8269 - accuracy: 0.7778 - val_loss: 51.8792 - val_accuracy: 0.0340\n",
            "Epoch 382/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8217 - accuracy: 0.7820 - val_loss: 51.5750 - val_accuracy: 0.0340\n",
            "Epoch 383/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8149 - accuracy: 0.7826 - val_loss: 51.2271 - val_accuracy: 0.0283\n",
            "Epoch 384/400\n",
            "540/540 [==============================] - 9s 17ms/step - loss: 0.8321 - accuracy: 0.7789 - val_loss: 50.9017 - val_accuracy: 0.0255\n",
            "Epoch 385/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8057 - accuracy: 0.7838 - val_loss: 51.5998 - val_accuracy: 0.0255\n",
            "Epoch 386/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8016 - accuracy: 0.7872 - val_loss: 50.4868 - val_accuracy: 0.0283\n",
            "Epoch 387/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.7869 - accuracy: 0.7914 - val_loss: 49.9655 - val_accuracy: 0.0283\n",
            "Epoch 388/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8201 - accuracy: 0.7810 - val_loss: 50.2137 - val_accuracy: 0.0368\n",
            "Epoch 389/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8325 - accuracy: 0.7788 - val_loss: 49.1431 - val_accuracy: 0.0312\n",
            "Epoch 390/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8292 - accuracy: 0.7806 - val_loss: 50.3814 - val_accuracy: 0.0340\n",
            "Epoch 391/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8209 - accuracy: 0.7828 - val_loss: 50.1670 - val_accuracy: 0.0255\n",
            "Epoch 392/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8224 - accuracy: 0.7823 - val_loss: 50.8967 - val_accuracy: 0.0368\n",
            "Epoch 393/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.7989 - accuracy: 0.7880 - val_loss: 50.1026 - val_accuracy: 0.0312\n",
            "Epoch 394/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8033 - accuracy: 0.7865 - val_loss: 50.9848 - val_accuracy: 0.0255\n",
            "Epoch 395/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8283 - accuracy: 0.7812 - val_loss: 50.6818 - val_accuracy: 0.0340\n",
            "Epoch 396/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.7863 - accuracy: 0.7892 - val_loss: 50.9106 - val_accuracy: 0.0397\n",
            "Epoch 397/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8174 - accuracy: 0.7815 - val_loss: 51.7196 - val_accuracy: 0.0397\n",
            "Epoch 398/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8140 - accuracy: 0.7881 - val_loss: 51.5012 - val_accuracy: 0.0340\n",
            "Epoch 399/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.8103 - accuracy: 0.7817 - val_loss: 51.8067 - val_accuracy: 0.0340\n",
            "Epoch 400/400\n",
            "540/540 [==============================] - 9s 16ms/step - loss: 0.7803 - accuracy: 0.7905 - val_loss: 50.9633 - val_accuracy: 0.0340\n"
          ]
        }
      ],
      "source": [
        "hist = model.fit(x_data, y_data, epochs=400, validation_split=0.02)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "q_orBXOrCsNn",
        "outputId": "82e51d36-097b-4e8c-fe36-c969c3636e97"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Entrenamiento\n",
        "epoch_count = range(1, len(hist.history['accuracy']) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=hist.history['accuracy'], label='train')\n",
        "sns.lineplot(x=epoch_count,  y=hist.history['val_accuracy'], label='valid')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Modelo 2"
      ],
      "metadata": {
        "id": "8JEYrGNTcdXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential()\n",
        "\n",
        "# Embedding:\n",
        "# input_seq_len = 3 --> ingreso 3 palabras\n",
        "# input_dim = vocab_size --> 1628 palabras distintas\n",
        "# output_dim = 5 --> crear embeddings de tamaño 3 (tamaño variable y ajustable)\n",
        "model2.add(Embedding(input_dim=vocab_size+1, output_dim=5, input_length=input_seq_len))\n",
        "model2.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model2.add(Dropout(0.3))\n",
        "model2.add(Bidirectional(LSTM(128,return_sequences=True)))\n",
        "model2.add(Dropout(0.1))\n",
        "model2.add(Bidirectional(LSTM(128))) # La última capa LSTM no lleva return_sequences\n",
        "model2.add(Dense(32, activation='relu'))\n",
        "\n",
        "# Predicción de clasificación con softmax\n",
        "# La salida vuelve al espacio de 1628 palabras posibles\n",
        "model2.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "# Clasificación multiple categórica --> loss = categorical_crossentropy\n",
        "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model2.summary()"
      ],
      "metadata": {
        "id": "gfPPwOqech16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c79bcee0-5e04-47e4-aa1f-a4419ceb8083"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 3, 5)              16130     \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirectio  (None, 3, 128)           35840     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 3, 128)            0         \n",
            "                                                                 \n",
            " bidirectional_5 (Bidirectio  (None, 3, 256)           263168    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 3, 256)            0         \n",
            "                                                                 \n",
            " bidirectional_6 (Bidirectio  (None, 256)              394240    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                8224      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3225)              106425    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 824,027\n",
            "Trainable params: 824,027\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model2.fit(x_data, y_data, epochs=400, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFZ3JxeViFyZ",
        "outputId": "571fabb9-b2c2-4bd9-8daa-dd3abcecd5ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "441/441 [==============================] - 20s 18ms/step - loss: 6.8280 - accuracy: 0.0260 - val_loss: 6.6968 - val_accuracy: 0.0261\n",
            "Epoch 2/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 6.4094 - accuracy: 0.0269 - val_loss: 6.8044 - val_accuracy: 0.0261\n",
            "Epoch 3/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 6.2812 - accuracy: 0.0279 - val_loss: 6.8838 - val_accuracy: 0.0281\n",
            "Epoch 4/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 6.1555 - accuracy: 0.0316 - val_loss: 7.0950 - val_accuracy: 0.0287\n",
            "Epoch 5/400\n",
            "441/441 [==============================] - 6s 15ms/step - loss: 6.0609 - accuracy: 0.0346 - val_loss: 7.2561 - val_accuracy: 0.0309\n",
            "Epoch 6/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 5.9873 - accuracy: 0.0375 - val_loss: 7.2747 - val_accuracy: 0.0227\n",
            "Epoch 7/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 5.9219 - accuracy: 0.0378 - val_loss: 7.5265 - val_accuracy: 0.0335\n",
            "Epoch 8/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 5.8536 - accuracy: 0.0392 - val_loss: 7.4416 - val_accuracy: 0.0281\n",
            "Epoch 9/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 5.7738 - accuracy: 0.0412 - val_loss: 7.6930 - val_accuracy: 0.0360\n",
            "Epoch 10/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 5.6958 - accuracy: 0.0475 - val_loss: 7.8737 - val_accuracy: 0.0352\n",
            "Epoch 11/400\n",
            "441/441 [==============================] - 7s 16ms/step - loss: 5.6181 - accuracy: 0.0456 - val_loss: 8.1254 - val_accuracy: 0.0289\n",
            "Epoch 12/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 5.5509 - accuracy: 0.0480 - val_loss: 8.3127 - val_accuracy: 0.0341\n",
            "Epoch 13/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 5.4778 - accuracy: 0.0492 - val_loss: 8.7138 - val_accuracy: 0.0346\n",
            "Epoch 14/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 5.3981 - accuracy: 0.0522 - val_loss: 8.4875 - val_accuracy: 0.0326\n",
            "Epoch 15/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 5.3192 - accuracy: 0.0573 - val_loss: 8.6205 - val_accuracy: 0.0292\n",
            "Epoch 16/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 5.2369 - accuracy: 0.0609 - val_loss: 9.0036 - val_accuracy: 0.0312\n",
            "Epoch 17/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 5.1534 - accuracy: 0.0671 - val_loss: 9.1381 - val_accuracy: 0.0346\n",
            "Epoch 18/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 5.0857 - accuracy: 0.0710 - val_loss: 9.4902 - val_accuracy: 0.0318\n",
            "Epoch 19/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 5.0095 - accuracy: 0.0753 - val_loss: 9.6148 - val_accuracy: 0.0306\n",
            "Epoch 20/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 4.9437 - accuracy: 0.0794 - val_loss: 9.8032 - val_accuracy: 0.0292\n",
            "Epoch 21/400\n",
            "441/441 [==============================] - 7s 15ms/step - loss: 4.8715 - accuracy: 0.0825 - val_loss: 10.1773 - val_accuracy: 0.0315\n",
            "Epoch 22/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 4.8109 - accuracy: 0.0880 - val_loss: 10.1441 - val_accuracy: 0.0250\n",
            "Epoch 23/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 4.7404 - accuracy: 0.0909 - val_loss: 10.7407 - val_accuracy: 0.0264\n",
            "Epoch 24/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 4.6768 - accuracy: 0.0945 - val_loss: 10.9271 - val_accuracy: 0.0275\n",
            "Epoch 25/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 4.6248 - accuracy: 0.0964 - val_loss: 11.2545 - val_accuracy: 0.0275\n",
            "Epoch 26/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 4.5653 - accuracy: 0.1063 - val_loss: 11.5292 - val_accuracy: 0.0267\n",
            "Epoch 27/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 4.5108 - accuracy: 0.1084 - val_loss: 11.7953 - val_accuracy: 0.0309\n",
            "Epoch 28/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 4.4439 - accuracy: 0.1120 - val_loss: 12.0449 - val_accuracy: 0.0264\n",
            "Epoch 29/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 4.3962 - accuracy: 0.1155 - val_loss: 12.4162 - val_accuracy: 0.0295\n",
            "Epoch 30/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 4.3531 - accuracy: 0.1162 - val_loss: 12.6343 - val_accuracy: 0.0221\n",
            "Epoch 31/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 4.2901 - accuracy: 0.1216 - val_loss: 13.1901 - val_accuracy: 0.0250\n",
            "Epoch 32/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 4.2332 - accuracy: 0.1261 - val_loss: 13.2876 - val_accuracy: 0.0287\n",
            "Epoch 33/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 4.1854 - accuracy: 0.1300 - val_loss: 13.5872 - val_accuracy: 0.0241\n",
            "Epoch 34/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 4.1422 - accuracy: 0.1296 - val_loss: 14.1480 - val_accuracy: 0.0230\n",
            "Epoch 35/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 4.1060 - accuracy: 0.1350 - val_loss: 14.2220 - val_accuracy: 0.0287\n",
            "Epoch 36/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 4.0525 - accuracy: 0.1369 - val_loss: 14.8869 - val_accuracy: 0.0247\n",
            "Epoch 37/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 4.0113 - accuracy: 0.1419 - val_loss: 15.0681 - val_accuracy: 0.0233\n",
            "Epoch 38/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 3.9614 - accuracy: 0.1440 - val_loss: 15.2885 - val_accuracy: 0.0216\n",
            "Epoch 39/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 3.9191 - accuracy: 0.1490 - val_loss: 15.6856 - val_accuracy: 0.0201\n",
            "Epoch 40/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 3.8870 - accuracy: 0.1540 - val_loss: 16.0672 - val_accuracy: 0.0213\n",
            "Epoch 41/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 3.8529 - accuracy: 0.1570 - val_loss: 16.2743 - val_accuracy: 0.0196\n",
            "Epoch 42/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 3.8085 - accuracy: 0.1612 - val_loss: 16.9033 - val_accuracy: 0.0207\n",
            "Epoch 43/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 3.7912 - accuracy: 0.1611 - val_loss: 16.6968 - val_accuracy: 0.0173\n",
            "Epoch 44/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 3.7196 - accuracy: 0.1717 - val_loss: 17.1580 - val_accuracy: 0.0199\n",
            "Epoch 45/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 3.6925 - accuracy: 0.1720 - val_loss: 17.4316 - val_accuracy: 0.0173\n",
            "Epoch 46/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 3.6626 - accuracy: 0.1768 - val_loss: 17.7494 - val_accuracy: 0.0190\n",
            "Epoch 47/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 3.6222 - accuracy: 0.1830 - val_loss: 18.0910 - val_accuracy: 0.0187\n",
            "Epoch 48/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 3.5870 - accuracy: 0.1890 - val_loss: 18.4135 - val_accuracy: 0.0190\n",
            "Epoch 49/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 3.5703 - accuracy: 0.1865 - val_loss: 18.1963 - val_accuracy: 0.0204\n",
            "Epoch 50/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 3.5333 - accuracy: 0.1932 - val_loss: 18.7805 - val_accuracy: 0.0196\n",
            "Epoch 51/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 3.4694 - accuracy: 0.1998 - val_loss: 19.3056 - val_accuracy: 0.0213\n",
            "Epoch 52/400\n",
            "441/441 [==============================] - 6s 15ms/step - loss: 3.4459 - accuracy: 0.2025 - val_loss: 18.7434 - val_accuracy: 0.0182\n",
            "Epoch 53/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 3.4168 - accuracy: 0.2074 - val_loss: 19.6514 - val_accuracy: 0.0162\n",
            "Epoch 54/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 3.3885 - accuracy: 0.2143 - val_loss: 19.8106 - val_accuracy: 0.0173\n",
            "Epoch 55/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 3.3456 - accuracy: 0.2165 - val_loss: 20.1838 - val_accuracy: 0.0173\n",
            "Epoch 56/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 3.3243 - accuracy: 0.2232 - val_loss: 20.8563 - val_accuracy: 0.0193\n",
            "Epoch 57/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 3.2828 - accuracy: 0.2322 - val_loss: 20.4956 - val_accuracy: 0.0173\n",
            "Epoch 58/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 3.2405 - accuracy: 0.2353 - val_loss: 21.0214 - val_accuracy: 0.0184\n",
            "Epoch 59/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 3.2316 - accuracy: 0.2425 - val_loss: 21.1025 - val_accuracy: 0.0170\n",
            "Epoch 60/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 3.1847 - accuracy: 0.2488 - val_loss: 21.2683 - val_accuracy: 0.0148\n",
            "Epoch 61/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 3.1493 - accuracy: 0.2512 - val_loss: 21.5571 - val_accuracy: 0.0165\n",
            "Epoch 62/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 3.1159 - accuracy: 0.2591 - val_loss: 21.9960 - val_accuracy: 0.0167\n",
            "Epoch 63/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 3.1030 - accuracy: 0.2612 - val_loss: 21.8571 - val_accuracy: 0.0165\n",
            "Epoch 64/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 3.0666 - accuracy: 0.2663 - val_loss: 22.1695 - val_accuracy: 0.0165\n",
            "Epoch 65/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 3.0300 - accuracy: 0.2748 - val_loss: 23.2452 - val_accuracy: 0.0165\n",
            "Epoch 66/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 3.0008 - accuracy: 0.2825 - val_loss: 22.6868 - val_accuracy: 0.0167\n",
            "Epoch 67/400\n",
            "441/441 [==============================] - 6s 15ms/step - loss: 2.9746 - accuracy: 0.2885 - val_loss: 23.3471 - val_accuracy: 0.0162\n",
            "Epoch 68/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 2.9311 - accuracy: 0.2904 - val_loss: 23.1757 - val_accuracy: 0.0167\n",
            "Epoch 69/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 2.9114 - accuracy: 0.2972 - val_loss: 23.7097 - val_accuracy: 0.0176\n",
            "Epoch 70/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 2.8908 - accuracy: 0.3012 - val_loss: 23.7200 - val_accuracy: 0.0165\n",
            "Epoch 71/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 2.8658 - accuracy: 0.3061 - val_loss: 23.9947 - val_accuracy: 0.0145\n",
            "Epoch 72/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 2.8368 - accuracy: 0.3115 - val_loss: 23.7998 - val_accuracy: 0.0139\n",
            "Epoch 73/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 2.7907 - accuracy: 0.3161 - val_loss: 24.0022 - val_accuracy: 0.0159\n",
            "Epoch 74/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 2.7791 - accuracy: 0.3211 - val_loss: 24.5029 - val_accuracy: 0.0167\n",
            "Epoch 75/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 2.7453 - accuracy: 0.3266 - val_loss: 24.3117 - val_accuracy: 0.0173\n",
            "Epoch 76/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 2.7100 - accuracy: 0.3359 - val_loss: 24.7566 - val_accuracy: 0.0148\n",
            "Epoch 77/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 2.6854 - accuracy: 0.3411 - val_loss: 25.0376 - val_accuracy: 0.0170\n",
            "Epoch 78/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 2.6665 - accuracy: 0.3458 - val_loss: 24.7758 - val_accuracy: 0.0165\n",
            "Epoch 79/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 2.6272 - accuracy: 0.3528 - val_loss: 25.0681 - val_accuracy: 0.0131\n",
            "Epoch 80/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 2.6125 - accuracy: 0.3528 - val_loss: 25.6262 - val_accuracy: 0.0170\n",
            "Epoch 81/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 2.5715 - accuracy: 0.3661 - val_loss: 26.1112 - val_accuracy: 0.0150\n",
            "Epoch 82/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 2.5610 - accuracy: 0.3642 - val_loss: 26.0103 - val_accuracy: 0.0153\n",
            "Epoch 83/400\n",
            "441/441 [==============================] - 6s 15ms/step - loss: 2.5340 - accuracy: 0.3730 - val_loss: 26.2908 - val_accuracy: 0.0159\n",
            "Epoch 84/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 2.4822 - accuracy: 0.3856 - val_loss: 26.4912 - val_accuracy: 0.0153\n",
            "Epoch 85/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 2.4518 - accuracy: 0.3891 - val_loss: 26.4653 - val_accuracy: 0.0173\n",
            "Epoch 86/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 2.4487 - accuracy: 0.3845 - val_loss: 26.3844 - val_accuracy: 0.0150\n",
            "Epoch 87/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 2.4007 - accuracy: 0.3994 - val_loss: 26.8039 - val_accuracy: 0.0136\n",
            "Epoch 88/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 2.3996 - accuracy: 0.4001 - val_loss: 26.9658 - val_accuracy: 0.0142\n",
            "Epoch 89/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 2.3792 - accuracy: 0.4026 - val_loss: 26.9783 - val_accuracy: 0.0162\n",
            "Epoch 90/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 2.3370 - accuracy: 0.4103 - val_loss: 27.4874 - val_accuracy: 0.0156\n",
            "Epoch 91/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 2.3260 - accuracy: 0.4125 - val_loss: 27.5668 - val_accuracy: 0.0148\n",
            "Epoch 92/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 2.3019 - accuracy: 0.4213 - val_loss: 27.3327 - val_accuracy: 0.0153\n",
            "Epoch 93/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 2.2536 - accuracy: 0.4344 - val_loss: 28.1356 - val_accuracy: 0.0170\n",
            "Epoch 94/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 2.2553 - accuracy: 0.4311 - val_loss: 28.1289 - val_accuracy: 0.0159\n",
            "Epoch 95/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 2.2312 - accuracy: 0.4325 - val_loss: 28.1308 - val_accuracy: 0.0142\n",
            "Epoch 96/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 2.2088 - accuracy: 0.4443 - val_loss: 28.3922 - val_accuracy: 0.0145\n",
            "Epoch 97/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 2.1878 - accuracy: 0.4437 - val_loss: 28.6380 - val_accuracy: 0.0167\n",
            "Epoch 98/400\n",
            "441/441 [==============================] - 6s 15ms/step - loss: 2.1658 - accuracy: 0.4457 - val_loss: 28.6247 - val_accuracy: 0.0165\n",
            "Epoch 99/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 2.1205 - accuracy: 0.4565 - val_loss: 28.7756 - val_accuracy: 0.0153\n",
            "Epoch 100/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 2.0882 - accuracy: 0.4678 - val_loss: 28.7134 - val_accuracy: 0.0148\n",
            "Epoch 101/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 2.0785 - accuracy: 0.4725 - val_loss: 29.0600 - val_accuracy: 0.0148\n",
            "Epoch 102/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 2.0554 - accuracy: 0.4759 - val_loss: 29.3477 - val_accuracy: 0.0162\n",
            "Epoch 103/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 2.0447 - accuracy: 0.4808 - val_loss: 29.2282 - val_accuracy: 0.0148\n",
            "Epoch 104/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 2.0231 - accuracy: 0.4789 - val_loss: 29.4138 - val_accuracy: 0.0116\n",
            "Epoch 105/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 2.0004 - accuracy: 0.4824 - val_loss: 29.0632 - val_accuracy: 0.0142\n",
            "Epoch 106/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.9780 - accuracy: 0.4930 - val_loss: 30.0462 - val_accuracy: 0.0162\n",
            "Epoch 107/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.9344 - accuracy: 0.5018 - val_loss: 30.2085 - val_accuracy: 0.0145\n",
            "Epoch 108/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.9395 - accuracy: 0.4985 - val_loss: 29.9403 - val_accuracy: 0.0145\n",
            "Epoch 109/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.9012 - accuracy: 0.5033 - val_loss: 30.2528 - val_accuracy: 0.0142\n",
            "Epoch 110/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.8831 - accuracy: 0.5130 - val_loss: 30.2360 - val_accuracy: 0.0167\n",
            "Epoch 111/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.8667 - accuracy: 0.5173 - val_loss: 30.5702 - val_accuracy: 0.0142\n",
            "Epoch 112/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.8398 - accuracy: 0.5213 - val_loss: 30.9475 - val_accuracy: 0.0139\n",
            "Epoch 113/400\n",
            "441/441 [==============================] - 6s 15ms/step - loss: 1.8221 - accuracy: 0.5250 - val_loss: 31.0622 - val_accuracy: 0.0125\n",
            "Epoch 114/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 1.8001 - accuracy: 0.5294 - val_loss: 30.9994 - val_accuracy: 0.0136\n",
            "Epoch 115/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.7762 - accuracy: 0.5362 - val_loss: 30.7237 - val_accuracy: 0.0150\n",
            "Epoch 116/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.7871 - accuracy: 0.5336 - val_loss: 31.3155 - val_accuracy: 0.0136\n",
            "Epoch 117/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.7320 - accuracy: 0.5512 - val_loss: 31.3904 - val_accuracy: 0.0122\n",
            "Epoch 118/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.7414 - accuracy: 0.5490 - val_loss: 31.9095 - val_accuracy: 0.0142\n",
            "Epoch 119/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.7215 - accuracy: 0.5492 - val_loss: 31.7919 - val_accuracy: 0.0142\n",
            "Epoch 120/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.6777 - accuracy: 0.5602 - val_loss: 32.2475 - val_accuracy: 0.0167\n",
            "Epoch 121/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.6758 - accuracy: 0.5615 - val_loss: 32.1781 - val_accuracy: 0.0150\n",
            "Epoch 122/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.6442 - accuracy: 0.5663 - val_loss: 32.2213 - val_accuracy: 0.0167\n",
            "Epoch 123/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.6355 - accuracy: 0.5715 - val_loss: 32.5232 - val_accuracy: 0.0145\n",
            "Epoch 124/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.6206 - accuracy: 0.5704 - val_loss: 32.5259 - val_accuracy: 0.0131\n",
            "Epoch 125/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.6182 - accuracy: 0.5731 - val_loss: 32.1205 - val_accuracy: 0.0148\n",
            "Epoch 126/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.5908 - accuracy: 0.5825 - val_loss: 32.5807 - val_accuracy: 0.0131\n",
            "Epoch 127/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.5729 - accuracy: 0.5823 - val_loss: 32.9089 - val_accuracy: 0.0102\n",
            "Epoch 128/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.5477 - accuracy: 0.5908 - val_loss: 32.7011 - val_accuracy: 0.0133\n",
            "Epoch 129/400\n",
            "441/441 [==============================] - 6s 15ms/step - loss: 1.5396 - accuracy: 0.5927 - val_loss: 33.5081 - val_accuracy: 0.0148\n",
            "Epoch 130/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.5158 - accuracy: 0.5989 - val_loss: 32.7797 - val_accuracy: 0.0159\n",
            "Epoch 131/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.4748 - accuracy: 0.6055 - val_loss: 33.4505 - val_accuracy: 0.0150\n",
            "Epoch 132/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 1.4591 - accuracy: 0.6130 - val_loss: 33.2219 - val_accuracy: 0.0128\n",
            "Epoch 133/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.4720 - accuracy: 0.6083 - val_loss: 34.0624 - val_accuracy: 0.0119\n",
            "Epoch 134/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.4535 - accuracy: 0.6152 - val_loss: 33.7410 - val_accuracy: 0.0139\n",
            "Epoch 135/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.4744 - accuracy: 0.6059 - val_loss: 33.6988 - val_accuracy: 0.0122\n",
            "Epoch 136/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 1.3985 - accuracy: 0.6246 - val_loss: 34.1894 - val_accuracy: 0.0156\n",
            "Epoch 137/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 1.4141 - accuracy: 0.6168 - val_loss: 33.8985 - val_accuracy: 0.0131\n",
            "Epoch 138/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.4052 - accuracy: 0.6245 - val_loss: 34.4106 - val_accuracy: 0.0196\n",
            "Epoch 139/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.3880 - accuracy: 0.6270 - val_loss: 33.9014 - val_accuracy: 0.0159\n",
            "Epoch 140/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 1.3633 - accuracy: 0.6346 - val_loss: 34.5799 - val_accuracy: 0.0145\n",
            "Epoch 141/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 1.3346 - accuracy: 0.6372 - val_loss: 34.3982 - val_accuracy: 0.0145\n",
            "Epoch 142/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.3336 - accuracy: 0.6423 - val_loss: 34.0746 - val_accuracy: 0.0156\n",
            "Epoch 143/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.3291 - accuracy: 0.6377 - val_loss: 35.0378 - val_accuracy: 0.0119\n",
            "Epoch 144/400\n",
            "441/441 [==============================] - 6s 15ms/step - loss: 1.3045 - accuracy: 0.6492 - val_loss: 35.2356 - val_accuracy: 0.0133\n",
            "Epoch 145/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.2850 - accuracy: 0.6517 - val_loss: 35.5443 - val_accuracy: 0.0114\n",
            "Epoch 146/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 1.2968 - accuracy: 0.6511 - val_loss: 35.0299 - val_accuracy: 0.0150\n",
            "Epoch 147/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 1.2727 - accuracy: 0.6550 - val_loss: 35.5705 - val_accuracy: 0.0148\n",
            "Epoch 148/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.2817 - accuracy: 0.6480 - val_loss: 35.8015 - val_accuracy: 0.0136\n",
            "Epoch 149/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.2202 - accuracy: 0.6701 - val_loss: 35.5219 - val_accuracy: 0.0133\n",
            "Epoch 150/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.2160 - accuracy: 0.6695 - val_loss: 35.9106 - val_accuracy: 0.0148\n",
            "Epoch 151/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.2402 - accuracy: 0.6641 - val_loss: 35.8452 - val_accuracy: 0.0119\n",
            "Epoch 152/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.2372 - accuracy: 0.6666 - val_loss: 36.0141 - val_accuracy: 0.0131\n",
            "Epoch 153/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.1869 - accuracy: 0.6807 - val_loss: 36.0494 - val_accuracy: 0.0150\n",
            "Epoch 154/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.1842 - accuracy: 0.6751 - val_loss: 36.1913 - val_accuracy: 0.0142\n",
            "Epoch 155/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.1773 - accuracy: 0.6793 - val_loss: 36.4492 - val_accuracy: 0.0122\n",
            "Epoch 156/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 1.1711 - accuracy: 0.6797 - val_loss: 36.2574 - val_accuracy: 0.0139\n",
            "Epoch 157/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.1523 - accuracy: 0.6878 - val_loss: 36.2359 - val_accuracy: 0.0148\n",
            "Epoch 158/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.1390 - accuracy: 0.6885 - val_loss: 36.8911 - val_accuracy: 0.0114\n",
            "Epoch 159/400\n",
            "441/441 [==============================] - 7s 15ms/step - loss: 1.1337 - accuracy: 0.6890 - val_loss: 37.2716 - val_accuracy: 0.0131\n",
            "Epoch 160/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.1404 - accuracy: 0.6889 - val_loss: 36.8461 - val_accuracy: 0.0119\n",
            "Epoch 161/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.1109 - accuracy: 0.6949 - val_loss: 37.7385 - val_accuracy: 0.0122\n",
            "Epoch 162/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.0956 - accuracy: 0.6988 - val_loss: 37.4453 - val_accuracy: 0.0142\n",
            "Epoch 163/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.0924 - accuracy: 0.7022 - val_loss: 37.3702 - val_accuracy: 0.0145\n",
            "Epoch 164/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.0768 - accuracy: 0.7024 - val_loss: 37.5549 - val_accuracy: 0.0125\n",
            "Epoch 165/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.0899 - accuracy: 0.6971 - val_loss: 37.5314 - val_accuracy: 0.0139\n",
            "Epoch 166/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.0570 - accuracy: 0.7156 - val_loss: 37.9747 - val_accuracy: 0.0131\n",
            "Epoch 167/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.0665 - accuracy: 0.7083 - val_loss: 37.8656 - val_accuracy: 0.0179\n",
            "Epoch 168/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.0330 - accuracy: 0.7145 - val_loss: 37.7215 - val_accuracy: 0.0133\n",
            "Epoch 169/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.0332 - accuracy: 0.7154 - val_loss: 37.5365 - val_accuracy: 0.0131\n",
            "Epoch 170/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.0133 - accuracy: 0.7188 - val_loss: 37.5275 - val_accuracy: 0.0148\n",
            "Epoch 171/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.9910 - accuracy: 0.7268 - val_loss: 37.9724 - val_accuracy: 0.0165\n",
            "Epoch 172/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.0155 - accuracy: 0.7213 - val_loss: 37.9567 - val_accuracy: 0.0128\n",
            "Epoch 173/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 1.0152 - accuracy: 0.7215 - val_loss: 38.9091 - val_accuracy: 0.0116\n",
            "Epoch 174/400\n",
            "441/441 [==============================] - 7s 15ms/step - loss: 0.9929 - accuracy: 0.7280 - val_loss: 38.9085 - val_accuracy: 0.0159\n",
            "Epoch 175/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.9809 - accuracy: 0.7315 - val_loss: 38.2931 - val_accuracy: 0.0167\n",
            "Epoch 176/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.9741 - accuracy: 0.7269 - val_loss: 38.5624 - val_accuracy: 0.0133\n",
            "Epoch 177/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.9541 - accuracy: 0.7395 - val_loss: 39.0304 - val_accuracy: 0.0125\n",
            "Epoch 178/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.9729 - accuracy: 0.7303 - val_loss: 38.6016 - val_accuracy: 0.0142\n",
            "Epoch 179/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.9521 - accuracy: 0.7383 - val_loss: 38.6679 - val_accuracy: 0.0148\n",
            "Epoch 180/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.9495 - accuracy: 0.7393 - val_loss: 39.1484 - val_accuracy: 0.0133\n",
            "Epoch 181/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.9522 - accuracy: 0.7403 - val_loss: 38.7317 - val_accuracy: 0.0153\n",
            "Epoch 182/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.9268 - accuracy: 0.7387 - val_loss: 39.1151 - val_accuracy: 0.0150\n",
            "Epoch 183/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.9132 - accuracy: 0.7445 - val_loss: 39.2625 - val_accuracy: 0.0139\n",
            "Epoch 184/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.9135 - accuracy: 0.7460 - val_loss: 39.0246 - val_accuracy: 0.0150\n",
            "Epoch 185/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.9132 - accuracy: 0.7443 - val_loss: 38.8626 - val_accuracy: 0.0139\n",
            "Epoch 186/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.8861 - accuracy: 0.7534 - val_loss: 39.3203 - val_accuracy: 0.0133\n",
            "Epoch 187/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.8877 - accuracy: 0.7467 - val_loss: 39.8563 - val_accuracy: 0.0162\n",
            "Epoch 188/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.8772 - accuracy: 0.7528 - val_loss: 39.7948 - val_accuracy: 0.0156\n",
            "Epoch 189/400\n",
            "441/441 [==============================] - 6s 15ms/step - loss: 0.8687 - accuracy: 0.7570 - val_loss: 39.7759 - val_accuracy: 0.0145\n",
            "Epoch 190/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.8829 - accuracy: 0.7539 - val_loss: 40.1909 - val_accuracy: 0.0159\n",
            "Epoch 191/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.8424 - accuracy: 0.7623 - val_loss: 39.9654 - val_accuracy: 0.0148\n",
            "Epoch 192/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.8518 - accuracy: 0.7640 - val_loss: 39.9981 - val_accuracy: 0.0145\n",
            "Epoch 193/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.8588 - accuracy: 0.7631 - val_loss: 40.4210 - val_accuracy: 0.0162\n",
            "Epoch 194/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.8531 - accuracy: 0.7602 - val_loss: 40.8587 - val_accuracy: 0.0142\n",
            "Epoch 195/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.8583 - accuracy: 0.7625 - val_loss: 40.3089 - val_accuracy: 0.0170\n",
            "Epoch 196/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.8157 - accuracy: 0.7693 - val_loss: 40.8944 - val_accuracy: 0.0136\n",
            "Epoch 197/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.8177 - accuracy: 0.7701 - val_loss: 40.8530 - val_accuracy: 0.0153\n",
            "Epoch 198/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.8100 - accuracy: 0.7708 - val_loss: 40.2178 - val_accuracy: 0.0176\n",
            "Epoch 199/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.8055 - accuracy: 0.7776 - val_loss: 40.7346 - val_accuracy: 0.0145\n",
            "Epoch 200/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.7754 - accuracy: 0.7797 - val_loss: 41.0001 - val_accuracy: 0.0148\n",
            "Epoch 201/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.8015 - accuracy: 0.7744 - val_loss: 40.8966 - val_accuracy: 0.0159\n",
            "Epoch 202/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.7815 - accuracy: 0.7808 - val_loss: 41.3246 - val_accuracy: 0.0145\n",
            "Epoch 203/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.7883 - accuracy: 0.7775 - val_loss: 40.7631 - val_accuracy: 0.0156\n",
            "Epoch 204/400\n",
            "441/441 [==============================] - 7s 15ms/step - loss: 0.8068 - accuracy: 0.7764 - val_loss: 41.1841 - val_accuracy: 0.0156\n",
            "Epoch 205/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.7689 - accuracy: 0.7829 - val_loss: 41.1041 - val_accuracy: 0.0167\n",
            "Epoch 206/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.7600 - accuracy: 0.7859 - val_loss: 41.6945 - val_accuracy: 0.0165\n",
            "Epoch 207/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.7642 - accuracy: 0.7826 - val_loss: 41.5880 - val_accuracy: 0.0145\n",
            "Epoch 208/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.7690 - accuracy: 0.7849 - val_loss: 41.7879 - val_accuracy: 0.0162\n",
            "Epoch 209/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.7547 - accuracy: 0.7890 - val_loss: 41.3166 - val_accuracy: 0.0167\n",
            "Epoch 210/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.7513 - accuracy: 0.7878 - val_loss: 41.6019 - val_accuracy: 0.0145\n",
            "Epoch 211/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.7272 - accuracy: 0.7961 - val_loss: 41.8692 - val_accuracy: 0.0165\n",
            "Epoch 212/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.7681 - accuracy: 0.7835 - val_loss: 41.6615 - val_accuracy: 0.0150\n",
            "Epoch 213/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.7362 - accuracy: 0.7921 - val_loss: 41.5270 - val_accuracy: 0.0156\n",
            "Epoch 214/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.7256 - accuracy: 0.7951 - val_loss: 41.9588 - val_accuracy: 0.0145\n",
            "Epoch 215/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.7135 - accuracy: 0.7981 - val_loss: 42.7463 - val_accuracy: 0.0179\n",
            "Epoch 216/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.6992 - accuracy: 0.8015 - val_loss: 42.0293 - val_accuracy: 0.0187\n",
            "Epoch 217/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.7136 - accuracy: 0.7999 - val_loss: 42.1629 - val_accuracy: 0.0162\n",
            "Epoch 218/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.7227 - accuracy: 0.7918 - val_loss: 41.6479 - val_accuracy: 0.0173\n",
            "Epoch 219/400\n",
            "441/441 [==============================] - 6s 15ms/step - loss: 0.7077 - accuracy: 0.7987 - val_loss: 41.9971 - val_accuracy: 0.0150\n",
            "Epoch 220/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.7085 - accuracy: 0.7983 - val_loss: 42.3222 - val_accuracy: 0.0153\n",
            "Epoch 221/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.7024 - accuracy: 0.8029 - val_loss: 42.7319 - val_accuracy: 0.0153\n",
            "Epoch 222/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.7141 - accuracy: 0.7961 - val_loss: 42.7360 - val_accuracy: 0.0176\n",
            "Epoch 223/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.6977 - accuracy: 0.8054 - val_loss: 42.8565 - val_accuracy: 0.0148\n",
            "Epoch 224/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.6974 - accuracy: 0.8029 - val_loss: 42.4725 - val_accuracy: 0.0153\n",
            "Epoch 225/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.6907 - accuracy: 0.8043 - val_loss: 42.8179 - val_accuracy: 0.0145\n",
            "Epoch 226/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.6898 - accuracy: 0.8062 - val_loss: 42.6513 - val_accuracy: 0.0182\n",
            "Epoch 227/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.6533 - accuracy: 0.8120 - val_loss: 43.0004 - val_accuracy: 0.0159\n",
            "Epoch 228/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.6766 - accuracy: 0.8061 - val_loss: 43.0275 - val_accuracy: 0.0136\n",
            "Epoch 229/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.6991 - accuracy: 0.8028 - val_loss: 42.8915 - val_accuracy: 0.0165\n",
            "Epoch 230/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.6688 - accuracy: 0.8110 - val_loss: 42.6939 - val_accuracy: 0.0131\n",
            "Epoch 231/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.6500 - accuracy: 0.8144 - val_loss: 43.3834 - val_accuracy: 0.0122\n",
            "Epoch 232/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.6498 - accuracy: 0.8161 - val_loss: 43.0390 - val_accuracy: 0.0173\n",
            "Epoch 233/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.6388 - accuracy: 0.8167 - val_loss: 43.1084 - val_accuracy: 0.0145\n",
            "Epoch 234/400\n",
            "441/441 [==============================] - 7s 15ms/step - loss: 0.6479 - accuracy: 0.8190 - val_loss: 43.1976 - val_accuracy: 0.0190\n",
            "Epoch 235/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.6724 - accuracy: 0.8107 - val_loss: 43.6801 - val_accuracy: 0.0176\n",
            "Epoch 236/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.6270 - accuracy: 0.8217 - val_loss: 44.1243 - val_accuracy: 0.0182\n",
            "Epoch 237/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.6261 - accuracy: 0.8230 - val_loss: 43.8824 - val_accuracy: 0.0150\n",
            "Epoch 238/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.6278 - accuracy: 0.8204 - val_loss: 43.6989 - val_accuracy: 0.0128\n",
            "Epoch 239/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.6532 - accuracy: 0.8203 - val_loss: 43.3617 - val_accuracy: 0.0165\n",
            "Epoch 240/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.6075 - accuracy: 0.8263 - val_loss: 43.6445 - val_accuracy: 0.0142\n",
            "Epoch 241/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.6200 - accuracy: 0.8252 - val_loss: 43.3246 - val_accuracy: 0.0148\n",
            "Epoch 242/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.6043 - accuracy: 0.8271 - val_loss: 44.1230 - val_accuracy: 0.0150\n",
            "Epoch 243/400\n",
            "441/441 [==============================] - 6s 13ms/step - loss: 0.6312 - accuracy: 0.8227 - val_loss: 43.7937 - val_accuracy: 0.0150\n",
            "Epoch 244/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.6482 - accuracy: 0.8174 - val_loss: 43.7823 - val_accuracy: 0.0122\n",
            "Epoch 245/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.6382 - accuracy: 0.8190 - val_loss: 43.4343 - val_accuracy: 0.0162\n",
            "Epoch 246/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.6035 - accuracy: 0.8250 - val_loss: 43.8410 - val_accuracy: 0.0159\n",
            "Epoch 247/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.6221 - accuracy: 0.8246 - val_loss: 44.0773 - val_accuracy: 0.0170\n",
            "Epoch 248/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.6120 - accuracy: 0.8289 - val_loss: 43.8334 - val_accuracy: 0.0133\n",
            "Epoch 249/400\n",
            "441/441 [==============================] - 7s 15ms/step - loss: 0.6147 - accuracy: 0.8241 - val_loss: 43.8026 - val_accuracy: 0.0139\n",
            "Epoch 250/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5734 - accuracy: 0.8354 - val_loss: 44.5363 - val_accuracy: 0.0156\n",
            "Epoch 251/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5879 - accuracy: 0.8327 - val_loss: 44.0804 - val_accuracy: 0.0136\n",
            "Epoch 252/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5949 - accuracy: 0.8303 - val_loss: 44.3398 - val_accuracy: 0.0176\n",
            "Epoch 253/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.6191 - accuracy: 0.8247 - val_loss: 44.2802 - val_accuracy: 0.0162\n",
            "Epoch 254/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.6074 - accuracy: 0.8288 - val_loss: 43.7743 - val_accuracy: 0.0131\n",
            "Epoch 255/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.6146 - accuracy: 0.8275 - val_loss: 43.9830 - val_accuracy: 0.0150\n",
            "Epoch 256/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5724 - accuracy: 0.8397 - val_loss: 44.5191 - val_accuracy: 0.0142\n",
            "Epoch 257/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5831 - accuracy: 0.8328 - val_loss: 44.7793 - val_accuracy: 0.0156\n",
            "Epoch 258/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5628 - accuracy: 0.8350 - val_loss: 44.5797 - val_accuracy: 0.0156\n",
            "Epoch 259/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5676 - accuracy: 0.8398 - val_loss: 44.7236 - val_accuracy: 0.0187\n",
            "Epoch 260/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5505 - accuracy: 0.8422 - val_loss: 45.2657 - val_accuracy: 0.0145\n",
            "Epoch 261/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5433 - accuracy: 0.8417 - val_loss: 44.8868 - val_accuracy: 0.0122\n",
            "Epoch 262/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5595 - accuracy: 0.8395 - val_loss: 44.4288 - val_accuracy: 0.0139\n",
            "Epoch 263/400\n",
            "441/441 [==============================] - 7s 15ms/step - loss: 0.5711 - accuracy: 0.8360 - val_loss: 44.9637 - val_accuracy: 0.0131\n",
            "Epoch 264/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5639 - accuracy: 0.8354 - val_loss: 44.7018 - val_accuracy: 0.0133\n",
            "Epoch 265/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5473 - accuracy: 0.8433 - val_loss: 44.5371 - val_accuracy: 0.0170\n",
            "Epoch 266/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5570 - accuracy: 0.8388 - val_loss: 44.6456 - val_accuracy: 0.0150\n",
            "Epoch 267/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5589 - accuracy: 0.8421 - val_loss: 44.8170 - val_accuracy: 0.0133\n",
            "Epoch 268/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5635 - accuracy: 0.8388 - val_loss: 44.6170 - val_accuracy: 0.0133\n",
            "Epoch 269/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5694 - accuracy: 0.8398 - val_loss: 44.9869 - val_accuracy: 0.0145\n",
            "Epoch 270/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5452 - accuracy: 0.8442 - val_loss: 45.1106 - val_accuracy: 0.0162\n",
            "Epoch 271/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5529 - accuracy: 0.8396 - val_loss: 45.7655 - val_accuracy: 0.0148\n",
            "Epoch 272/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5400 - accuracy: 0.8467 - val_loss: 45.2996 - val_accuracy: 0.0142\n",
            "Epoch 273/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5323 - accuracy: 0.8489 - val_loss: 45.3671 - val_accuracy: 0.0139\n",
            "Epoch 274/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5536 - accuracy: 0.8419 - val_loss: 45.1576 - val_accuracy: 0.0131\n",
            "Epoch 275/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5385 - accuracy: 0.8470 - val_loss: 45.3747 - val_accuracy: 0.0170\n",
            "Epoch 276/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5309 - accuracy: 0.8464 - val_loss: 45.8055 - val_accuracy: 0.0125\n",
            "Epoch 277/400\n",
            "441/441 [==============================] - 6s 15ms/step - loss: 0.5211 - accuracy: 0.8496 - val_loss: 45.6897 - val_accuracy: 0.0153\n",
            "Epoch 278/400\n",
            "441/441 [==============================] - 6s 15ms/step - loss: 0.4874 - accuracy: 0.8591 - val_loss: 45.2633 - val_accuracy: 0.0139\n",
            "Epoch 279/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5371 - accuracy: 0.8465 - val_loss: 45.4707 - val_accuracy: 0.0176\n",
            "Epoch 280/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5530 - accuracy: 0.8421 - val_loss: 45.4140 - val_accuracy: 0.0167\n",
            "Epoch 281/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5266 - accuracy: 0.8496 - val_loss: 45.8042 - val_accuracy: 0.0145\n",
            "Epoch 282/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5429 - accuracy: 0.8438 - val_loss: 45.6059 - val_accuracy: 0.0162\n",
            "Epoch 283/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5237 - accuracy: 0.8517 - val_loss: 46.4320 - val_accuracy: 0.0156\n",
            "Epoch 284/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5124 - accuracy: 0.8563 - val_loss: 46.4057 - val_accuracy: 0.0114\n",
            "Epoch 285/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4828 - accuracy: 0.8607 - val_loss: 46.3561 - val_accuracy: 0.0142\n",
            "Epoch 286/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5067 - accuracy: 0.8533 - val_loss: 46.1492 - val_accuracy: 0.0122\n",
            "Epoch 287/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4980 - accuracy: 0.8553 - val_loss: 46.4646 - val_accuracy: 0.0159\n",
            "Epoch 288/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5441 - accuracy: 0.8434 - val_loss: 46.3112 - val_accuracy: 0.0159\n",
            "Epoch 289/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5231 - accuracy: 0.8517 - val_loss: 46.1387 - val_accuracy: 0.0167\n",
            "Epoch 290/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5298 - accuracy: 0.8481 - val_loss: 46.0888 - val_accuracy: 0.0136\n",
            "Epoch 291/400\n",
            "441/441 [==============================] - 6s 15ms/step - loss: 0.4925 - accuracy: 0.8557 - val_loss: 46.8190 - val_accuracy: 0.0122\n",
            "Epoch 292/400\n",
            "441/441 [==============================] - 7s 15ms/step - loss: 0.4729 - accuracy: 0.8628 - val_loss: 46.3453 - val_accuracy: 0.0125\n",
            "Epoch 293/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4878 - accuracy: 0.8578 - val_loss: 46.6825 - val_accuracy: 0.0142\n",
            "Epoch 294/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5022 - accuracy: 0.8579 - val_loss: 46.9479 - val_accuracy: 0.0165\n",
            "Epoch 295/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5133 - accuracy: 0.8513 - val_loss: 46.5277 - val_accuracy: 0.0162\n",
            "Epoch 296/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4978 - accuracy: 0.8567 - val_loss: 46.3651 - val_accuracy: 0.0148\n",
            "Epoch 297/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4964 - accuracy: 0.8577 - val_loss: 45.9657 - val_accuracy: 0.0173\n",
            "Epoch 298/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4919 - accuracy: 0.8601 - val_loss: 46.0896 - val_accuracy: 0.0162\n",
            "Epoch 299/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4884 - accuracy: 0.8621 - val_loss: 46.1987 - val_accuracy: 0.0125\n",
            "Epoch 300/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5107 - accuracy: 0.8550 - val_loss: 46.8192 - val_accuracy: 0.0156\n",
            "Epoch 301/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4961 - accuracy: 0.8596 - val_loss: 46.2320 - val_accuracy: 0.0148\n",
            "Epoch 302/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4778 - accuracy: 0.8613 - val_loss: 46.3026 - val_accuracy: 0.0148\n",
            "Epoch 303/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.5037 - accuracy: 0.8597 - val_loss: 47.1979 - val_accuracy: 0.0145\n",
            "Epoch 304/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4816 - accuracy: 0.8640 - val_loss: 46.4872 - val_accuracy: 0.0159\n",
            "Epoch 305/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4964 - accuracy: 0.8601 - val_loss: 46.7478 - val_accuracy: 0.0153\n",
            "Epoch 306/400\n",
            "441/441 [==============================] - 7s 15ms/step - loss: 0.4695 - accuracy: 0.8598 - val_loss: 46.7724 - val_accuracy: 0.0156\n",
            "Epoch 307/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4910 - accuracy: 0.8619 - val_loss: 46.8429 - val_accuracy: 0.0150\n",
            "Epoch 308/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4608 - accuracy: 0.8677 - val_loss: 46.9738 - val_accuracy: 0.0153\n",
            "Epoch 309/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4628 - accuracy: 0.8648 - val_loss: 46.4261 - val_accuracy: 0.0150\n",
            "Epoch 310/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4716 - accuracy: 0.8639 - val_loss: 46.7995 - val_accuracy: 0.0156\n",
            "Epoch 311/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4578 - accuracy: 0.8702 - val_loss: 47.0725 - val_accuracy: 0.0167\n",
            "Epoch 312/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4756 - accuracy: 0.8649 - val_loss: 46.6980 - val_accuracy: 0.0150\n",
            "Epoch 313/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4670 - accuracy: 0.8644 - val_loss: 47.7829 - val_accuracy: 0.0131\n",
            "Epoch 314/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4640 - accuracy: 0.8669 - val_loss: 47.6646 - val_accuracy: 0.0131\n",
            "Epoch 315/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4625 - accuracy: 0.8658 - val_loss: 47.1876 - val_accuracy: 0.0182\n",
            "Epoch 316/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4622 - accuracy: 0.8674 - val_loss: 47.4368 - val_accuracy: 0.0139\n",
            "Epoch 317/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4938 - accuracy: 0.8598 - val_loss: 47.6915 - val_accuracy: 0.0159\n",
            "Epoch 318/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4678 - accuracy: 0.8620 - val_loss: 46.6964 - val_accuracy: 0.0133\n",
            "Epoch 319/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4613 - accuracy: 0.8671 - val_loss: 47.2443 - val_accuracy: 0.0156\n",
            "Epoch 320/400\n",
            "441/441 [==============================] - 7s 15ms/step - loss: 0.4303 - accuracy: 0.8759 - val_loss: 47.1662 - val_accuracy: 0.0182\n",
            "Epoch 321/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4600 - accuracy: 0.8693 - val_loss: 47.3108 - val_accuracy: 0.0150\n",
            "Epoch 322/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4669 - accuracy: 0.8660 - val_loss: 47.6887 - val_accuracy: 0.0150\n",
            "Epoch 323/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4483 - accuracy: 0.8729 - val_loss: 47.8946 - val_accuracy: 0.0145\n",
            "Epoch 324/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4469 - accuracy: 0.8733 - val_loss: 47.9254 - val_accuracy: 0.0150\n",
            "Epoch 325/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4305 - accuracy: 0.8752 - val_loss: 47.5344 - val_accuracy: 0.0148\n",
            "Epoch 326/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4569 - accuracy: 0.8674 - val_loss: 47.7315 - val_accuracy: 0.0170\n",
            "Epoch 327/400\n",
            "441/441 [==============================] - 6s 15ms/step - loss: 0.4266 - accuracy: 0.8748 - val_loss: 47.8591 - val_accuracy: 0.0153\n",
            "Epoch 328/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4537 - accuracy: 0.8683 - val_loss: 47.4613 - val_accuracy: 0.0122\n",
            "Epoch 329/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4494 - accuracy: 0.8742 - val_loss: 48.3910 - val_accuracy: 0.0145\n",
            "Epoch 330/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4373 - accuracy: 0.8763 - val_loss: 48.3134 - val_accuracy: 0.0125\n",
            "Epoch 331/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4495 - accuracy: 0.8673 - val_loss: 47.7361 - val_accuracy: 0.0125\n",
            "Epoch 332/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4344 - accuracy: 0.8757 - val_loss: 48.1101 - val_accuracy: 0.0153\n",
            "Epoch 333/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4383 - accuracy: 0.8729 - val_loss: 48.4636 - val_accuracy: 0.0142\n",
            "Epoch 334/400\n",
            "441/441 [==============================] - 7s 15ms/step - loss: 0.4492 - accuracy: 0.8721 - val_loss: 48.5257 - val_accuracy: 0.0150\n",
            "Epoch 335/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4112 - accuracy: 0.8785 - val_loss: 47.4932 - val_accuracy: 0.0150\n",
            "Epoch 336/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4188 - accuracy: 0.8777 - val_loss: 48.1935 - val_accuracy: 0.0162\n",
            "Epoch 337/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4355 - accuracy: 0.8747 - val_loss: 47.9616 - val_accuracy: 0.0145\n",
            "Epoch 338/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4300 - accuracy: 0.8740 - val_loss: 47.5719 - val_accuracy: 0.0116\n",
            "Epoch 339/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4307 - accuracy: 0.8750 - val_loss: 48.1724 - val_accuracy: 0.0148\n",
            "Epoch 340/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4174 - accuracy: 0.8756 - val_loss: 47.9981 - val_accuracy: 0.0145\n",
            "Epoch 341/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4278 - accuracy: 0.8792 - val_loss: 47.6126 - val_accuracy: 0.0139\n",
            "Epoch 342/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4556 - accuracy: 0.8679 - val_loss: 47.9573 - val_accuracy: 0.0136\n",
            "Epoch 343/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4239 - accuracy: 0.8745 - val_loss: 48.8582 - val_accuracy: 0.0139\n",
            "Epoch 344/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4478 - accuracy: 0.8680 - val_loss: 48.1309 - val_accuracy: 0.0156\n",
            "Epoch 345/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4205 - accuracy: 0.8779 - val_loss: 48.5601 - val_accuracy: 0.0145\n",
            "Epoch 346/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4193 - accuracy: 0.8750 - val_loss: 48.6899 - val_accuracy: 0.0150\n",
            "Epoch 347/400\n",
            "441/441 [==============================] - 7s 15ms/step - loss: 0.4143 - accuracy: 0.8781 - val_loss: 49.0781 - val_accuracy: 0.0165\n",
            "Epoch 348/400\n",
            "441/441 [==============================] - 6s 15ms/step - loss: 0.4157 - accuracy: 0.8777 - val_loss: 48.2457 - val_accuracy: 0.0139\n",
            "Epoch 349/400\n",
            "441/441 [==============================] - 6s 15ms/step - loss: 0.4167 - accuracy: 0.8792 - val_loss: 48.9466 - val_accuracy: 0.0153\n",
            "Epoch 350/400\n",
            "441/441 [==============================] - 6s 15ms/step - loss: 0.4437 - accuracy: 0.8733 - val_loss: 48.7979 - val_accuracy: 0.0136\n",
            "Epoch 351/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4152 - accuracy: 0.8804 - val_loss: 47.9415 - val_accuracy: 0.0170\n",
            "Epoch 352/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4273 - accuracy: 0.8759 - val_loss: 48.3384 - val_accuracy: 0.0173\n",
            "Epoch 353/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4105 - accuracy: 0.8778 - val_loss: 48.0861 - val_accuracy: 0.0153\n",
            "Epoch 354/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4249 - accuracy: 0.8745 - val_loss: 48.4056 - val_accuracy: 0.0131\n",
            "Epoch 355/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4237 - accuracy: 0.8805 - val_loss: 47.6126 - val_accuracy: 0.0142\n",
            "Epoch 356/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4319 - accuracy: 0.8779 - val_loss: 48.3690 - val_accuracy: 0.0162\n",
            "Epoch 357/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4128 - accuracy: 0.8814 - val_loss: 48.8058 - val_accuracy: 0.0139\n",
            "Epoch 358/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4143 - accuracy: 0.8775 - val_loss: 48.3134 - val_accuracy: 0.0128\n",
            "Epoch 359/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.3927 - accuracy: 0.8841 - val_loss: 48.3119 - val_accuracy: 0.0148\n",
            "Epoch 360/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4053 - accuracy: 0.8862 - val_loss: 48.3464 - val_accuracy: 0.0145\n",
            "Epoch 361/400\n",
            "441/441 [==============================] - 7s 15ms/step - loss: 0.4098 - accuracy: 0.8838 - val_loss: 48.4199 - val_accuracy: 0.0148\n",
            "Epoch 362/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.3953 - accuracy: 0.8832 - val_loss: 48.8937 - val_accuracy: 0.0131\n",
            "Epoch 363/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4100 - accuracy: 0.8824 - val_loss: 48.6074 - val_accuracy: 0.0139\n",
            "Epoch 364/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4118 - accuracy: 0.8810 - val_loss: 48.7156 - val_accuracy: 0.0125\n",
            "Epoch 365/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4325 - accuracy: 0.8750 - val_loss: 48.2170 - val_accuracy: 0.0114\n",
            "Epoch 366/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.3907 - accuracy: 0.8859 - val_loss: 48.3363 - val_accuracy: 0.0150\n",
            "Epoch 367/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.3956 - accuracy: 0.8876 - val_loss: 48.3381 - val_accuracy: 0.0133\n",
            "Epoch 368/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4104 - accuracy: 0.8833 - val_loss: 48.9424 - val_accuracy: 0.0128\n",
            "Epoch 369/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.3798 - accuracy: 0.8865 - val_loss: 48.3563 - val_accuracy: 0.0142\n",
            "Epoch 370/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.3973 - accuracy: 0.8836 - val_loss: 48.6460 - val_accuracy: 0.0136\n",
            "Epoch 371/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.3863 - accuracy: 0.8857 - val_loss: 48.5467 - val_accuracy: 0.0136\n",
            "Epoch 372/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.3972 - accuracy: 0.8861 - val_loss: 49.1521 - val_accuracy: 0.0142\n",
            "Epoch 373/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.3757 - accuracy: 0.8898 - val_loss: 48.6355 - val_accuracy: 0.0159\n",
            "Epoch 374/400\n",
            "441/441 [==============================] - 6s 15ms/step - loss: 0.3871 - accuracy: 0.8891 - val_loss: 49.1841 - val_accuracy: 0.0148\n",
            "Epoch 375/400\n",
            "441/441 [==============================] - 7s 16ms/step - loss: 0.4017 - accuracy: 0.8845 - val_loss: 49.1066 - val_accuracy: 0.0150\n",
            "Epoch 376/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.3851 - accuracy: 0.8877 - val_loss: 49.2379 - val_accuracy: 0.0159\n",
            "Epoch 377/400\n",
            "441/441 [==============================] - 6s 15ms/step - loss: 0.3839 - accuracy: 0.8893 - val_loss: 49.3392 - val_accuracy: 0.0184\n",
            "Epoch 378/400\n",
            "441/441 [==============================] - 6s 15ms/step - loss: 0.3948 - accuracy: 0.8866 - val_loss: 49.5569 - val_accuracy: 0.0133\n",
            "Epoch 379/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4082 - accuracy: 0.8786 - val_loss: 48.8387 - val_accuracy: 0.0133\n",
            "Epoch 380/400\n",
            "441/441 [==============================] - 7s 15ms/step - loss: 0.3872 - accuracy: 0.8885 - val_loss: 48.5831 - val_accuracy: 0.0142\n",
            "Epoch 381/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.3877 - accuracy: 0.8889 - val_loss: 49.7699 - val_accuracy: 0.0133\n",
            "Epoch 382/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.3731 - accuracy: 0.8880 - val_loss: 49.6702 - val_accuracy: 0.0122\n",
            "Epoch 383/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.3945 - accuracy: 0.8880 - val_loss: 49.5014 - val_accuracy: 0.0133\n",
            "Epoch 384/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.3841 - accuracy: 0.8867 - val_loss: 49.5800 - val_accuracy: 0.0128\n",
            "Epoch 385/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.3788 - accuracy: 0.8870 - val_loss: 50.0029 - val_accuracy: 0.0131\n",
            "Epoch 386/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4099 - accuracy: 0.8833 - val_loss: 49.7808 - val_accuracy: 0.0150\n",
            "Epoch 387/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.4199 - accuracy: 0.8819 - val_loss: 50.0061 - val_accuracy: 0.0148\n",
            "Epoch 388/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.3723 - accuracy: 0.8889 - val_loss: 48.8964 - val_accuracy: 0.0148\n",
            "Epoch 389/400\n",
            "441/441 [==============================] - 7s 16ms/step - loss: 0.3802 - accuracy: 0.8900 - val_loss: 49.5646 - val_accuracy: 0.0159\n",
            "Epoch 390/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.3834 - accuracy: 0.8911 - val_loss: 49.7491 - val_accuracy: 0.0148\n",
            "Epoch 391/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.3987 - accuracy: 0.8888 - val_loss: 49.2613 - val_accuracy: 0.0142\n",
            "Epoch 392/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.3769 - accuracy: 0.8936 - val_loss: 49.5134 - val_accuracy: 0.0133\n",
            "Epoch 393/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.3841 - accuracy: 0.8882 - val_loss: 48.9734 - val_accuracy: 0.0148\n",
            "Epoch 394/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.3833 - accuracy: 0.8905 - val_loss: 49.1760 - val_accuracy: 0.0150\n",
            "Epoch 395/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.3737 - accuracy: 0.8923 - val_loss: 49.3123 - val_accuracy: 0.0176\n",
            "Epoch 396/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.3823 - accuracy: 0.8879 - val_loss: 50.0013 - val_accuracy: 0.0182\n",
            "Epoch 397/400\n",
            "441/441 [==============================] - 6s 15ms/step - loss: 0.3879 - accuracy: 0.8890 - val_loss: 49.2688 - val_accuracy: 0.0167\n",
            "Epoch 398/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.3963 - accuracy: 0.8888 - val_loss: 49.4636 - val_accuracy: 0.0187\n",
            "Epoch 399/400\n",
            "441/441 [==============================] - 6s 15ms/step - loss: 0.3746 - accuracy: 0.8891 - val_loss: 49.8519 - val_accuracy: 0.0156\n",
            "Epoch 400/400\n",
            "441/441 [==============================] - 6s 14ms/step - loss: 0.3722 - accuracy: 0.8925 - val_loss: 49.2699 - val_accuracy: 0.0128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Entrenamiento\n",
        "epoch_count = range(1, len(hist.history['accuracy']) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=hist.history['accuracy'], label='train')\n",
        "sns.lineplot(x=epoch_count,  y=hist.history['val_accuracy'], label='valid')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "KpXXTBolr97r",
        "outputId": "5aa92327-f949-4b85-8120-b26844bcc145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhU1f3H8ffJvi9kJRsJhH2HgCyKiFBRWbR1wWpdat39udVabKu1VmtdutlarXWtFa2iFKooiIILIJAgaxIgQCD7CllIJtuc3x9nSAIGCJLMnUy+r+fhIXPvnbnfOXPnM2fOvXOv0lojhBCi5/OwugAhhBBdQwJdCCHchAS6EEK4CQl0IYRwExLoQgjhJrysWnFkZKROTk62avVCCNEjZWRklGutozqaZ1mgJycnk56ebtXqhRCiR1JKHTjRPBlyEUIINyGBLoQQbkICXQgh3IRlY+gdaWpqIj8/H5vNZnUp3c7Pz4+EhAS8vb2tLkUI4SZcKtDz8/MJDg4mOTkZpZTV5XQbrTUVFRXk5+eTkpJidTlCCDfhUkMuNpuNiIgItw5zAKUUERERveKbiBDCeVwq0AG3D/OjesvzFEI4j8sFuhBC9HQNzS28k55HbUMzJdU2bE0trfNW7iw+5nZXcqkxdKsdPnyYRYsWcfvtt5/W/S666CIWLVpEWFhYN1UmhOhuWmvKahuIDvZrnfbhtiI27K/g6rP6saukBltTC/NGx7F0SwEtdugXEcDIhFCCfLxotmueX7OXj3YUkV1cA8A/Pt/LgYo6ooN9uTwtkbLaBhZtOMgDswdz+/TULn8OyqoLXKSlpenjfymalZXF0KFDLakHIDc3lzlz5rBjx45jpjc3N+Pl1fWffVY/XyF6o7rGZn63PIuCQ/XcOSOV4XGheHt6cMNrm/hidxkAQ2KDCfL1Iv3AoW/dP8jXi9qG5mOmxYf5M31wFG9uOMjE5D7klNVSeaQRpeCcgVGtjwswb3Qcz1w+Gh+v7zZAopTK0FqndTRPeujtLFy4kL179zJmzBi8vb3x8/MjPDyc7Oxsdu/ezSWXXEJeXh42m427776bm2++GWg7jUFtbS0XXnghZ599NuvWrSM+Pp6lS5fi7+9v8TMToudrbLZja24hxK/tUN99ZbUkRwTi4dG2T6rFrskursbXy5P1+yq4emISRdU23tmUx8HKOtbsKuVQXRMAq3eV4ePpweDYYLYXVLU+Rk5pLdHBvlw/JZmLRvbl9jc3c/O0FDIOHGLFzhL6hvqx6KZJHKysY11OOYs2HOTNDQeZ3D+Ct26ehN2uUQrKaxuJCvYlu7iaxPAAAn27N3Jdtof+m//tJLOwukvXOSwuhF/PHX7C+e176GvWrOHiiy9mx44drYcWVlZW0qdPH+rr65kwYQKff/45ERERxwR6amoq6enpjBkzhiuuuIJ58+ZxzTXXdLg+6aGL3qzFrnltXS7zRscRFexLVX0Tmw8cYmBMEF4eHmwvqGJ3SQ39IwNJiQrk6Y938dmuUhZMSGTBhCQ+3lnM82v28vPZQ/je8Bhu//dm/Lw92Jpfdcp1zxnVl9/MG86m3EN8tKOIpVsKAUj/1Uyq65vw8fIgMsgXP29PwAzHKKXIOFDJD55fzy3T+vPgRW3v3bzKOhZn5DN3dF9So4O7p8EcpIf+HU2cOPGY48SfffZZlixZAkBeXh579uwhIiLimPukpKQwZswYAMaPH09ubq7T6hXCFeUfqiM62O9bQwyf7y7ltx9ksnJnMf2jAnlrY94pHyvU35u3NuYds+yTH2fz5MfZrbfnjo4jPbeSoipzWLCHAruGS8bEMXtEXw5WHuHSsQlEBPkye0Qs5w+N5ss95QyPCyEyyJfIIN9vrffoUWnj+/XhvdumMDI+9Jj5iX0CuHfWoM43Sjdx2UA/WU/aWQIDA1v/XrNmDatWrWL9+vUEBAQwffr0Do8j9/Vt2xg8PT2pr693Sq1CuJLiKht/+XQ3FwyP5fpXNzExuQ+3nTeAzMJqymsbuO3cAbztCOUN+yvZsL+SSf378PW+yg4fb8aQaHy9PPjTlWPYV3aE3IojjIwP5YXP9/LmhoOty215eBZhAT7Ymlr4YFsRc0b1xc/bk4MVdST28e/wcGFvTw/W/nwGnT2SeHy/8NNvECdx2UC3QnBwMDU1NR3Oq6qqIjw8nICAALKzs/n666+dXJ0QztHQ3IKHUnh7tvWoc8uPsCqrhB9PTWkdr65vbOHD7UXMHhFLWU0DW/IO8fq6A/zu0pH8edVuVmaWtPakN+ZWsvHVtrBeubOEgsP13DA1mfTcQ5TVNPDK9RP4NKuU5duLGJkQysyhMSzfXoStyc7CC4e03ndYXAjD4kIAuPXcAdQ3ttA/KpCkiEDCAnwA8PP25LLxCa33SYoIOOlz9vfxPMNWcw0S6O1EREQwdepURowYgb+/PzExMa3zZs+ezQsvvMDQoUMZPHgwkyZNsrBSIc5cta2Jny/exgOzh5ASab6NVtU1Mf+5rxgSG8ILPxrfuuyt/84gu7iGL/eUs/DCIewqruGPn+zmYGUd97+79ZjHvejZLwG4dnI/Qvy8GRgTRFOLpr6phemDonjy42w+2FbEoJggfj57CN6eHtQ3tRDg48Xc0XHMHR3X+liDYk4+Hp3YJ4A/Xjmmq5qkx3PZnaK9QW97vsK1vPLVfh79IJNLxsTx5wVj0Vpz078yWJVVAoCvlwcr7plGVX0T859b+637p0QGEurvzZa8w1wyJo7U6CBGJ4axYV8lI+JDuGB4bIdDHGU1DSzdUsCVExIJ9pOT050u2SkqhKCpxc6SzQVM6h9BWKA3S7cUALC//Agvf7WfrXmHWZVVwj0zB/KPz/eZHvUzawBQCrb++nt8uK2IB9/fzsWj+vLsgrGU1zawOCOfG89OaT0i5JyBHV4drVVUsC8/Oad/tz7X3koCXQg3VHC4ntgQPzw9FLamFj7NKmXJNwWtve+j4sP82Zpf1XqoX2SQD3efP5B7Zg4ieeGHrcvdNWMgIX7eXJGWSESgD9MGReHpoYgJ8eOO87r+F4/iu5FAF6KH+nJPGSmRgZTXNnLvf7ZQVd/EjWencMHwGGb+8QvADItEBPq0/uLRz9sDW5OdqGBffjt/BGMSw5j0xKetj/nA7CGtwyRXpCXwTno+6x+cQWyI+Tm8p4fie8NjnfxMRWfJGLqFetvzFd9dcZWNr/dVMHd0HJ4eitqGZkb8egUAkUG++HgqUmOCj/mJObQF+NikMMpqGlhy+1RW7Cxm3pi41l9c7i6pobS6gbFJYQT4eLYGekNzC1X1Tcec20RYT8bQhejBtNY8tSKb9zcX8G5GHs8uGEtGu3OMlNc28PE95zA4Jpi/fLqHV77az2XjE7l2cj8ignyosTUTF+aP3a7x8FBcM6nfMY8/KCa4w6NJfL08iQ52j8P5egsJdCFcgN2uWba1kNIaG75enlw3JZmmFjsb9lVy3ztbKK1pYFBMEOm5hxj/2KrW+90zcyBzRrX93PyemYO4Z+axv1g8eiRJ+/OdCPckgX4GgoKCqK2tpbCwkLvuuovFixd/a5np06fzzDPPkJbW4Tck0YtprXllbS57y2oJ9ffm+TV7W+cF+Xqxbm8F723Ob512x3mplFY38PjyLPy9Pbl75kBuPXeAFaULFyWB3gXi4uI6DHMhjqe1Jru4hkUbDrKzsIrNBw+3zusfGcgfrhjNE8uz+anjxzoTk/vw0JxhbNhfwewRsXh5eDCkbzBnpUR859OvCvclgd7OwoULSUxM5I477gDgkUcewcvLi9WrV3Po0CGampp47LHHmD9//jH3a3+Wxvr6em644Qa2bt3KkCFD5FwuguIqG9HBvlTbmrhj0WbW5lQcM3/VfdPYfPAwU1MjiQ/z56nLRvH959cxNjGMZ68aS6CvFyMT2k4GdarjvEXv1alAV0rNBv4CeAIvaa1/f9z8JOB1IMyxzEKt9fIzquyjhVC8/Ywe4ltiR8KFvz/h7CuvvJJ77rmnNdDfeecdVqxYwV133UVISAjl5eVMmjSJefPmnfCaoM8//zwBAQFkZWWxbds2xo0b17XPQfQoOwqquOS5tdwwNZldJbVs2n+Ih+YMY3BMMNe8vIGUyEBSo4OPOeVqcmQgGb+aKdedFaftlIGulPIEngNmAfnAJqXUMq11ZrvFfgW8o7V+Xik1DFgOJHdDvd1q7NixlJaWUlhYSFlZGeHh4cTGxnLvvffyxRdf4OHhQUFBASUlJcTGdnws7hdffMFdd90FwKhRoxg1apQzn4KwWENzC5VHGnnyo2xSIoNYvDmPZrvmn1/uB+CB2YO58WxzSua/XjX2W6dhPUrCXHwXnemhTwRytNb7AJRSbwPzgfaBroEQx9+hQOEZV3aSnnR3uvzyy1m8eDHFxcVceeWVvPnmm5SVlZGRkYG3tzfJyckdnjZX9E4vf7Wfdzblcc/MgUSH+HH7mxmUVDe0zh8UE8QL14zjF0t2UHmkkQUTklrntT8JlRBdoTOBHg+0P/N8PnDWccs8AqxUSv0fEAjM7OiBlFI3AzcDJCUldbSI5a688kpuuukmysvL+fzzz3nnnXeIjo7G29ub1atXc+DAgZPef9q0aSxatIgZM2awY8cOtm3b5qTKhTNUHmnkT5/s5mezB/P8mr2tR6bc9ubmby37/u1TGJMQhoeH4pyBUZTXNtAn0MfZJYtepKt2il4FvKa1/oNSajLwhlJqhNba3n4hrfWLwItgfinaRevuUsOHD6empob4+Hj69u3L1Vdfzdy5cxk5ciRpaWkMGTLkpPe/7bbbuOGGGxg6dChDhw5l/PjxJ11e9BwNzS389oNMlnxTwH+3FFBja+aHZyVx2fgEvv/3dQAsvWMqS74pYER8KOOS2i6EEOjr1e3XkxSiM1tYAZDY7naCY1p7NwKzAbTW65VSfkAkUNoVRTrb9u1tO2MjIyNZv359h8vV1tYC5iLRO3bsAMDf35+33367+4sUTqG1ZlVWKYNjgvnx65vIKTWveY2tmXmj43j8khEopbjx7BQmpvRhdGIYoxPDLK5a9FadCfRNwEClVAomyBcAPzxumYPA+cBrSqmhgB9QhhA9kNaa3Io6EsP9+fWyncdc4mzGkGg+yzb9lJ+ck9K68/KhOcMsqVWI9k4Z6FrrZqXUncAKzCGJr2itdyqlHgXStdbLgJ8C/1RK3YvZQXq9tuqsX0J8RwWH67njzc1syTM/9gn29aKmoZkhscGEB/hw54xUpqZGsqu4hi92l53wCBUhrNKpQT3HMeXLj5v2cLu/M4GpXVGQ1rpXHLIln3eu53cfZrWGOUBNQzORQT68e+vkY66sMzg2mMGxJ780mhBWcKm9NH5+flRUVBAREeHWoa61pqKiAj8/OS2pK1i6pYDn1+wlu7iG/5uRSmSQL0P7hjA4NpimFrtcJk30GC4V6AkJCeTn51NW5v7D735+fiQkJJx6QdHlWuyaj3YUUWNrZuqASH7x/nYSwgO4/3uD+Mk5/VsvpSZET+NSge7t7U1KSorVZQg396dPdvO31Tmtt5WCv/1wLANPcYV5IVydSwW6EN2l2tZEra2Za17ewL6yI8wcGs0NU1N49tM93DA1RcJcuAUJdOH2PtxWxB2LNuPloWi2m53RP56awpTUSKamRlpcnRBdRwJduC1bUwsrM0u4661vAGi2a576wSimpEaQEB5gcXVCdD0JdOF27HbNwco6Hvswi1VZJYC5eMTYpHAuG58gl2ITbksCXbiF3PIjzPrT58wfE8/q7FIqjjQCcPf5AxmVEMrU1Eg5ekW4PQl00eNV1TXx5oYDNLVoFmfkMyI+xFx/s6aB288bgK+XBLnoHSTQRY9UY2vCQykqjzQy/7m1VDp65AC/ungYk/pHWFidENaQQBc9jtaa+X9bS2OLndTooNYwnz44iguGx3JWSh+LKxTCGhLoosf5el8l+8qPAJB/qJ6fXTCY2SNiiQnxI0jOOS56Mdn6RY+wfm8F2/IPEx3iy9Mf7yIyyJe7zk+lsdnOjyb3k3FyIZBAFz3ELW+kU21rBiAu1I/XfzyB4XFy+loh2pNAFz1C+7NvrvnZefh4eVhYjRCuSQJduCy7XfO31Tls2F9BVX0TM4fGsPDCwRLmQpyABLpwSVprHv0gk9fW5bZOu/qsJFKj5SRaQpyIdHWES3prYx6vrcvlxrNTeOX6NFKjgxibJBdfFuJkpIcuXMbhukZe/mo/u4prWJlZwlkpffjVxUNRSjFjSIzV5Qnh8iTQhct4/MMsFm/OJyUykKmpEfxm3nC3vhShEF1NAl1Y6pPMEhZtOMD4fuG8m5HP1Wcl8filI60uS4geSQJdWOqpj7PZU1rL6l1l9I8K5JZpA6wuSYgeSwJdOF1u+RFWZZXwvWGxlNc2AHDt5H4yxCLEGZJAF073wud7eXtTHo99mAXA05eN4vK0RIurEqLnk8MWhdPllNa2/h0W4M2MIdEWViOE+5AeunCqhuYW9pUf4aqJSSyYkEhyZCCh/t5WlyWEW5BAF06RV1nHe5vz+fOqPQAMiApkdKL8UEiIriSBLrrdjoIqrvjHeuoaW1qnJUcEWliREO5JAl10q8LD9by+Lhe71iz6yVnYNTz6wU75Gb8Q3UACXXSbvMo6znlqNQDnDopiSmokACvvPdfKsoRwW3KUi+gWeZV1XPfqxtbbF4/sa2E1QvQO0kMX3eIPK3dRXGXjrZsmERfmR2J4gNUlCeH2JNBFl6lrbOZgZR0VtY18sK2IaycnM3lAhNVlCdFrSKCLLvPYh1ks2nAQXy8PkiMDufXc/laXJESvImPooksUV9n45uBhABqa7Tx/9TiiQ/wsrkqI3kV66OKMbMqt5F/rD/C/rYWt066amMjAGLlUnBDO1qkeulJqtlJql1IqRym18ATLXKGUylRK7VRKLeraMoUr0lpz42ubjgnz+2YN4onvj7KwKiF6r1P20JVSnsBzwCwgH9iklFqmtc5st8xA4EFgqtb6kFJKzrbUC6zeVUq1rZm4UD88PRV5lfUMiAqyuiwheq3ODLlMBHK01vsAlFJvA/OBzHbL3AQ8p7U+BKC1Lu3qQoVrsds1T6/YTVKfAFbddy7enooN+ys5K6WP1aUJ0Wt1ZsglHshrdzvfMa29QcAgpdRapdTXSqnZHT2QUupmpVS6Uiq9rKzsu1UsXML/thWSVVTNT783CB8vD5RSTOofIReoEMJCXXWUixcwEJgOXAX8Uyn1rZN1aK1f1Fqnaa3ToqKiumjVwtlW7izmwfe3MyQ2mLmj4qwuRwjh0JlALwDaX04mwTGtvXxgmda6SWu9H9iNCXjhZrTWPPlxNvFh/rx0XRoeHtIjF8JVdCbQNwEDlVIpSikfYAGw7Lhl/ovpnaOUisQMwezrwjqFC6i2NTHl95+xt+wIt5w7gAT5Ob8QLuWUga61bgbuBFYAWcA7WuudSqlHlVLzHIutACqUUpnAauBnWuuK7ipaWGP5tiKKqmycPySaOaPkZFtCuBqltbZkxWlpaTo9Pd2SdYvTU1XfxLItBby2LhcNfHrfubLzUwiLKKUytNZpHc2TX4qKk9Jac/+7W/kkswQvD8WfF4yRMBfCRUmgi5N6b3MBn2SW8MOzkrh12gCSImTcXAhXJYEuTuhvn+3hmZW7mZAczm/nj8BTjmgRwqXJ2RZFh1rsmlfX5jI6MYyXrp0gYS5EDyA9dHEMrTW3vJFBweF6Ko408pv5wwkN8La6LCFEJ0igi2MUVdlYmVkCQJ9AH84dJL/oFaKnkEAXx9hZWA3A6z+eyOT+Efh4yaicED2FvFtFq7zKOn65ZDsAE5LDJcyF6GHkHSta/fTdrZTWNBDg40mAj3x5E6KnkXetAODTrBI27q9kamoE/zdDzqsmRE8kgS7YXVLDfe9sZVjfEF6+bgJ+3p5WlySE+A5kyKWXK6tp4PpXNuLj5cE/fjRewlyIHkwCvRdraG7htn9nUFnXyKvXTyCxj/ysX4ieTIZcerElmwtIP3CIvywYw4j4UKvLEUKcIemh92JLtxSSEhnIvNFyGTkh3IH00HuhJd/k86dP9nCwso67zx8op8MVwk1IoPcyLXbNg+9vx9ZkJ9Tfmx+fnWJ1SUKILiKB3suszSnH1mTn1nMHcPVZSYT6y4m3hHAXEui9zPLtRQT6eHLPzIFyiKIQbkYCvZdobLZT39TCJ5klzBgaI2EuhBuSQO8F7HbNja9v4ss95QB8f2y8xRUJIbqDBLqb01rzzMpdfLmnnAAfTx68cAjnDYm2uiwhRDeQQHdzizPy+fuavSyYkMgT3x8phygK4cbkh0VurKG5hUc/yGRiSh8ev1TCXAh3J4HuxtbvraDG1swt0/rLRZ6F6AUk0N3YJ5kl+Ht7MjU10upShBBOIIHupux2zaqsEqYNipRDFIXoJSTQ3dT2gipKqhuYNSzW6lKEEE4iR7m4meYWO/OfW8uu4hp8vTyYIYcoCtFrSA/dzWzJO8zOwmpiQvz4zy2T6RPoY3VJQggnkR66myitsfH75dmU1Njw9FAsv/scOfGWEL2MBLqbWLalkPe/KQDg3EFREuZC9EIS6G7i630VKAVPXDqSi0f1tbocIYQFJNDdQGOznQ37KrlqYhILJiZZXY4QwiKyU9QNfJZdQk1DM7OGxlhdihDCQhLoPVxptY2/fpZDbIgf0wZFWV2OEMJCnQp0pdRspdQupVSOUmrhSZb7gVJKK6XSuq5EcTK//O8O9pbV8tCcYXK+FiF6uVMGulLKE3gOuBAYBlyllBrWwXLBwN3Ahq4uUnRsa95hVmWVcNM5/WVHqBCiUz30iUCO1nqf1roReBuY38FyvwWeBGxdWJ84gVvfyGD+c2uJCvLl2snJVpcjhHABnQn0eCCv3e18x7RWSqlxQKLW+sOTPZBS6malVLpSKr2srOy0ixVGbUMzKzOLGZ0QyvK7zyEq2NfqkoQQLuCMd4oqpTyAPwI/PdWyWusXtdZpWuu0qCjZgfdd7Cur5cevbcKu4b7vDSYySMJcCGF05jj0AiCx3e0Ex7SjgoERwBrHFXFigWVKqXla6/SuKlRAta2JS/++jqr6JgDGJoVZXJEQwpV0JtA3AQOVUimYIF8A/PDoTK11FdB6BQWl1Brgfgnzrvfl7nKq6puY3D+CmBBfQvzk5/1CiDanDHStdbNS6k5gBeAJvKK13qmUehRI11ov6+4ihfFVThnBvl68ceNEvDzlJwRCiGN16qf/WuvlwPLjpj18gmWnn3lZ4nh2u+bzXWVMHhAhYS6E6JAkQw9QVdfE/Yu3Ulhl46KRcry5EKJjEug9wEtf7eP9zQV4eihmj5BLygkhOiaB3gOs21sBwHu3TZELPgshTkgC3cW9vfEgGQcOcfv0AYxJlMMUhRAnJoHuwrKLq1n4/nYAZg2TU+MKIU5OLnDhorTW/HHlbgJ9PPnq5zMIl4s9CyFOQXroLmrplkJWZpZwx4xUCXMhRKdIoLug0hobDy3dwfh+4dwybYDV5QgheggJdBe0OCOfGlszT/5glFy0QgjRaRLoLsZu17y/uYC0fuGkRgdZXY4QogeRQHcx/95wgJzSWq6elGR1KUKIHkYC3YUcqDjCE8uzmTYoikvGxJ/6DkII0Y4Euouw2zU/W7wNLw/Fkz8YiePc8kII0WkS6C7i9fW5bNxfyUNzh9E31N/qcoQQPZAEugvYX36EJz/O5rzBUVw+PsHqcoQQPZQEusVsTS3c+58t+Hh68MT3R8lQixDiO5Of/lvsyY+z2ZJ3mOevHkdsqJ/V5QghejDpoVsoq6iaN78+yFUTE7lQLlwhhDhDEugWySmt4ZLn1hLg68mdMwZaXY4Qwg3IkItFfrc8Gx8vDz6+e5oMtQghuoT00C2QU1rDZ9ml3DKtv4S5EKLLSKBb4F/rD+Dj6cFVE+Xn/UKIriOB7mQ1tibey8hnzui+RAT5Wl2OEMKNSKA72atrcznS2MK1k5OtLkUI4WYk0J3oja8P8NfP9jBnVF+54LMQostJoDtJXmUdDy/dwVkpETx+yUiryxFCuCEJdCdobLbz9IpdeCjF05ePIjTA2+qShBBuSALdCf68ajfLthZy27kD5EyKQohuI4HezSpqG3htXS7zRsdx/wWDrS5HCOHGJNC72Ytf7MPW1MLdM+Xn/UKI7iWB3o1WZZbw6tpcLhkTz4AoueCzEKJ7SaB3kxa75qGlOxgQHcTDc4dZXY4QoheQQO8ma3PKKaqyced5qYQF+FhdjhCiF5BA7yb//HIfEYE+zBwWbXUpQoheQgK9Gzz76R6+3FPOLef2x9fL0+pyhBC9RKcCXSk1Wym1SymVo5Ra2MH8+5RSmUqpbUqpT5VS/bq+1J5hw74K/vjJbi4e2VfO1yKEcKpTBrpSyhN4DrgQGAZcpZQ6fi/fN0Ca1noUsBh4qqsL7Qnsds3TK3YRFezLH64YjZ+39M6FEM7TmR76RCBHa71Pa90IvA3Mb7+A1nq11rrOcfNrIKFry3R9LXbN75ZnkX7gED+7YLCEuRDC6ToT6PFAXrvb+Y5pJ3Ij8FFHM5RSNyul0pVS6WVlZZ2vsgdYtOEAL321n6vPSuLy8b3u80wI4QK6dKeoUuoaIA14uqP5WusXtdZpWuu0qKiorly1pWxNLfz1sxwmpvThsUtGoJSyuiQhRC/UmYtEFwCJ7W4nOKYdQyk1E/glcK7WuqFrynN9izYc5BdLtgPw7FVjJcyFEJbpTA99EzBQKZWilPIBFgDL2i+glBoL/AOYp7Uu7foyXVNpta01zM8ZGMmk/hEWVySE6M1O2UPXWjcrpe4EVgCewCta651KqUeBdK31MswQSxDwrqOHelBrPa8b63YJf/xkN96eindvncKgGDlXixDCWp0ZckFrvRxYfty0h9v9PbOL63J5GQcqeSc9j+unpMjl5IQQLqFTgS6O9dTH2fx9zV7iw/y5Z5acFlcI4Rrkp/+nqbnFztub8ugb6sebPzmLED+5nJwQwjVIoJ+GalsTP/lXOpVHGnlozjCSIwOtLkkIIVpJoHeSramFu976hjW7yhjaN4Tpg93nOHohhHuQMfRO0Frzf44wf1WmLuAAABGVSURBVOL7I7lqYpLVJQkhxLdID70T3k3P55PMEn550VAJcyGEy5JAP4W1OeU8+kEmk/r34cazU6wuRwghTkgC/SS25R/m2lc2Eh3syzOXj8bDQ37WL4RwXTKGfgKrMku49z9biAryZckdUwn1l8MThRCuTQL9OI3Ndv68ajd/X7OXoX1D+PvV4yTMhRA9ggT6cX65ZDvvZuQTGeTDn64cTYocay6E6CEk0NtZvr2IdzPyufO8VO6/YLDV5QghxGmRQMccZ/7BtiJ+sWQ7I+NDuXumnJ9FCNHzSKADz6zcxXOr97YOs3h7ysE/Qoiep1cHekNzC7/7MIvX1x9gwYREHr90JJ5yaKIQoofq1YH+2tpcXl9/gOunJPPwnGFynLkQokfr1YG+bGshYxLDeGTecKtLEUKIM9YrB4tb7JqH/ruDnYXVzB0dZ3U5QgjRJXpdD72huYUHFm9j6ZZCrp+SzDWT5GRbQgj30OsC/fcfZbN0SyEPzB7M7dNTrS5HCCG6TK8aclmbU87r63K5ZlKShLkQwu30mkDPLKzmljcySI0O4oHZQ6wuRwghulyvCPT8Q3Vc/+pGgv28eP3HE+XCzkIIt+T2Y+jVtiaue2Uj9U0tLL51Cn1D/a0uSQghuoXbB/pzq3PYV36EN39yFoNjg60uRwghuo1bD7msyynn1a9yuXRMPFMGRFpdjhBCdCu3DfSymgbuWLSZ5MgAHp47zOpyhBCi27nVkEtTi526xhZ2FlTx2IdZHGls4d2rxxEW4GN1aUII0e3cKtAfWLyNJd8UABDq782LPxpParSMmwshege3CPTmFjvvbc5vDfP7Zg3i5mn98fP2tLgyIYRwnh4d6LamFh58fzsfbCsgvOUQz4avYtal1+EfGwhFmyBholmweCvEjgYPt91lIIQQPTfQ6xtbeODlD7Hnb+LTkE9Iqs+CemDRkraFYkZCWBLs+hBSZ8GEG6FoK0y8GQL6mGXK90B1AcSngW+QJc9FCCG6Qo8L9MJdm9iX8SkB+z7mr83fgDcmyAHixkHhZvP3zEfg00ehZDv494GDX0POJ2Ze8XbwD4PqItj7aduDX/A72PsZhMRD31Hwzb/hqv9AcIzznqAQQnxHPS7QD278H2fv/QuHVCgHUhbQb//bZsaIH8CMh6C2BPzDIWow9J8OWkP8OGisg/2fw6aXIPsD8A2F0HjwDYGmerA3wYpffHuF/5gGE2+CflMhMAq8fCE0AVS7qxs11UNzA5RlQ+JZx84TQggnUVprS1aclpam09PTT/t+FZUVNB05TGxsPHj7wdcvmCCd++fOPUDjETiwDpLPBm/HaQDsdjjwFSy51fTSy/fAgbUw/jrY/C/Taz9eSAKExIHygOJt0FRnpo+8wjx28XYo32WW6zsKhs03dQJ4+UFLk/kQqas0HwhD54JfGJTuhNIsiB4KVfkQPx5KdkLiRHOfhhrI3whD54GHF1QXQnCseYyD683yfmHmb/8wiB4G2m7WExRlPuAaqsEvFFqazf6FuHEdfwhVF5n1tTRA5GDwOu7wz8Yj4OV/7L6J5gZYdKX5ADz3Z2Z90DUfcrs+goAI0xa1peDpbZ5ryQ4IioGg6BPf195iPuyDYqHZBj4BYKsybVCxB2KGw/bF5nXyDjCP3dIE5btNG/QdbV6HsETT1mH9oOkIfP4U1FVA0iRIPgf69IfMpRCeDHFjzPbj6Wset67C1Lh7hfkmWZFjhgQn3gwe3uAbfOywX1UBHNpvtrM+/c207YvNN8h+kx3t3QgZr8KRMjjvl23tnPsVRA2FwAjzGhwph8BIM7+h1myLCWlmevYHpiPiH25q8Ak0j1FXCVV5EBxnth2AwwdN5whMbQNmgKdP23ptVeAdaN4XHh6m3Yu2Qp8U8/ibXoK+Y8x22VQHXz8Po66EqEHm/rWlcOiAqa2jbaau0tTn5dvx69xQax43KBrqD8Ou5RCeYtrraMfLP+ykm9m3tht7i9ketrxpnt/kO06yvB2a69vaUGvY8R7kbzLbk6c3zPyNya7vSCmVobVO63BeTwt0S5RkmjfgkTLYu9q8OD6B5l9ootlYA6NNsOxeAWhAmY3KVm1e4FPxDTXj+of2n2AB5Xhch4iB5s1XuNm8gdBmQ/byg+C+bY8TEGH+r6uAwRebZfatNgHVWGfCLG6c+TZTvhsO5cKQOea57FsDjbXm/lFDIbyfebwhc0yI5Kwyt6fcBXXlsO9zKNrSVmPkIKgpNu0zdC7kfAo1RWZndV2F+VDxCYC8jTDgfKgpNG+Y1FnmPiU7TQ2hiWb5o0Nmw78PWf8zz7NPivnm5RcKaTeaD7Jmmwke70Az3S/EfPAd2m8+AGyHTZBW5ZsPu/a8A80Hrbe/qeUoD28z/WSvi/I0QXP0w/3417e53rxupTs7fokDo03Y1FWa9jzKyx+ih0DhN23TfIJNyB7KbXsOg2a3fbhv+4/59jnyMtO5yN8EEakQOwpKM9s6F8fz9G37wCzfbZ6bXxjM+g2U7YYNL4Bu+fZ9wpLMshU5jpr92tqm2WZeh6TJsPtjR1t5mKHQo88zrJ95HjVFYG82H7xRg8wHxvb3HJ2fCvMeDIo135Kb6sx7wC/UdIJaGh2BfsRMa//69Tvb1NZUB4MvNNuW1mb7CYgwHZANL5hv9j6BUH/IPIe9q6G+0ryuRx9vyBzw8ITESea5efrAnpVQtsvUWX/I7JMLSzKdx5pCs20cbbekybBgUdt+vNN0xoGulJoN/AXwBF7SWv/+uPm+wL+A8UAFcKXWOvdkj9mjAv14LY43tofXt3sR5XvMG6pPCvgEmY103xrTYxpwngmGlgZzXw9v0yNraYJ1z5oQGnO12ah2/tcMFa1+HAIiIXmq6YW2NJmNKXOZ6W0Mm282cqUgYQLs/8K8yYfONRtk/kbTiwuOgXV/M0GVen5b7zRmuNnoSnaYIaXwfubNHxBp1h891DyHPavMfeoqTP1BMTDqCshPNyHa3oDzYdAFJvCri8x+jKOSzzEbfkO1eTN4eJkPlPxNJnjbvwnBfJCUZTl6gZ7mzdZQDSMuM6HeWAODLjTfhir3mR3hzfXmzeTt6IXbDpve2sjLzQ7woGjTRsF9zX2qCkw4DpgBBZtNWBwpN69heLJZ977V5k1/YK0JIjChN/wS8+FYvN20Q0uT6UFX5ZsPw+BYExjrn4PDB8z9AiLMN7lZj5qQWXyD2W7ix5maALKWmXoGzDC9fOVh5vmHmftvf9esN2oIxI2FvA2Q8ZpZTmszBNlUb/YRhae0hVhZtvmm0mwzQRw9xHwgl+ww99v6lpl/9LUaOhc2vWzaV3nA6KvMt8CqPFPHJw+b2yHxZnuMHWFe04aattcwPNkE3p6V5nUJiTft6xMA0x8022xtSdvr6xts2utoAPoEm2874clmnbtXmG2i39nmvWCrMvcJiDDfAuod33qr8uGcn5q2/frv5n2l7eY1jh9v2vLgBkC3dVxQphcdFGvCOXqo6VAoD/P+2vqW2eYDI00bHBUQYbZDtPk7f5P5QEyabF7DsT8yH14H15uRgJmPnLynfxJnFOhKKU9gNzALyAc2AVdprTPbLXM7MEprfatSagFwqdb6ypM9bo8OdGfSuuvG5Iu2mqAOjf/2vLpK06Pz9DIBF9CnbUiqveLtZmfxOfe3DeGU7DRvpGZb29BA+5oLt5g3UrMN+k1pm16eY95UgZFQU2IC/VCuCV0vf/PGiB5iwtg3xDymUuZrrYeHqbnwG/PtQnk4hlRiXHcfht1uAjw8+djhK7vdhJdnu9M6H84zwXeiQ2072i6qC00vXykTdCeitWPIr9mEantVBeZDLizRBJmHp6mvNNO8TsGxxy5ff7jzQxjNDccOz5xMVb55/avyTTu0r7PxiNmm+k35bq/10aEPMG1hb4H9a8zQUuQg09M/vl06cjjPdJo8PNveO51Rtsus5ztup2ca6JOBR7TWFzhuPwigtX6i3TIrHMusV0p5AcVAlD7Jg0ugCyHE6TtZoHfmlzbxQLvvFuQ7pnW4jNa6GagCIjoo5GalVLpSKr2srKwztQshhOgkp/50Umv9otY6TWudFhUV5cxVCyGE2+tMoBcAie1uJzimdbiMY8glFLNzVAghhJN0JtA3AQOVUilKKR9gAbDsuGWWAdc5/r4M+Oxk4+dCCCG63il3y2qtm5VSdwIrMIctvqK13qmUehRI11ovA14G3lBK5QCVmNAXQgjhRJ06zkZrvRxYfty0h9v9bQMu79rShBBCnA45n6wQQrgJCXQhhHATlp3LRSlVBhz4jnePBMpPuZTzSV2nR+o6PVLX6XPV2s6krn5a6w6P+7Ys0M+EUir9RL+UspLUdXqkrtMjdZ0+V62tu+qSIRchhHATEuhCCOEmemqgv2h1AScgdZ0eqev0SF2nz1Vr65a6euQYuhBCiG/rqT10IYQQx5FAF0IIN9GjAl0pNVsptUsplaOUWmhxLblKqe1KqS1KqXTHtD5KqU+UUnsc/4c7oY5XlFKlSqkd7aZ1WIcynnW03zal1DgLantEKVXgaLctSqmL2s170FHbLqXUBd1UU6JSarVSKlMptVMpdbdjuqVtdpK6LG0vx3r8lFIblVJbHbX9xjE9RSm1wVHDfxwn70Mp5eu4neOYn+zkul5TSu1v12ZjHNOdvf17KqW+UUp94Ljd/e2lte4R/zAnBtsL9Ad8gK3AMAvryQUij5v2FLDQ8fdC4Ekn1DENGAfsOFUdwEXAR5ir904CNlhQ2yPA/R0sO8zxmvoCKY7X2rMbauoLjHP8HYy5vOIwq9vsJHVZ2l6OdSkgyPG3N7DB0RbvAAsc018AbnP8fTvwguPvBcB/nFzXa8BlHSzv7O3/PmAR8IHjdre3V0/qoU8EcrTW+7TWjcDbwHyLazrefOB1x9+vA5d09wq11l9gznDZmTrmA//SxtdAmFKqr5NrO5H5wNta6wat9X4gB/Oad3VNRVrrzY6/a4AszBW3LG2zk9R1Ik5pL0c9Wmt99CrK3o5/GpgBLHZMP77NjrblYuB8pbr+Qq8nqetEnLb9K6USgIuBlxy3FU5or54U6J25FJ4zaWClUipDKXWzY1qM1rrI8XcxEGNNaSesw1Xa8E7HV95X2g1LOb02x1fbsZiencu02XF1gQu0l2P4YAtQCnyC+UZwWJtLTh6//k5dkrI76tJaH22zxx1t9iellO/xdXVQc1f7M/AAYHfcjsAJ7dWTAt3VnK21HgdcCNyhlJrWfqY2358sPybUVepo53lgADAGKAL+YEURSqkg4D3gHq11dft5VrZZB3W5RHtprVu01mMwVyybCAyxoo7jHV+XUmoE8CCmvglAH+DnzqxJKTUHKNVaZzhzvdCzAr0zl8JzGq11geP/UmAJZiMvOfoVzvF/qUXlnagOy9tQa13ieBPagX/SNkzgtNqUUt6Y0HxTa/2+Y7LlbdZRXa7QXu1prQ8Dq4HJmCGLo9dUaL9+p1+Ssl1dsx3DV1pr3QC8ivPbbCowTymVixkangH8BSe0V08K9M5cCs8plFKBSqngo38D3wN2cOyl+K4DllpR30nqWAZc69jbPwmoajfM4BTHjVleimm3o7UtcOzxTwEGAhu7Yf0Kc4WtLK31H9vNsrTNTlSX1e3lqCFKKRXm+NsfmIUZ41+NueQkfLvNuv2SlCeoK7vdB7PCjFO3b7Nufy211g9qrRO01smYnPpMa301zmivrtqj64x/mL3UuzHjd7+0sI7+mCMMtgI7j9aCGff6FNgDrAL6OKGWtzBfxZsw43I3nqgOzN795xzttx1Is6C2Nxzr3ubYkPu2W/6Xjtp2ARd2U01nY4ZTtgFbHP8usrrNTlKXpe3lWM8o4BtHDTuAh9u9DzZidsi+C/g6pvs5buc45vd3cl2fOdpsB/Bv2o6Ecer271jndNqOcun29pKf/gshhJvoSUMuQgghTkICXQgh3IQEuhBCuAkJdCGEcBMS6EII4SYk0IUQwk1IoAshhJv4f52/BmwSseNKAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN6Fg_BsxJe6"
      },
      "source": [
        "### 5 - Predicción de próxima palabra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBvKHFPmzpy2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0a0f593-a147-455d-8362-71d5de0a97ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 5.6 MB 30.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 65.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 77.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 79.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 71.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 272 kB 75.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 4.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 4.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 77.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 78.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 80 kB 10.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 68 kB 7.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 856 kB 66.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 61.6 MB/s \n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Se utilizará gradio para ensayar el modelo\n",
        "# Herramienta poderosa para crear interfaces rápidas para ensayar modelos\n",
        "# https://gradio.app/\n",
        "import sys\n",
        "!{sys.executable} -m pip install gradio --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "id": "HNyBykvhzs7-",
        "outputId": "51268b14-1789-4d90-d230-cb6d3f6b0f7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gradio/deprecation.py:40: UserWarning: `layout` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://18692.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting, check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://18692.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<gradio.routes.App at 0x7f73466eea50>,\n",
              " 'http://127.0.0.1:7860/',\n",
              " 'https://18692.gradio.app')"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def model_response(human_text):\n",
        "\n",
        "    # Encodeamos\n",
        "    encoded = tok.texts_to_sequences([human_text])[0]\n",
        "    # Si tienen distinto largo\n",
        "    encoded = pad_sequences([encoded], maxlen=3, padding='pre')\n",
        "    \n",
        "    # Predicción softmax\n",
        "    y_hat = model2.predict(encoded).argmax(axis=-1)\n",
        "\n",
        "    # Debemos buscar en el vocabulario la palabra\n",
        "    # que corresopnde al indice (y_hat) predicho por le modelo\n",
        "    out_word = ''\n",
        "    for word, index in tok.word_index.items():\n",
        "        if index == y_hat:\n",
        "            out_word = word\n",
        "            break\n",
        "\n",
        "    # Agrego la palabra a la frase predicha\n",
        "    return human_text + ' ' + out_word\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=model_response,\n",
        "    inputs=[\"textbox\"],\n",
        "    outputs=\"text\",\n",
        "    layout=\"vertical\")\n",
        "\n",
        "iface.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCeMWWupxN1-"
      },
      "source": [
        "### 6 - Generación de secuencias nuevas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwbS_pfhxvB3"
      },
      "outputs": [],
      "source": [
        "def generate_seq(model, tokenizer, seed_text, max_length, n_words):\n",
        "    \"\"\"\n",
        "        Exec model sequence prediction\n",
        "\n",
        "        Args:\n",
        "            model (keras): modelo entrenado\n",
        "            tokenizer (keras tokenizer): tonenizer utilizado en el preprocesamiento\n",
        "            seed_text (string): texto de entrada (input_seq)\n",
        "            max_length (int): máxima longitud de la sequencia de entrada\n",
        "            n_words (int): números de palabras a agregar a la sequencia de entrada\n",
        "        returns:\n",
        "            output_text (string): sentencia con las \"n_words\" agregadas\n",
        "    \"\"\"\n",
        "    output_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "    for _ in range(n_words):\n",
        "\t\t# Encodeamos\n",
        "        encoded = tokenizer.texts_to_sequences([output_text])[0]\n",
        "\t\t# Si tienen distinto largo\n",
        "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\t\t\n",
        "\t\t# Predicción softmax\n",
        "        y_hat = model.predict(encoded).argmax(axis=-1)\n",
        "\t\t# Vamos concatenando las predicciones\n",
        "        out_word = ''\n",
        "\n",
        "        # Debemos buscar en el vocabulario la palabra\n",
        "        # que corresopnde al indice (y_hat) predicho por le modelo\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == y_hat:\n",
        "                out_word = word\n",
        "                break\n",
        "\n",
        "\t\t# Agrego las palabras a la frase predicha\n",
        "        output_text += ' ' + out_word\n",
        "    return output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoFqRC5pxzqS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9c9c7f94-9062-48f6-8143-bc9289e7897b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'but as the riper now he'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "input_text='but as the riper'\n",
        "\n",
        "generate_seq(model2, tok, input_text, max_length=3, n_words=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2SHmXbgxQH9"
      },
      "source": [
        "### 7 - Conclusiones\n",
        "*   A pesar de realizar cerca de 10 modelos diferentes, no se logró mejorar el resultado.\n",
        "*   Se probaron modelos con varias capas, así como con y sin BRNN.\n",
        "*   Se volvió a producir el overfitting en todos los casos.\n",
        "*   Cada entrenamiento, tomó cerca de 1 hora.\n",
        "*   Una posibilidad sería utilizar modelos preentrenados en busca de mejorar los resultados."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Desafio_4_predicción_palabra.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
